{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a29875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:16:21.564965Z",
     "iopub.status.busy": "2024-10-21T06:16:21.564473Z",
     "iopub.status.idle": "2024-10-21T06:16:39.522023Z",
     "shell.execute_reply": "2024-10-21T06:16:39.520893Z"
    },
    "id": "vhdm-KYDNLia",
    "outputId": "e3baabd0-5b95-4c6a-a721-dd41ed2189f1",
    "papermill": {
     "duration": 17.971193,
     "end_time": "2024-10-21T06:16:39.524681",
     "exception": false,
     "start_time": "2024-10-21T06:16:21.553488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/debayan20000/brainsegmentation2018-dataset\r\n",
      "License(s): apache-2.0\r\n",
      "Downloading brainsegmentation2018-dataset.zip to /kaggle/working\r\n",
      "100%|██████████████████████████████████████▉| 1.95G/1.95G [00:15<00:00, 135MB/s]\r\n",
      "100%|███████████████████████████████████████| 1.95G/1.95G [00:15<00:00, 132MB/s]\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d debayan20000/brainsegmentation2018-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40c7012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:16:39.560432Z",
     "iopub.status.busy": "2024-10-21T06:16:39.559728Z",
     "iopub.status.idle": "2024-10-21T06:16:56.667949Z",
     "shell.execute_reply": "2024-10-21T06:16:56.666745Z"
    },
    "id": "8GI5qiKydn_H",
    "outputId": "de674e01-3517-443d-afbd-d07eafa7f0e6",
    "papermill": {
     "duration": 17.129162,
     "end_time": "2024-10-21T06:16:56.670489",
     "exception": false,
     "start_time": "2024-10-21T06:16:39.541327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\r\n",
      "  Downloading rasterio-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\r\n",
      "Collecting affine (from rasterio)\r\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\r\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from rasterio) (23.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from rasterio) (2024.8.30)\r\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.10/site-packages (from rasterio) (8.1.7)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from rasterio) (0.7.2)\r\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.26.4)\r\n",
      "Requirement already satisfied: click-plugins in /opt/conda/lib/python3.10/site-packages (from rasterio) (1.1.1)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from rasterio) (3.1.2)\r\n",
      "Downloading rasterio-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: affine, rasterio\r\n",
      "Successfully installed affine-2.4.0 rasterio-1.4.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310317fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:16:56.708956Z",
     "iopub.status.busy": "2024-10-21T06:16:56.707960Z",
     "iopub.status.idle": "2024-10-21T06:17:25.367732Z",
     "shell.execute_reply": "2024-10-21T06:17:25.366490Z"
    },
    "id": "ZXFr-AcONRKa",
    "outputId": "d1f15f7d-f126-4052-9cdc-85087cf6255c",
    "papermill": {
     "duration": 28.681715,
     "end_time": "2024-10-21T06:17:25.370246",
     "exception": false,
     "start_time": "2024-10-21T06:16:56.688531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File unzipped successfully!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your .zip file\n",
    "zip_file_path = '/kaggle/working/brainsegmentation2018-dataset.zip'\n",
    "\n",
    "# Directory where you want to extract the files\n",
    "extract_to_path = '/kaggle/working/'\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(extract_to_path, exist_ok=True)\n",
    "\n",
    "# Unzipping the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)\n",
    "\n",
    "print(\"File unzipped successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b70ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:25.409903Z",
     "iopub.status.busy": "2024-10-21T06:17:25.409514Z",
     "iopub.status.idle": "2024-10-21T06:17:34.581033Z",
     "shell.execute_reply": "2024-10-21T06:17:34.580049Z"
    },
    "id": "VdLNlYsJSGTx",
    "papermill": {
     "duration": 9.193999,
     "end_time": "2024-10-21T06:17:34.583557",
     "exception": false,
     "start_time": "2024-10-21T06:17:25.389558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "from skimage.transform import resize\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1bfa66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:35.477887Z",
     "iopub.status.busy": "2024-10-21T06:17:35.477089Z",
     "iopub.status.idle": "2024-10-21T06:17:35.506926Z",
     "shell.execute_reply": "2024-10-21T06:17:35.505848Z"
    },
    "id": "imeiAoaudXK-",
    "papermill": {
     "duration": 0.081684,
     "end_time": "2024-10-21T06:17:35.510858",
     "exception": false,
     "start_time": "2024-10-21T06:17:35.429174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BrainSegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, patch_size=(48, 240, 240), stride=8, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.patch_size = (64, 64, 16)\n",
    "        self.stride = 16\n",
    "        self.transform = transform\n",
    "        self.patches_img = []\n",
    "        self.patches_mask = []\n",
    "\n",
    "        # Load data and extract patches\n",
    "        self._load_data()\n",
    "        print(f\"Number of image patches: {len(self.patches_img)}\") # Print the number of image patches\n",
    "\n",
    "    def _load_data(self):\n",
    "        for subfolder in os.listdir(self.root_dir):\n",
    "            subfolder_path = os.path.join(self.root_dir, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                pre_dir = os.path.join(subfolder_path, 'pre')\n",
    "                seg_dir = os.path.join(subfolder_path, 'segm.nii')\n",
    "\n",
    "                # Load MRI modalities\n",
    "                t1_path = os.path.join(pre_dir, 'T1.nii/T1.nii')\n",
    "                ir_path = os.path.join(pre_dir, 'IR.nii/IR.nii')\n",
    "                flair_path = os.path.join(pre_dir, 'FLAIR.nii/FLAIR.nii')\n",
    "                seg_path = os.path.join(seg_dir, 'segm.nii')\n",
    "\n",
    "                print(f\"Checking for files in subfolder: {subfolder_path}\") # Print the subfolder being checked\n",
    "                print(f\" - T1 path: {t1_path}\")\n",
    "                print(f\" - IR path: {ir_path}\")\n",
    "                print(f\" - FLAIR path: {flair_path}\")\n",
    "                print(f\" - Segmentation path: {seg_path}\")\n",
    "\n",
    "                # Check if files exist\n",
    "                if not os.path.exists(t1_path):\n",
    "                    print(f\" - T1 file not found: {t1_path}\")\n",
    "                if not os.path.exists(ir_path):\n",
    "                    print(f\" - IR file not found: {ir_path}\")\n",
    "                if not os.path.exists(flair_path):\n",
    "                    print(f\" - FLAIR file not found: {flair_path}\")\n",
    "                if not os.path.exists(seg_path):\n",
    "                    print(f\" - Segmentation file not found: {seg_path}\")\n",
    "                    continue  # Skip to the next subfolder\n",
    "\n",
    "                # Read NIfTI files\n",
    "                try:\n",
    "                    t1_img = nib.load(t1_path).get_fdata()\n",
    "                    ir_img = nib.load(ir_path).get_fdata()\n",
    "                    flair_img = nib.load(flair_path).get_fdata()\n",
    "                    seg_img = nib.load(seg_path).get_fdata()\n",
    "\n",
    "                    # Print shapes after loading images\n",
    "                    print(f\" - T1 shape after loading: {t1_img.shape}\")\n",
    "                    print(f\" - IR shape after loading: {ir_img.shape}\")\n",
    "                    print(f\" - FLAIR shape after loading: {flair_img.shape}\")\n",
    "                    print(f\" - Segmentation shape after loading: {seg_img.shape}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading images from subfolder {subfolder_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Resize the images to the target shape\n",
    "                t1_img = self._resize(t1_img)\n",
    "                ir_img = self._resize(ir_img)\n",
    "                flair_img = self._resize(flair_img)\n",
    "                seg_img = self._resize(seg_img)\n",
    "\n",
    "                print(f\" - T1 shape: {t1_img.shape}\")\n",
    "                print(f\" - IR shape: {ir_img.shape}\")\n",
    "                print(f\" - FLAIR shape: {flair_img.shape}\")\n",
    "                print(f\" - Segmentation shape: {seg_img.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "                # Extract patches\n",
    "                img = np.stack([t1_img, ir_img, flair_img], axis=0)  # Shape: (3, D, H, W)\n",
    "                patches_img, patches_mask = self._extract_patches(img, seg_img)\n",
    "\n",
    "                # Print number of patches extracted\n",
    "                print(f\" - Number of image patches extracted: {len(patches_img)}\")\n",
    "                print(f\" - Number of mask patches extracted: {len(patches_mask)}\")\n",
    "\n",
    "\n",
    "                # Store patches\n",
    "                self.patches_img.extend(patches_img)\n",
    "                self.patches_mask.extend(patches_mask)\n",
    "\n",
    "    def _resize(self, image):\n",
    "        # Resize image to target shape\n",
    "        target_shape = (240, 240, 48)  # For simplicity, you can resize to this shape\n",
    "        return resize(image, target_shape, mode='reflect', anti_aliasing=True)\n",
    "    def _extract_patches(self, image, mask):\n",
    "        patches_img = []\n",
    "        patches_mask = []\n",
    "        _, depth, height, width = image.shape\n",
    "        p_depth, p_height, p_width = self.patch_size\n",
    "\n",
    "        # Check if patch extraction is feasible\n",
    "        if depth < p_depth or height < p_height or width < p_width:\n",
    "            print(f\"Patch size {self.patch_size} is too large for image dimensions {image.shape}.\")\n",
    "            return patches_img, patches_mask\n",
    "\n",
    "        print(f\"Stride: {self.stride}, Patch size: {self.patch_size}\")\n",
    "        print(f\"Depth: {depth}, Height: {height}, Width: {width}\")\n",
    "\n",
    "        # Extract patches\n",
    "        for i in range(0, depth - p_depth + 1, self.stride):\n",
    "            for j in range(0, height - p_height + 1, self.stride):\n",
    "                for k in range(0, width - p_width + 1, self.stride):\n",
    "                    img_patch = image[:, i:i+p_depth, j:j+p_height, k:k+p_width]\n",
    "                    mask_patch = mask[i:i+p_depth, j:j+p_height, k:k+p_width]\n",
    "                    patches_img.append(img_patch)\n",
    "                    patches_mask.append(mask_patch)\n",
    "                    print(f\"Patch extracted: depth {i}, height {j}, width {k}\")\n",
    "\n",
    "        print(f\"Total patches extracted: {len(patches_img)}\")\n",
    "        return np.array(patches_img), np.array(patches_mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches_img)\n",
    "        print(f\"Number of image patches: {len(self.patches_img)}\") # Print the number of image patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.patches_img[idx]\n",
    "        mask = self.patches_mask[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0ff026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:35.625167Z",
     "iopub.status.busy": "2024-10-21T06:17:35.623617Z",
     "iopub.status.idle": "2024-10-21T06:17:35.630547Z",
     "shell.execute_reply": "2024-10-21T06:17:35.629233Z"
    },
    "id": "9KksuYOqWcE0",
    "papermill": {
     "duration": 0.056114,
     "end_time": "2024-10-21T06:17:35.632876",
     "exception": false,
     "start_time": "2024-10-21T06:17:35.576762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c22ae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:35.724673Z",
     "iopub.status.busy": "2024-10-21T06:17:35.723878Z",
     "iopub.status.idle": "2024-10-21T06:17:35.873929Z",
     "shell.execute_reply": "2024-10-21T06:17:35.872799Z"
    },
    "id": "2qWc0NXWWc8S",
    "outputId": "5b600eed-73ab-4db8-bdfd-74e280d49e07",
    "papermill": {
     "duration": 0.205588,
     "end_time": "2024-10-21T06:17:35.876957",
     "exception": false,
     "start_time": "2024-10-21T06:17:35.671369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa65a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:35.971421Z",
     "iopub.status.busy": "2024-10-21T06:17:35.970680Z",
     "iopub.status.idle": "2024-10-21T06:17:35.975623Z",
     "shell.execute_reply": "2024-10-21T06:17:35.974539Z"
    },
    "id": "wT7593kcdurX",
    "papermill": {
     "duration": 0.056569,
     "end_time": "2024-10-21T06:17:35.977795",
     "exception": false,
     "start_time": "2024-10-21T06:17:35.921226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the dataset paths\n",
    "train_data_dir = '/kaggle/working/training_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c817b651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:36.064586Z",
     "iopub.status.busy": "2024-10-21T06:17:36.063271Z",
     "iopub.status.idle": "2024-10-21T06:17:46.959557Z",
     "shell.execute_reply": "2024-10-21T06:17:46.958473Z"
    },
    "id": "4qPBU-JZimYc",
    "outputId": "34b3b908-b483-4f6b-e659-1e2123e382f5",
    "papermill": {
     "duration": 10.947581,
     "end_time": "2024-10-21T06:17:46.961874",
     "exception": false,
     "start_time": "2024-10-21T06:17:36.014293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for files in subfolder: /kaggle/working/training_dataset/29\n",
      " - T1 path: /kaggle/working/training_dataset/29/pre/T1.nii/T1.nii\n",
      " - IR path: /kaggle/working/training_dataset/29/pre/IR.nii/IR.nii\n",
      " - FLAIR path: /kaggle/working/training_dataset/29/pre/FLAIR.nii/FLAIR.nii\n",
      " - Segmentation path: /kaggle/working/training_dataset/29/segm.nii/segm.nii\n",
      " - T1 shape after loading: (256, 256, 192)\n",
      " - IR shape after loading: (240, 240, 48)\n",
      " - FLAIR shape after loading: (240, 240, 48)\n",
      " - Segmentation shape after loading: (240, 240, 48)\n",
      " - T1 shape: (240, 240, 48)\n",
      " - IR shape: (240, 240, 48)\n",
      " - FLAIR shape: (240, 240, 48)\n",
      " - Segmentation shape: (240, 240, 48)\n",
      "Stride: 16, Patch size: (64, 64, 16)\n",
      "Depth: 240, Height: 240, Width: 48\n",
      "Patch extracted: depth 0, height 0, width 0\n",
      "Patch extracted: depth 0, height 0, width 16\n",
      "Patch extracted: depth 0, height 0, width 32\n",
      "Patch extracted: depth 0, height 16, width 0\n",
      "Patch extracted: depth 0, height 16, width 16\n",
      "Patch extracted: depth 0, height 16, width 32\n",
      "Patch extracted: depth 0, height 32, width 0\n",
      "Patch extracted: depth 0, height 32, width 16\n",
      "Patch extracted: depth 0, height 32, width 32\n",
      "Patch extracted: depth 0, height 48, width 0\n",
      "Patch extracted: depth 0, height 48, width 16\n",
      "Patch extracted: depth 0, height 48, width 32\n",
      "Patch extracted: depth 0, height 64, width 0\n",
      "Patch extracted: depth 0, height 64, width 16\n",
      "Patch extracted: depth 0, height 64, width 32\n",
      "Patch extracted: depth 0, height 80, width 0\n",
      "Patch extracted: depth 0, height 80, width 16\n",
      "Patch extracted: depth 0, height 80, width 32\n",
      "Patch extracted: depth 0, height 96, width 0\n",
      "Patch extracted: depth 0, height 96, width 16\n",
      "Patch extracted: depth 0, height 96, width 32\n",
      "Patch extracted: depth 0, height 112, width 0\n",
      "Patch extracted: depth 0, height 112, width 16\n",
      "Patch extracted: depth 0, height 112, width 32\n",
      "Patch extracted: depth 0, height 128, width 0\n",
      "Patch extracted: depth 0, height 128, width 16\n",
      "Patch extracted: depth 0, height 128, width 32\n",
      "Patch extracted: depth 0, height 144, width 0\n",
      "Patch extracted: depth 0, height 144, width 16\n",
      "Patch extracted: depth 0, height 144, width 32\n",
      "Patch extracted: depth 0, height 160, width 0\n",
      "Patch extracted: depth 0, height 160, width 16\n",
      "Patch extracted: depth 0, height 160, width 32\n",
      "Patch extracted: depth 0, height 176, width 0\n",
      "Patch extracted: depth 0, height 176, width 16\n",
      "Patch extracted: depth 0, height 176, width 32\n",
      "Patch extracted: depth 16, height 0, width 0\n",
      "Patch extracted: depth 16, height 0, width 16\n",
      "Patch extracted: depth 16, height 0, width 32\n",
      "Patch extracted: depth 16, height 16, width 0\n",
      "Patch extracted: depth 16, height 16, width 16\n",
      "Patch extracted: depth 16, height 16, width 32\n",
      "Patch extracted: depth 16, height 32, width 0\n",
      "Patch extracted: depth 16, height 32, width 16\n",
      "Patch extracted: depth 16, height 32, width 32\n",
      "Patch extracted: depth 16, height 48, width 0\n",
      "Patch extracted: depth 16, height 48, width 16\n",
      "Patch extracted: depth 16, height 48, width 32\n",
      "Patch extracted: depth 16, height 64, width 0\n",
      "Patch extracted: depth 16, height 64, width 16\n",
      "Patch extracted: depth 16, height 64, width 32\n",
      "Patch extracted: depth 16, height 80, width 0\n",
      "Patch extracted: depth 16, height 80, width 16\n",
      "Patch extracted: depth 16, height 80, width 32\n",
      "Patch extracted: depth 16, height 96, width 0\n",
      "Patch extracted: depth 16, height 96, width 16\n",
      "Patch extracted: depth 16, height 96, width 32\n",
      "Patch extracted: depth 16, height 112, width 0\n",
      "Patch extracted: depth 16, height 112, width 16\n",
      "Patch extracted: depth 16, height 112, width 32\n",
      "Patch extracted: depth 16, height 128, width 0\n",
      "Patch extracted: depth 16, height 128, width 16\n",
      "Patch extracted: depth 16, height 128, width 32\n",
      "Patch extracted: depth 16, height 144, width 0\n",
      "Patch extracted: depth 16, height 144, width 16\n",
      "Patch extracted: depth 16, height 144, width 32\n",
      "Patch extracted: depth 16, height 160, width 0\n",
      "Patch extracted: depth 16, height 160, width 16\n",
      "Patch extracted: depth 16, height 160, width 32\n",
      "Patch extracted: depth 16, height 176, width 0\n",
      "Patch extracted: depth 16, height 176, width 16\n",
      "Patch extracted: depth 16, height 176, width 32\n",
      "Patch extracted: depth 32, height 0, width 0\n",
      "Patch extracted: depth 32, height 0, width 16\n",
      "Patch extracted: depth 32, height 0, width 32\n",
      "Patch extracted: depth 32, height 16, width 0\n",
      "Patch extracted: depth 32, height 16, width 16\n",
      "Patch extracted: depth 32, height 16, width 32\n",
      "Patch extracted: depth 32, height 32, width 0\n",
      "Patch extracted: depth 32, height 32, width 16\n",
      "Patch extracted: depth 32, height 32, width 32\n",
      "Patch extracted: depth 32, height 48, width 0\n",
      "Patch extracted: depth 32, height 48, width 16\n",
      "Patch extracted: depth 32, height 48, width 32\n",
      "Patch extracted: depth 32, height 64, width 0\n",
      "Patch extracted: depth 32, height 64, width 16\n",
      "Patch extracted: depth 32, height 64, width 32\n",
      "Patch extracted: depth 32, height 80, width 0\n",
      "Patch extracted: depth 32, height 80, width 16\n",
      "Patch extracted: depth 32, height 80, width 32\n",
      "Patch extracted: depth 32, height 96, width 0\n",
      "Patch extracted: depth 32, height 96, width 16\n",
      "Patch extracted: depth 32, height 96, width 32\n",
      "Patch extracted: depth 32, height 112, width 0\n",
      "Patch extracted: depth 32, height 112, width 16\n",
      "Patch extracted: depth 32, height 112, width 32\n",
      "Patch extracted: depth 32, height 128, width 0\n",
      "Patch extracted: depth 32, height 128, width 16\n",
      "Patch extracted: depth 32, height 128, width 32\n",
      "Patch extracted: depth 32, height 144, width 0\n",
      "Patch extracted: depth 32, height 144, width 16\n",
      "Patch extracted: depth 32, height 144, width 32\n",
      "Patch extracted: depth 32, height 160, width 0\n",
      "Patch extracted: depth 32, height 160, width 16\n",
      "Patch extracted: depth 32, height 160, width 32\n",
      "Patch extracted: depth 32, height 176, width 0\n",
      "Patch extracted: depth 32, height 176, width 16\n",
      "Patch extracted: depth 32, height 176, width 32\n",
      "Patch extracted: depth 48, height 0, width 0\n",
      "Patch extracted: depth 48, height 0, width 16\n",
      "Patch extracted: depth 48, height 0, width 32\n",
      "Patch extracted: depth 48, height 16, width 0\n",
      "Patch extracted: depth 48, height 16, width 16\n",
      "Patch extracted: depth 48, height 16, width 32\n",
      "Patch extracted: depth 48, height 32, width 0\n",
      "Patch extracted: depth 48, height 32, width 16\n",
      "Patch extracted: depth 48, height 32, width 32\n",
      "Patch extracted: depth 48, height 48, width 0\n",
      "Patch extracted: depth 48, height 48, width 16\n",
      "Patch extracted: depth 48, height 48, width 32\n",
      "Patch extracted: depth 48, height 64, width 0\n",
      "Patch extracted: depth 48, height 64, width 16\n",
      "Patch extracted: depth 48, height 64, width 32\n",
      "Patch extracted: depth 48, height 80, width 0\n",
      "Patch extracted: depth 48, height 80, width 16\n",
      "Patch extracted: depth 48, height 80, width 32\n",
      "Patch extracted: depth 48, height 96, width 0\n",
      "Patch extracted: depth 48, height 96, width 16\n",
      "Patch extracted: depth 48, height 96, width 32\n",
      "Patch extracted: depth 48, height 112, width 0\n",
      "Patch extracted: depth 48, height 112, width 16\n",
      "Patch extracted: depth 48, height 112, width 32\n",
      "Patch extracted: depth 48, height 128, width 0\n",
      "Patch extracted: depth 48, height 128, width 16\n",
      "Patch extracted: depth 48, height 128, width 32\n",
      "Patch extracted: depth 48, height 144, width 0\n",
      "Patch extracted: depth 48, height 144, width 16\n",
      "Patch extracted: depth 48, height 144, width 32\n",
      "Patch extracted: depth 48, height 160, width 0\n",
      "Patch extracted: depth 48, height 160, width 16\n",
      "Patch extracted: depth 48, height 160, width 32\n",
      "Patch extracted: depth 48, height 176, width 0\n",
      "Patch extracted: depth 48, height 176, width 16\n",
      "Patch extracted: depth 48, height 176, width 32\n",
      "Patch extracted: depth 64, height 0, width 0\n",
      "Patch extracted: depth 64, height 0, width 16\n",
      "Patch extracted: depth 64, height 0, width 32\n",
      "Patch extracted: depth 64, height 16, width 0\n",
      "Patch extracted: depth 64, height 16, width 16\n",
      "Patch extracted: depth 64, height 16, width 32\n",
      "Patch extracted: depth 64, height 32, width 0\n",
      "Patch extracted: depth 64, height 32, width 16\n",
      "Patch extracted: depth 64, height 32, width 32\n",
      "Patch extracted: depth 64, height 48, width 0\n",
      "Patch extracted: depth 64, height 48, width 16\n",
      "Patch extracted: depth 64, height 48, width 32\n",
      "Patch extracted: depth 64, height 64, width 0\n",
      "Patch extracted: depth 64, height 64, width 16\n",
      "Patch extracted: depth 64, height 64, width 32\n",
      "Patch extracted: depth 64, height 80, width 0\n",
      "Patch extracted: depth 64, height 80, width 16\n",
      "Patch extracted: depth 64, height 80, width 32\n",
      "Patch extracted: depth 64, height 96, width 0\n",
      "Patch extracted: depth 64, height 96, width 16\n",
      "Patch extracted: depth 64, height 96, width 32\n",
      "Patch extracted: depth 64, height 112, width 0\n",
      "Patch extracted: depth 64, height 112, width 16\n",
      "Patch extracted: depth 64, height 112, width 32\n",
      "Patch extracted: depth 64, height 128, width 0\n",
      "Patch extracted: depth 64, height 128, width 16\n",
      "Patch extracted: depth 64, height 128, width 32\n",
      "Patch extracted: depth 64, height 144, width 0\n",
      "Patch extracted: depth 64, height 144, width 16\n",
      "Patch extracted: depth 64, height 144, width 32\n",
      "Patch extracted: depth 64, height 160, width 0\n",
      "Patch extracted: depth 64, height 160, width 16\n",
      "Patch extracted: depth 64, height 160, width 32\n",
      "Patch extracted: depth 64, height 176, width 0\n",
      "Patch extracted: depth 64, height 176, width 16\n",
      "Patch extracted: depth 64, height 176, width 32\n",
      "Patch extracted: depth 80, height 0, width 0\n",
      "Patch extracted: depth 80, height 0, width 16\n",
      "Patch extracted: depth 80, height 0, width 32\n",
      "Patch extracted: depth 80, height 16, width 0\n",
      "Patch extracted: depth 80, height 16, width 16\n",
      "Patch extracted: depth 80, height 16, width 32\n",
      "Patch extracted: depth 80, height 32, width 0\n",
      "Patch extracted: depth 80, height 32, width 16\n",
      "Patch extracted: depth 80, height 32, width 32\n",
      "Patch extracted: depth 80, height 48, width 0\n",
      "Patch extracted: depth 80, height 48, width 16\n",
      "Patch extracted: depth 80, height 48, width 32\n",
      "Patch extracted: depth 80, height 64, width 0\n",
      "Patch extracted: depth 80, height 64, width 16\n",
      "Patch extracted: depth 80, height 64, width 32\n",
      "Patch extracted: depth 80, height 80, width 0\n",
      "Patch extracted: depth 80, height 80, width 16\n",
      "Patch extracted: depth 80, height 80, width 32\n",
      "Patch extracted: depth 80, height 96, width 0\n",
      "Patch extracted: depth 80, height 96, width 16\n",
      "Patch extracted: depth 80, height 96, width 32\n",
      "Patch extracted: depth 80, height 112, width 0\n",
      "Patch extracted: depth 80, height 112, width 16\n",
      "Patch extracted: depth 80, height 112, width 32\n",
      "Patch extracted: depth 80, height 128, width 0\n",
      "Patch extracted: depth 80, height 128, width 16\n",
      "Patch extracted: depth 80, height 128, width 32\n",
      "Patch extracted: depth 80, height 144, width 0\n",
      "Patch extracted: depth 80, height 144, width 16\n",
      "Patch extracted: depth 80, height 144, width 32\n",
      "Patch extracted: depth 80, height 160, width 0\n",
      "Patch extracted: depth 80, height 160, width 16\n",
      "Patch extracted: depth 80, height 160, width 32\n",
      "Patch extracted: depth 80, height 176, width 0\n",
      "Patch extracted: depth 80, height 176, width 16\n",
      "Patch extracted: depth 80, height 176, width 32\n",
      "Patch extracted: depth 96, height 0, width 0\n",
      "Patch extracted: depth 96, height 0, width 16\n",
      "Patch extracted: depth 96, height 0, width 32\n",
      "Patch extracted: depth 96, height 16, width 0\n",
      "Patch extracted: depth 96, height 16, width 16\n",
      "Patch extracted: depth 96, height 16, width 32\n",
      "Patch extracted: depth 96, height 32, width 0\n",
      "Patch extracted: depth 96, height 32, width 16\n",
      "Patch extracted: depth 96, height 32, width 32\n",
      "Patch extracted: depth 96, height 48, width 0\n",
      "Patch extracted: depth 96, height 48, width 16\n",
      "Patch extracted: depth 96, height 48, width 32\n",
      "Patch extracted: depth 96, height 64, width 0\n",
      "Patch extracted: depth 96, height 64, width 16\n",
      "Patch extracted: depth 96, height 64, width 32\n",
      "Patch extracted: depth 96, height 80, width 0\n",
      "Patch extracted: depth 96, height 80, width 16\n",
      "Patch extracted: depth 96, height 80, width 32\n",
      "Patch extracted: depth 96, height 96, width 0\n",
      "Patch extracted: depth 96, height 96, width 16\n",
      "Patch extracted: depth 96, height 96, width 32\n",
      "Patch extracted: depth 96, height 112, width 0\n",
      "Patch extracted: depth 96, height 112, width 16\n",
      "Patch extracted: depth 96, height 112, width 32\n",
      "Patch extracted: depth 96, height 128, width 0\n",
      "Patch extracted: depth 96, height 128, width 16\n",
      "Patch extracted: depth 96, height 128, width 32\n",
      "Patch extracted: depth 96, height 144, width 0\n",
      "Patch extracted: depth 96, height 144, width 16\n",
      "Patch extracted: depth 96, height 144, width 32\n",
      "Patch extracted: depth 96, height 160, width 0\n",
      "Patch extracted: depth 96, height 160, width 16\n",
      "Patch extracted: depth 96, height 160, width 32\n",
      "Patch extracted: depth 96, height 176, width 0\n",
      "Patch extracted: depth 96, height 176, width 16\n",
      "Patch extracted: depth 96, height 176, width 32\n",
      "Patch extracted: depth 112, height 0, width 0\n",
      "Patch extracted: depth 112, height 0, width 16\n",
      "Patch extracted: depth 112, height 0, width 32\n",
      "Patch extracted: depth 112, height 16, width 0\n",
      "Patch extracted: depth 112, height 16, width 16\n",
      "Patch extracted: depth 112, height 16, width 32\n",
      "Patch extracted: depth 112, height 32, width 0\n",
      "Patch extracted: depth 112, height 32, width 16\n",
      "Patch extracted: depth 112, height 32, width 32\n",
      "Patch extracted: depth 112, height 48, width 0\n",
      "Patch extracted: depth 112, height 48, width 16\n",
      "Patch extracted: depth 112, height 48, width 32\n",
      "Patch extracted: depth 112, height 64, width 0\n",
      "Patch extracted: depth 112, height 64, width 16\n",
      "Patch extracted: depth 112, height 64, width 32\n",
      "Patch extracted: depth 112, height 80, width 0\n",
      "Patch extracted: depth 112, height 80, width 16\n",
      "Patch extracted: depth 112, height 80, width 32\n",
      "Patch extracted: depth 112, height 96, width 0\n",
      "Patch extracted: depth 112, height 96, width 16\n",
      "Patch extracted: depth 112, height 96, width 32\n",
      "Patch extracted: depth 112, height 112, width 0\n",
      "Patch extracted: depth 112, height 112, width 16\n",
      "Patch extracted: depth 112, height 112, width 32\n",
      "Patch extracted: depth 112, height 128, width 0\n",
      "Patch extracted: depth 112, height 128, width 16\n",
      "Patch extracted: depth 112, height 128, width 32\n",
      "Patch extracted: depth 112, height 144, width 0\n",
      "Patch extracted: depth 112, height 144, width 16\n",
      "Patch extracted: depth 112, height 144, width 32\n",
      "Patch extracted: depth 112, height 160, width 0\n",
      "Patch extracted: depth 112, height 160, width 16\n",
      "Patch extracted: depth 112, height 160, width 32\n",
      "Patch extracted: depth 112, height 176, width 0\n",
      "Patch extracted: depth 112, height 176, width 16\n",
      "Patch extracted: depth 112, height 176, width 32\n",
      "Patch extracted: depth 128, height 0, width 0\n",
      "Patch extracted: depth 128, height 0, width 16\n",
      "Patch extracted: depth 128, height 0, width 32\n",
      "Patch extracted: depth 128, height 16, width 0\n",
      "Patch extracted: depth 128, height 16, width 16\n",
      "Patch extracted: depth 128, height 16, width 32\n",
      "Patch extracted: depth 128, height 32, width 0\n",
      "Patch extracted: depth 128, height 32, width 16\n",
      "Patch extracted: depth 128, height 32, width 32\n",
      "Patch extracted: depth 128, height 48, width 0\n",
      "Patch extracted: depth 128, height 48, width 16\n",
      "Patch extracted: depth 128, height 48, width 32\n",
      "Patch extracted: depth 128, height 64, width 0\n",
      "Patch extracted: depth 128, height 64, width 16\n",
      "Patch extracted: depth 128, height 64, width 32\n",
      "Patch extracted: depth 128, height 80, width 0\n",
      "Patch extracted: depth 128, height 80, width 16\n",
      "Patch extracted: depth 128, height 80, width 32\n",
      "Patch extracted: depth 128, height 96, width 0\n",
      "Patch extracted: depth 128, height 96, width 16\n",
      "Patch extracted: depth 128, height 96, width 32\n",
      "Patch extracted: depth 128, height 112, width 0\n",
      "Patch extracted: depth 128, height 112, width 16\n",
      "Patch extracted: depth 128, height 112, width 32\n",
      "Patch extracted: depth 128, height 128, width 0\n",
      "Patch extracted: depth 128, height 128, width 16\n",
      "Patch extracted: depth 128, height 128, width 32\n",
      "Patch extracted: depth 128, height 144, width 0\n",
      "Patch extracted: depth 128, height 144, width 16\n",
      "Patch extracted: depth 128, height 144, width 32\n",
      "Patch extracted: depth 128, height 160, width 0\n",
      "Patch extracted: depth 128, height 160, width 16\n",
      "Patch extracted: depth 128, height 160, width 32\n",
      "Patch extracted: depth 128, height 176, width 0\n",
      "Patch extracted: depth 128, height 176, width 16\n",
      "Patch extracted: depth 128, height 176, width 32\n",
      "Patch extracted: depth 144, height 0, width 0\n",
      "Patch extracted: depth 144, height 0, width 16\n",
      "Patch extracted: depth 144, height 0, width 32\n",
      "Patch extracted: depth 144, height 16, width 0\n",
      "Patch extracted: depth 144, height 16, width 16\n",
      "Patch extracted: depth 144, height 16, width 32\n",
      "Patch extracted: depth 144, height 32, width 0\n",
      "Patch extracted: depth 144, height 32, width 16\n",
      "Patch extracted: depth 144, height 32, width 32\n",
      "Patch extracted: depth 144, height 48, width 0\n",
      "Patch extracted: depth 144, height 48, width 16\n",
      "Patch extracted: depth 144, height 48, width 32\n",
      "Patch extracted: depth 144, height 64, width 0\n",
      "Patch extracted: depth 144, height 64, width 16\n",
      "Patch extracted: depth 144, height 64, width 32\n",
      "Patch extracted: depth 144, height 80, width 0\n",
      "Patch extracted: depth 144, height 80, width 16\n",
      "Patch extracted: depth 144, height 80, width 32\n",
      "Patch extracted: depth 144, height 96, width 0\n",
      "Patch extracted: depth 144, height 96, width 16\n",
      "Patch extracted: depth 144, height 96, width 32\n",
      "Patch extracted: depth 144, height 112, width 0\n",
      "Patch extracted: depth 144, height 112, width 16\n",
      "Patch extracted: depth 144, height 112, width 32\n",
      "Patch extracted: depth 144, height 128, width 0\n",
      "Patch extracted: depth 144, height 128, width 16\n",
      "Patch extracted: depth 144, height 128, width 32\n",
      "Patch extracted: depth 144, height 144, width 0\n",
      "Patch extracted: depth 144, height 144, width 16\n",
      "Patch extracted: depth 144, height 144, width 32\n",
      "Patch extracted: depth 144, height 160, width 0\n",
      "Patch extracted: depth 144, height 160, width 16\n",
      "Patch extracted: depth 144, height 160, width 32\n",
      "Patch extracted: depth 144, height 176, width 0\n",
      "Patch extracted: depth 144, height 176, width 16\n",
      "Patch extracted: depth 144, height 176, width 32\n",
      "Patch extracted: depth 160, height 0, width 0\n",
      "Patch extracted: depth 160, height 0, width 16\n",
      "Patch extracted: depth 160, height 0, width 32\n",
      "Patch extracted: depth 160, height 16, width 0\n",
      "Patch extracted: depth 160, height 16, width 16\n",
      "Patch extracted: depth 160, height 16, width 32\n",
      "Patch extracted: depth 160, height 32, width 0\n",
      "Patch extracted: depth 160, height 32, width 16\n",
      "Patch extracted: depth 160, height 32, width 32\n",
      "Patch extracted: depth 160, height 48, width 0\n",
      "Patch extracted: depth 160, height 48, width 16\n",
      "Patch extracted: depth 160, height 48, width 32\n",
      "Patch extracted: depth 160, height 64, width 0\n",
      "Patch extracted: depth 160, height 64, width 16\n",
      "Patch extracted: depth 160, height 64, width 32\n",
      "Patch extracted: depth 160, height 80, width 0\n",
      "Patch extracted: depth 160, height 80, width 16\n",
      "Patch extracted: depth 160, height 80, width 32\n",
      "Patch extracted: depth 160, height 96, width 0\n",
      "Patch extracted: depth 160, height 96, width 16\n",
      "Patch extracted: depth 160, height 96, width 32\n",
      "Patch extracted: depth 160, height 112, width 0\n",
      "Patch extracted: depth 160, height 112, width 16\n",
      "Patch extracted: depth 160, height 112, width 32\n",
      "Patch extracted: depth 160, height 128, width 0\n",
      "Patch extracted: depth 160, height 128, width 16\n",
      "Patch extracted: depth 160, height 128, width 32\n",
      "Patch extracted: depth 160, height 144, width 0\n",
      "Patch extracted: depth 160, height 144, width 16\n",
      "Patch extracted: depth 160, height 144, width 32\n",
      "Patch extracted: depth 160, height 160, width 0\n",
      "Patch extracted: depth 160, height 160, width 16\n",
      "Patch extracted: depth 160, height 160, width 32\n",
      "Patch extracted: depth 160, height 176, width 0\n",
      "Patch extracted: depth 160, height 176, width 16\n",
      "Patch extracted: depth 160, height 176, width 32\n",
      "Patch extracted: depth 176, height 0, width 0\n",
      "Patch extracted: depth 176, height 0, width 16\n",
      "Patch extracted: depth 176, height 0, width 32\n",
      "Patch extracted: depth 176, height 16, width 0\n",
      "Patch extracted: depth 176, height 16, width 16\n",
      "Patch extracted: depth 176, height 16, width 32\n",
      "Patch extracted: depth 176, height 32, width 0\n",
      "Patch extracted: depth 176, height 32, width 16\n",
      "Patch extracted: depth 176, height 32, width 32\n",
      "Patch extracted: depth 176, height 48, width 0\n",
      "Patch extracted: depth 176, height 48, width 16\n",
      "Patch extracted: depth 176, height 48, width 32\n",
      "Patch extracted: depth 176, height 64, width 0\n",
      "Patch extracted: depth 176, height 64, width 16\n",
      "Patch extracted: depth 176, height 64, width 32\n",
      "Patch extracted: depth 176, height 80, width 0\n",
      "Patch extracted: depth 176, height 80, width 16\n",
      "Patch extracted: depth 176, height 80, width 32\n",
      "Patch extracted: depth 176, height 96, width 0\n",
      "Patch extracted: depth 176, height 96, width 16\n",
      "Patch extracted: depth 176, height 96, width 32\n",
      "Patch extracted: depth 176, height 112, width 0\n",
      "Patch extracted: depth 176, height 112, width 16\n",
      "Patch extracted: depth 176, height 112, width 32\n",
      "Patch extracted: depth 176, height 128, width 0\n",
      "Patch extracted: depth 176, height 128, width 16\n",
      "Patch extracted: depth 176, height 128, width 32\n",
      "Patch extracted: depth 176, height 144, width 0\n",
      "Patch extracted: depth 176, height 144, width 16\n",
      "Patch extracted: depth 176, height 144, width 32\n",
      "Patch extracted: depth 176, height 160, width 0\n",
      "Patch extracted: depth 176, height 160, width 16\n",
      "Patch extracted: depth 176, height 160, width 32\n",
      "Patch extracted: depth 176, height 176, width 0\n",
      "Patch extracted: depth 176, height 176, width 16\n",
      "Patch extracted: depth 176, height 176, width 32\n",
      "Total patches extracted: 432\n",
      " - Number of image patches extracted: 432\n",
      " - Number of mask patches extracted: 432\n",
      "Checking for files in subfolder: /kaggle/working/training_dataset/1\n",
      " - T1 path: /kaggle/working/training_dataset/1/pre/T1.nii/T1.nii\n",
      " - IR path: /kaggle/working/training_dataset/1/pre/IR.nii/IR.nii\n",
      " - FLAIR path: /kaggle/working/training_dataset/1/pre/FLAIR.nii/FLAIR.nii\n",
      " - Segmentation path: /kaggle/working/training_dataset/1/segm.nii/segm.nii\n",
      " - T1 shape after loading: (256, 256, 192)\n",
      " - IR shape after loading: (240, 240, 48)\n",
      " - FLAIR shape after loading: (240, 240, 48)\n",
      " - Segmentation shape after loading: (240, 240, 48)\n",
      " - T1 shape: (240, 240, 48)\n",
      " - IR shape: (240, 240, 48)\n",
      " - FLAIR shape: (240, 240, 48)\n",
      " - Segmentation shape: (240, 240, 48)\n",
      "Stride: 16, Patch size: (64, 64, 16)\n",
      "Depth: 240, Height: 240, Width: 48\n",
      "Patch extracted: depth 0, height 0, width 0\n",
      "Patch extracted: depth 0, height 0, width 16\n",
      "Patch extracted: depth 0, height 0, width 32\n",
      "Patch extracted: depth 0, height 16, width 0\n",
      "Patch extracted: depth 0, height 16, width 16\n",
      "Patch extracted: depth 0, height 16, width 32\n",
      "Patch extracted: depth 0, height 32, width 0\n",
      "Patch extracted: depth 0, height 32, width 16\n",
      "Patch extracted: depth 0, height 32, width 32\n",
      "Patch extracted: depth 0, height 48, width 0\n",
      "Patch extracted: depth 0, height 48, width 16\n",
      "Patch extracted: depth 0, height 48, width 32\n",
      "Patch extracted: depth 0, height 64, width 0\n",
      "Patch extracted: depth 0, height 64, width 16\n",
      "Patch extracted: depth 0, height 64, width 32\n",
      "Patch extracted: depth 0, height 80, width 0\n",
      "Patch extracted: depth 0, height 80, width 16\n",
      "Patch extracted: depth 0, height 80, width 32\n",
      "Patch extracted: depth 0, height 96, width 0\n",
      "Patch extracted: depth 0, height 96, width 16\n",
      "Patch extracted: depth 0, height 96, width 32\n",
      "Patch extracted: depth 0, height 112, width 0\n",
      "Patch extracted: depth 0, height 112, width 16\n",
      "Patch extracted: depth 0, height 112, width 32\n",
      "Patch extracted: depth 0, height 128, width 0\n",
      "Patch extracted: depth 0, height 128, width 16\n",
      "Patch extracted: depth 0, height 128, width 32\n",
      "Patch extracted: depth 0, height 144, width 0\n",
      "Patch extracted: depth 0, height 144, width 16\n",
      "Patch extracted: depth 0, height 144, width 32\n",
      "Patch extracted: depth 0, height 160, width 0\n",
      "Patch extracted: depth 0, height 160, width 16\n",
      "Patch extracted: depth 0, height 160, width 32\n",
      "Patch extracted: depth 0, height 176, width 0\n",
      "Patch extracted: depth 0, height 176, width 16\n",
      "Patch extracted: depth 0, height 176, width 32\n",
      "Patch extracted: depth 16, height 0, width 0\n",
      "Patch extracted: depth 16, height 0, width 16\n",
      "Patch extracted: depth 16, height 0, width 32\n",
      "Patch extracted: depth 16, height 16, width 0\n",
      "Patch extracted: depth 16, height 16, width 16\n",
      "Patch extracted: depth 16, height 16, width 32\n",
      "Patch extracted: depth 16, height 32, width 0\n",
      "Patch extracted: depth 16, height 32, width 16\n",
      "Patch extracted: depth 16, height 32, width 32\n",
      "Patch extracted: depth 16, height 48, width 0\n",
      "Patch extracted: depth 16, height 48, width 16\n",
      "Patch extracted: depth 16, height 48, width 32\n",
      "Patch extracted: depth 16, height 64, width 0\n",
      "Patch extracted: depth 16, height 64, width 16\n",
      "Patch extracted: depth 16, height 64, width 32\n",
      "Patch extracted: depth 16, height 80, width 0\n",
      "Patch extracted: depth 16, height 80, width 16\n",
      "Patch extracted: depth 16, height 80, width 32\n",
      "Patch extracted: depth 16, height 96, width 0\n",
      "Patch extracted: depth 16, height 96, width 16\n",
      "Patch extracted: depth 16, height 96, width 32\n",
      "Patch extracted: depth 16, height 112, width 0\n",
      "Patch extracted: depth 16, height 112, width 16\n",
      "Patch extracted: depth 16, height 112, width 32\n",
      "Patch extracted: depth 16, height 128, width 0\n",
      "Patch extracted: depth 16, height 128, width 16\n",
      "Patch extracted: depth 16, height 128, width 32\n",
      "Patch extracted: depth 16, height 144, width 0\n",
      "Patch extracted: depth 16, height 144, width 16\n",
      "Patch extracted: depth 16, height 144, width 32\n",
      "Patch extracted: depth 16, height 160, width 0\n",
      "Patch extracted: depth 16, height 160, width 16\n",
      "Patch extracted: depth 16, height 160, width 32\n",
      "Patch extracted: depth 16, height 176, width 0\n",
      "Patch extracted: depth 16, height 176, width 16\n",
      "Patch extracted: depth 16, height 176, width 32\n",
      "Patch extracted: depth 32, height 0, width 0\n",
      "Patch extracted: depth 32, height 0, width 16\n",
      "Patch extracted: depth 32, height 0, width 32\n",
      "Patch extracted: depth 32, height 16, width 0\n",
      "Patch extracted: depth 32, height 16, width 16\n",
      "Patch extracted: depth 32, height 16, width 32\n",
      "Patch extracted: depth 32, height 32, width 0\n",
      "Patch extracted: depth 32, height 32, width 16\n",
      "Patch extracted: depth 32, height 32, width 32\n",
      "Patch extracted: depth 32, height 48, width 0\n",
      "Patch extracted: depth 32, height 48, width 16\n",
      "Patch extracted: depth 32, height 48, width 32\n",
      "Patch extracted: depth 32, height 64, width 0\n",
      "Patch extracted: depth 32, height 64, width 16\n",
      "Patch extracted: depth 32, height 64, width 32\n",
      "Patch extracted: depth 32, height 80, width 0\n",
      "Patch extracted: depth 32, height 80, width 16\n",
      "Patch extracted: depth 32, height 80, width 32\n",
      "Patch extracted: depth 32, height 96, width 0\n",
      "Patch extracted: depth 32, height 96, width 16\n",
      "Patch extracted: depth 32, height 96, width 32\n",
      "Patch extracted: depth 32, height 112, width 0\n",
      "Patch extracted: depth 32, height 112, width 16\n",
      "Patch extracted: depth 32, height 112, width 32\n",
      "Patch extracted: depth 32, height 128, width 0\n",
      "Patch extracted: depth 32, height 128, width 16\n",
      "Patch extracted: depth 32, height 128, width 32\n",
      "Patch extracted: depth 32, height 144, width 0\n",
      "Patch extracted: depth 32, height 144, width 16\n",
      "Patch extracted: depth 32, height 144, width 32\n",
      "Patch extracted: depth 32, height 160, width 0\n",
      "Patch extracted: depth 32, height 160, width 16\n",
      "Patch extracted: depth 32, height 160, width 32\n",
      "Patch extracted: depth 32, height 176, width 0\n",
      "Patch extracted: depth 32, height 176, width 16\n",
      "Patch extracted: depth 32, height 176, width 32\n",
      "Patch extracted: depth 48, height 0, width 0\n",
      "Patch extracted: depth 48, height 0, width 16\n",
      "Patch extracted: depth 48, height 0, width 32\n",
      "Patch extracted: depth 48, height 16, width 0\n",
      "Patch extracted: depth 48, height 16, width 16\n",
      "Patch extracted: depth 48, height 16, width 32\n",
      "Patch extracted: depth 48, height 32, width 0\n",
      "Patch extracted: depth 48, height 32, width 16\n",
      "Patch extracted: depth 48, height 32, width 32\n",
      "Patch extracted: depth 48, height 48, width 0\n",
      "Patch extracted: depth 48, height 48, width 16\n",
      "Patch extracted: depth 48, height 48, width 32\n",
      "Patch extracted: depth 48, height 64, width 0\n",
      "Patch extracted: depth 48, height 64, width 16\n",
      "Patch extracted: depth 48, height 64, width 32\n",
      "Patch extracted: depth 48, height 80, width 0\n",
      "Patch extracted: depth 48, height 80, width 16\n",
      "Patch extracted: depth 48, height 80, width 32\n",
      "Patch extracted: depth 48, height 96, width 0\n",
      "Patch extracted: depth 48, height 96, width 16\n",
      "Patch extracted: depth 48, height 96, width 32\n",
      "Patch extracted: depth 48, height 112, width 0\n",
      "Patch extracted: depth 48, height 112, width 16\n",
      "Patch extracted: depth 48, height 112, width 32\n",
      "Patch extracted: depth 48, height 128, width 0\n",
      "Patch extracted: depth 48, height 128, width 16\n",
      "Patch extracted: depth 48, height 128, width 32\n",
      "Patch extracted: depth 48, height 144, width 0\n",
      "Patch extracted: depth 48, height 144, width 16\n",
      "Patch extracted: depth 48, height 144, width 32\n",
      "Patch extracted: depth 48, height 160, width 0\n",
      "Patch extracted: depth 48, height 160, width 16\n",
      "Patch extracted: depth 48, height 160, width 32\n",
      "Patch extracted: depth 48, height 176, width 0\n",
      "Patch extracted: depth 48, height 176, width 16\n",
      "Patch extracted: depth 48, height 176, width 32\n",
      "Patch extracted: depth 64, height 0, width 0\n",
      "Patch extracted: depth 64, height 0, width 16\n",
      "Patch extracted: depth 64, height 0, width 32\n",
      "Patch extracted: depth 64, height 16, width 0\n",
      "Patch extracted: depth 64, height 16, width 16\n",
      "Patch extracted: depth 64, height 16, width 32\n",
      "Patch extracted: depth 64, height 32, width 0\n",
      "Patch extracted: depth 64, height 32, width 16\n",
      "Patch extracted: depth 64, height 32, width 32\n",
      "Patch extracted: depth 64, height 48, width 0\n",
      "Patch extracted: depth 64, height 48, width 16\n",
      "Patch extracted: depth 64, height 48, width 32\n",
      "Patch extracted: depth 64, height 64, width 0\n",
      "Patch extracted: depth 64, height 64, width 16\n",
      "Patch extracted: depth 64, height 64, width 32\n",
      "Patch extracted: depth 64, height 80, width 0\n",
      "Patch extracted: depth 64, height 80, width 16\n",
      "Patch extracted: depth 64, height 80, width 32\n",
      "Patch extracted: depth 64, height 96, width 0\n",
      "Patch extracted: depth 64, height 96, width 16\n",
      "Patch extracted: depth 64, height 96, width 32\n",
      "Patch extracted: depth 64, height 112, width 0\n",
      "Patch extracted: depth 64, height 112, width 16\n",
      "Patch extracted: depth 64, height 112, width 32\n",
      "Patch extracted: depth 64, height 128, width 0\n",
      "Patch extracted: depth 64, height 128, width 16\n",
      "Patch extracted: depth 64, height 128, width 32\n",
      "Patch extracted: depth 64, height 144, width 0\n",
      "Patch extracted: depth 64, height 144, width 16\n",
      "Patch extracted: depth 64, height 144, width 32\n",
      "Patch extracted: depth 64, height 160, width 0\n",
      "Patch extracted: depth 64, height 160, width 16\n",
      "Patch extracted: depth 64, height 160, width 32\n",
      "Patch extracted: depth 64, height 176, width 0\n",
      "Patch extracted: depth 64, height 176, width 16\n",
      "Patch extracted: depth 64, height 176, width 32\n",
      "Patch extracted: depth 80, height 0, width 0\n",
      "Patch extracted: depth 80, height 0, width 16\n",
      "Patch extracted: depth 80, height 0, width 32\n",
      "Patch extracted: depth 80, height 16, width 0\n",
      "Patch extracted: depth 80, height 16, width 16\n",
      "Patch extracted: depth 80, height 16, width 32\n",
      "Patch extracted: depth 80, height 32, width 0\n",
      "Patch extracted: depth 80, height 32, width 16\n",
      "Patch extracted: depth 80, height 32, width 32\n",
      "Patch extracted: depth 80, height 48, width 0\n",
      "Patch extracted: depth 80, height 48, width 16\n",
      "Patch extracted: depth 80, height 48, width 32\n",
      "Patch extracted: depth 80, height 64, width 0\n",
      "Patch extracted: depth 80, height 64, width 16\n",
      "Patch extracted: depth 80, height 64, width 32\n",
      "Patch extracted: depth 80, height 80, width 0\n",
      "Patch extracted: depth 80, height 80, width 16\n",
      "Patch extracted: depth 80, height 80, width 32\n",
      "Patch extracted: depth 80, height 96, width 0\n",
      "Patch extracted: depth 80, height 96, width 16\n",
      "Patch extracted: depth 80, height 96, width 32\n",
      "Patch extracted: depth 80, height 112, width 0\n",
      "Patch extracted: depth 80, height 112, width 16\n",
      "Patch extracted: depth 80, height 112, width 32\n",
      "Patch extracted: depth 80, height 128, width 0\n",
      "Patch extracted: depth 80, height 128, width 16\n",
      "Patch extracted: depth 80, height 128, width 32\n",
      "Patch extracted: depth 80, height 144, width 0\n",
      "Patch extracted: depth 80, height 144, width 16\n",
      "Patch extracted: depth 80, height 144, width 32\n",
      "Patch extracted: depth 80, height 160, width 0\n",
      "Patch extracted: depth 80, height 160, width 16\n",
      "Patch extracted: depth 80, height 160, width 32\n",
      "Patch extracted: depth 80, height 176, width 0\n",
      "Patch extracted: depth 80, height 176, width 16\n",
      "Patch extracted: depth 80, height 176, width 32\n",
      "Patch extracted: depth 96, height 0, width 0\n",
      "Patch extracted: depth 96, height 0, width 16\n",
      "Patch extracted: depth 96, height 0, width 32\n",
      "Patch extracted: depth 96, height 16, width 0\n",
      "Patch extracted: depth 96, height 16, width 16\n",
      "Patch extracted: depth 96, height 16, width 32\n",
      "Patch extracted: depth 96, height 32, width 0\n",
      "Patch extracted: depth 96, height 32, width 16\n",
      "Patch extracted: depth 96, height 32, width 32\n",
      "Patch extracted: depth 96, height 48, width 0\n",
      "Patch extracted: depth 96, height 48, width 16\n",
      "Patch extracted: depth 96, height 48, width 32\n",
      "Patch extracted: depth 96, height 64, width 0\n",
      "Patch extracted: depth 96, height 64, width 16\n",
      "Patch extracted: depth 96, height 64, width 32\n",
      "Patch extracted: depth 96, height 80, width 0\n",
      "Patch extracted: depth 96, height 80, width 16\n",
      "Patch extracted: depth 96, height 80, width 32\n",
      "Patch extracted: depth 96, height 96, width 0\n",
      "Patch extracted: depth 96, height 96, width 16\n",
      "Patch extracted: depth 96, height 96, width 32\n",
      "Patch extracted: depth 96, height 112, width 0\n",
      "Patch extracted: depth 96, height 112, width 16\n",
      "Patch extracted: depth 96, height 112, width 32\n",
      "Patch extracted: depth 96, height 128, width 0\n",
      "Patch extracted: depth 96, height 128, width 16\n",
      "Patch extracted: depth 96, height 128, width 32\n",
      "Patch extracted: depth 96, height 144, width 0\n",
      "Patch extracted: depth 96, height 144, width 16\n",
      "Patch extracted: depth 96, height 144, width 32\n",
      "Patch extracted: depth 96, height 160, width 0\n",
      "Patch extracted: depth 96, height 160, width 16\n",
      "Patch extracted: depth 96, height 160, width 32\n",
      "Patch extracted: depth 96, height 176, width 0\n",
      "Patch extracted: depth 96, height 176, width 16\n",
      "Patch extracted: depth 96, height 176, width 32\n",
      "Patch extracted: depth 112, height 0, width 0\n",
      "Patch extracted: depth 112, height 0, width 16\n",
      "Patch extracted: depth 112, height 0, width 32\n",
      "Patch extracted: depth 112, height 16, width 0\n",
      "Patch extracted: depth 112, height 16, width 16\n",
      "Patch extracted: depth 112, height 16, width 32\n",
      "Patch extracted: depth 112, height 32, width 0\n",
      "Patch extracted: depth 112, height 32, width 16\n",
      "Patch extracted: depth 112, height 32, width 32\n",
      "Patch extracted: depth 112, height 48, width 0\n",
      "Patch extracted: depth 112, height 48, width 16\n",
      "Patch extracted: depth 112, height 48, width 32\n",
      "Patch extracted: depth 112, height 64, width 0\n",
      "Patch extracted: depth 112, height 64, width 16\n",
      "Patch extracted: depth 112, height 64, width 32\n",
      "Patch extracted: depth 112, height 80, width 0\n",
      "Patch extracted: depth 112, height 80, width 16\n",
      "Patch extracted: depth 112, height 80, width 32\n",
      "Patch extracted: depth 112, height 96, width 0\n",
      "Patch extracted: depth 112, height 96, width 16\n",
      "Patch extracted: depth 112, height 96, width 32\n",
      "Patch extracted: depth 112, height 112, width 0\n",
      "Patch extracted: depth 112, height 112, width 16\n",
      "Patch extracted: depth 112, height 112, width 32\n",
      "Patch extracted: depth 112, height 128, width 0\n",
      "Patch extracted: depth 112, height 128, width 16\n",
      "Patch extracted: depth 112, height 128, width 32\n",
      "Patch extracted: depth 112, height 144, width 0\n",
      "Patch extracted: depth 112, height 144, width 16\n",
      "Patch extracted: depth 112, height 144, width 32\n",
      "Patch extracted: depth 112, height 160, width 0\n",
      "Patch extracted: depth 112, height 160, width 16\n",
      "Patch extracted: depth 112, height 160, width 32\n",
      "Patch extracted: depth 112, height 176, width 0\n",
      "Patch extracted: depth 112, height 176, width 16\n",
      "Patch extracted: depth 112, height 176, width 32\n",
      "Patch extracted: depth 128, height 0, width 0\n",
      "Patch extracted: depth 128, height 0, width 16\n",
      "Patch extracted: depth 128, height 0, width 32\n",
      "Patch extracted: depth 128, height 16, width 0\n",
      "Patch extracted: depth 128, height 16, width 16\n",
      "Patch extracted: depth 128, height 16, width 32\n",
      "Patch extracted: depth 128, height 32, width 0\n",
      "Patch extracted: depth 128, height 32, width 16\n",
      "Patch extracted: depth 128, height 32, width 32\n",
      "Patch extracted: depth 128, height 48, width 0\n",
      "Patch extracted: depth 128, height 48, width 16\n",
      "Patch extracted: depth 128, height 48, width 32\n",
      "Patch extracted: depth 128, height 64, width 0\n",
      "Patch extracted: depth 128, height 64, width 16\n",
      "Patch extracted: depth 128, height 64, width 32\n",
      "Patch extracted: depth 128, height 80, width 0\n",
      "Patch extracted: depth 128, height 80, width 16\n",
      "Patch extracted: depth 128, height 80, width 32\n",
      "Patch extracted: depth 128, height 96, width 0\n",
      "Patch extracted: depth 128, height 96, width 16\n",
      "Patch extracted: depth 128, height 96, width 32\n",
      "Patch extracted: depth 128, height 112, width 0\n",
      "Patch extracted: depth 128, height 112, width 16\n",
      "Patch extracted: depth 128, height 112, width 32\n",
      "Patch extracted: depth 128, height 128, width 0\n",
      "Patch extracted: depth 128, height 128, width 16\n",
      "Patch extracted: depth 128, height 128, width 32\n",
      "Patch extracted: depth 128, height 144, width 0\n",
      "Patch extracted: depth 128, height 144, width 16\n",
      "Patch extracted: depth 128, height 144, width 32\n",
      "Patch extracted: depth 128, height 160, width 0\n",
      "Patch extracted: depth 128, height 160, width 16\n",
      "Patch extracted: depth 128, height 160, width 32\n",
      "Patch extracted: depth 128, height 176, width 0\n",
      "Patch extracted: depth 128, height 176, width 16\n",
      "Patch extracted: depth 128, height 176, width 32\n",
      "Patch extracted: depth 144, height 0, width 0\n",
      "Patch extracted: depth 144, height 0, width 16\n",
      "Patch extracted: depth 144, height 0, width 32\n",
      "Patch extracted: depth 144, height 16, width 0\n",
      "Patch extracted: depth 144, height 16, width 16\n",
      "Patch extracted: depth 144, height 16, width 32\n",
      "Patch extracted: depth 144, height 32, width 0\n",
      "Patch extracted: depth 144, height 32, width 16\n",
      "Patch extracted: depth 144, height 32, width 32\n",
      "Patch extracted: depth 144, height 48, width 0\n",
      "Patch extracted: depth 144, height 48, width 16\n",
      "Patch extracted: depth 144, height 48, width 32\n",
      "Patch extracted: depth 144, height 64, width 0\n",
      "Patch extracted: depth 144, height 64, width 16\n",
      "Patch extracted: depth 144, height 64, width 32\n",
      "Patch extracted: depth 144, height 80, width 0\n",
      "Patch extracted: depth 144, height 80, width 16\n",
      "Patch extracted: depth 144, height 80, width 32\n",
      "Patch extracted: depth 144, height 96, width 0\n",
      "Patch extracted: depth 144, height 96, width 16\n",
      "Patch extracted: depth 144, height 96, width 32\n",
      "Patch extracted: depth 144, height 112, width 0\n",
      "Patch extracted: depth 144, height 112, width 16\n",
      "Patch extracted: depth 144, height 112, width 32\n",
      "Patch extracted: depth 144, height 128, width 0\n",
      "Patch extracted: depth 144, height 128, width 16\n",
      "Patch extracted: depth 144, height 128, width 32\n",
      "Patch extracted: depth 144, height 144, width 0\n",
      "Patch extracted: depth 144, height 144, width 16\n",
      "Patch extracted: depth 144, height 144, width 32\n",
      "Patch extracted: depth 144, height 160, width 0\n",
      "Patch extracted: depth 144, height 160, width 16\n",
      "Patch extracted: depth 144, height 160, width 32\n",
      "Patch extracted: depth 144, height 176, width 0\n",
      "Patch extracted: depth 144, height 176, width 16\n",
      "Patch extracted: depth 144, height 176, width 32\n",
      "Patch extracted: depth 160, height 0, width 0\n",
      "Patch extracted: depth 160, height 0, width 16\n",
      "Patch extracted: depth 160, height 0, width 32\n",
      "Patch extracted: depth 160, height 16, width 0\n",
      "Patch extracted: depth 160, height 16, width 16\n",
      "Patch extracted: depth 160, height 16, width 32\n",
      "Patch extracted: depth 160, height 32, width 0\n",
      "Patch extracted: depth 160, height 32, width 16\n",
      "Patch extracted: depth 160, height 32, width 32\n",
      "Patch extracted: depth 160, height 48, width 0\n",
      "Patch extracted: depth 160, height 48, width 16\n",
      "Patch extracted: depth 160, height 48, width 32\n",
      "Patch extracted: depth 160, height 64, width 0\n",
      "Patch extracted: depth 160, height 64, width 16\n",
      "Patch extracted: depth 160, height 64, width 32\n",
      "Patch extracted: depth 160, height 80, width 0\n",
      "Patch extracted: depth 160, height 80, width 16\n",
      "Patch extracted: depth 160, height 80, width 32\n",
      "Patch extracted: depth 160, height 96, width 0\n",
      "Patch extracted: depth 160, height 96, width 16\n",
      "Patch extracted: depth 160, height 96, width 32\n",
      "Patch extracted: depth 160, height 112, width 0\n",
      "Patch extracted: depth 160, height 112, width 16\n",
      "Patch extracted: depth 160, height 112, width 32\n",
      "Patch extracted: depth 160, height 128, width 0\n",
      "Patch extracted: depth 160, height 128, width 16\n",
      "Patch extracted: depth 160, height 128, width 32\n",
      "Patch extracted: depth 160, height 144, width 0\n",
      "Patch extracted: depth 160, height 144, width 16\n",
      "Patch extracted: depth 160, height 144, width 32\n",
      "Patch extracted: depth 160, height 160, width 0\n",
      "Patch extracted: depth 160, height 160, width 16\n",
      "Patch extracted: depth 160, height 160, width 32\n",
      "Patch extracted: depth 160, height 176, width 0\n",
      "Patch extracted: depth 160, height 176, width 16\n",
      "Patch extracted: depth 160, height 176, width 32\n",
      "Patch extracted: depth 176, height 0, width 0\n",
      "Patch extracted: depth 176, height 0, width 16\n",
      "Patch extracted: depth 176, height 0, width 32\n",
      "Patch extracted: depth 176, height 16, width 0\n",
      "Patch extracted: depth 176, height 16, width 16\n",
      "Patch extracted: depth 176, height 16, width 32\n",
      "Patch extracted: depth 176, height 32, width 0\n",
      "Patch extracted: depth 176, height 32, width 16\n",
      "Patch extracted: depth 176, height 32, width 32\n",
      "Patch extracted: depth 176, height 48, width 0\n",
      "Patch extracted: depth 176, height 48, width 16\n",
      "Patch extracted: depth 176, height 48, width 32\n",
      "Patch extracted: depth 176, height 64, width 0\n",
      "Patch extracted: depth 176, height 64, width 16\n",
      "Patch extracted: depth 176, height 64, width 32\n",
      "Patch extracted: depth 176, height 80, width 0\n",
      "Patch extracted: depth 176, height 80, width 16\n",
      "Patch extracted: depth 176, height 80, width 32\n",
      "Patch extracted: depth 176, height 96, width 0\n",
      "Patch extracted: depth 176, height 96, width 16\n",
      "Patch extracted: depth 176, height 96, width 32\n",
      "Patch extracted: depth 176, height 112, width 0\n",
      "Patch extracted: depth 176, height 112, width 16\n",
      "Patch extracted: depth 176, height 112, width 32\n",
      "Patch extracted: depth 176, height 128, width 0\n",
      "Patch extracted: depth 176, height 128, width 16\n",
      "Patch extracted: depth 176, height 128, width 32\n",
      "Patch extracted: depth 176, height 144, width 0\n",
      "Patch extracted: depth 176, height 144, width 16\n",
      "Patch extracted: depth 176, height 144, width 32\n",
      "Patch extracted: depth 176, height 160, width 0\n",
      "Patch extracted: depth 176, height 160, width 16\n",
      "Patch extracted: depth 176, height 160, width 32\n",
      "Patch extracted: depth 176, height 176, width 0\n",
      "Patch extracted: depth 176, height 176, width 16\n",
      "Patch extracted: depth 176, height 176, width 32\n",
      "Total patches extracted: 432\n",
      " - Number of image patches extracted: 432\n",
      " - Number of mask patches extracted: 432\n",
      "Checking for files in subfolder: /kaggle/working/training_dataset/27\n",
      " - T1 path: /kaggle/working/training_dataset/27/pre/T1.nii/T1.nii\n",
      " - IR path: /kaggle/working/training_dataset/27/pre/IR.nii/IR.nii\n",
      " - FLAIR path: /kaggle/working/training_dataset/27/pre/FLAIR.nii/FLAIR.nii\n",
      " - Segmentation path: /kaggle/working/training_dataset/27/segm.nii/segm.nii\n",
      " - T1 shape after loading: (256, 256, 192)\n",
      " - IR shape after loading: (240, 240, 48)\n",
      " - FLAIR shape after loading: (240, 240, 48)\n",
      " - Segmentation shape after loading: (240, 240, 48)\n",
      " - T1 shape: (240, 240, 48)\n",
      " - IR shape: (240, 240, 48)\n",
      " - FLAIR shape: (240, 240, 48)\n",
      " - Segmentation shape: (240, 240, 48)\n",
      "Stride: 16, Patch size: (64, 64, 16)\n",
      "Depth: 240, Height: 240, Width: 48\n",
      "Patch extracted: depth 0, height 0, width 0\n",
      "Patch extracted: depth 0, height 0, width 16\n",
      "Patch extracted: depth 0, height 0, width 32\n",
      "Patch extracted: depth 0, height 16, width 0\n",
      "Patch extracted: depth 0, height 16, width 16\n",
      "Patch extracted: depth 0, height 16, width 32\n",
      "Patch extracted: depth 0, height 32, width 0\n",
      "Patch extracted: depth 0, height 32, width 16\n",
      "Patch extracted: depth 0, height 32, width 32\n",
      "Patch extracted: depth 0, height 48, width 0\n",
      "Patch extracted: depth 0, height 48, width 16\n",
      "Patch extracted: depth 0, height 48, width 32\n",
      "Patch extracted: depth 0, height 64, width 0\n",
      "Patch extracted: depth 0, height 64, width 16\n",
      "Patch extracted: depth 0, height 64, width 32\n",
      "Patch extracted: depth 0, height 80, width 0\n",
      "Patch extracted: depth 0, height 80, width 16\n",
      "Patch extracted: depth 0, height 80, width 32\n",
      "Patch extracted: depth 0, height 96, width 0\n",
      "Patch extracted: depth 0, height 96, width 16\n",
      "Patch extracted: depth 0, height 96, width 32\n",
      "Patch extracted: depth 0, height 112, width 0\n",
      "Patch extracted: depth 0, height 112, width 16\n",
      "Patch extracted: depth 0, height 112, width 32\n",
      "Patch extracted: depth 0, height 128, width 0\n",
      "Patch extracted: depth 0, height 128, width 16\n",
      "Patch extracted: depth 0, height 128, width 32\n",
      "Patch extracted: depth 0, height 144, width 0\n",
      "Patch extracted: depth 0, height 144, width 16\n",
      "Patch extracted: depth 0, height 144, width 32\n",
      "Patch extracted: depth 0, height 160, width 0\n",
      "Patch extracted: depth 0, height 160, width 16\n",
      "Patch extracted: depth 0, height 160, width 32\n",
      "Patch extracted: depth 0, height 176, width 0\n",
      "Patch extracted: depth 0, height 176, width 16\n",
      "Patch extracted: depth 0, height 176, width 32\n",
      "Patch extracted: depth 16, height 0, width 0\n",
      "Patch extracted: depth 16, height 0, width 16\n",
      "Patch extracted: depth 16, height 0, width 32\n",
      "Patch extracted: depth 16, height 16, width 0\n",
      "Patch extracted: depth 16, height 16, width 16\n",
      "Patch extracted: depth 16, height 16, width 32\n",
      "Patch extracted: depth 16, height 32, width 0\n",
      "Patch extracted: depth 16, height 32, width 16\n",
      "Patch extracted: depth 16, height 32, width 32\n",
      "Patch extracted: depth 16, height 48, width 0\n",
      "Patch extracted: depth 16, height 48, width 16\n",
      "Patch extracted: depth 16, height 48, width 32\n",
      "Patch extracted: depth 16, height 64, width 0\n",
      "Patch extracted: depth 16, height 64, width 16\n",
      "Patch extracted: depth 16, height 64, width 32\n",
      "Patch extracted: depth 16, height 80, width 0\n",
      "Patch extracted: depth 16, height 80, width 16\n",
      "Patch extracted: depth 16, height 80, width 32\n",
      "Patch extracted: depth 16, height 96, width 0\n",
      "Patch extracted: depth 16, height 96, width 16\n",
      "Patch extracted: depth 16, height 96, width 32\n",
      "Patch extracted: depth 16, height 112, width 0\n",
      "Patch extracted: depth 16, height 112, width 16\n",
      "Patch extracted: depth 16, height 112, width 32\n",
      "Patch extracted: depth 16, height 128, width 0\n",
      "Patch extracted: depth 16, height 128, width 16\n",
      "Patch extracted: depth 16, height 128, width 32\n",
      "Patch extracted: depth 16, height 144, width 0\n",
      "Patch extracted: depth 16, height 144, width 16\n",
      "Patch extracted: depth 16, height 144, width 32\n",
      "Patch extracted: depth 16, height 160, width 0\n",
      "Patch extracted: depth 16, height 160, width 16\n",
      "Patch extracted: depth 16, height 160, width 32\n",
      "Patch extracted: depth 16, height 176, width 0\n",
      "Patch extracted: depth 16, height 176, width 16\n",
      "Patch extracted: depth 16, height 176, width 32\n",
      "Patch extracted: depth 32, height 0, width 0\n",
      "Patch extracted: depth 32, height 0, width 16\n",
      "Patch extracted: depth 32, height 0, width 32\n",
      "Patch extracted: depth 32, height 16, width 0\n",
      "Patch extracted: depth 32, height 16, width 16\n",
      "Patch extracted: depth 32, height 16, width 32\n",
      "Patch extracted: depth 32, height 32, width 0\n",
      "Patch extracted: depth 32, height 32, width 16\n",
      "Patch extracted: depth 32, height 32, width 32\n",
      "Patch extracted: depth 32, height 48, width 0\n",
      "Patch extracted: depth 32, height 48, width 16\n",
      "Patch extracted: depth 32, height 48, width 32\n",
      "Patch extracted: depth 32, height 64, width 0\n",
      "Patch extracted: depth 32, height 64, width 16\n",
      "Patch extracted: depth 32, height 64, width 32\n",
      "Patch extracted: depth 32, height 80, width 0\n",
      "Patch extracted: depth 32, height 80, width 16\n",
      "Patch extracted: depth 32, height 80, width 32\n",
      "Patch extracted: depth 32, height 96, width 0\n",
      "Patch extracted: depth 32, height 96, width 16\n",
      "Patch extracted: depth 32, height 96, width 32\n",
      "Patch extracted: depth 32, height 112, width 0\n",
      "Patch extracted: depth 32, height 112, width 16\n",
      "Patch extracted: depth 32, height 112, width 32\n",
      "Patch extracted: depth 32, height 128, width 0\n",
      "Patch extracted: depth 32, height 128, width 16\n",
      "Patch extracted: depth 32, height 128, width 32\n",
      "Patch extracted: depth 32, height 144, width 0\n",
      "Patch extracted: depth 32, height 144, width 16\n",
      "Patch extracted: depth 32, height 144, width 32\n",
      "Patch extracted: depth 32, height 160, width 0\n",
      "Patch extracted: depth 32, height 160, width 16\n",
      "Patch extracted: depth 32, height 160, width 32\n",
      "Patch extracted: depth 32, height 176, width 0\n",
      "Patch extracted: depth 32, height 176, width 16\n",
      "Patch extracted: depth 32, height 176, width 32\n",
      "Patch extracted: depth 48, height 0, width 0\n",
      "Patch extracted: depth 48, height 0, width 16\n",
      "Patch extracted: depth 48, height 0, width 32\n",
      "Patch extracted: depth 48, height 16, width 0\n",
      "Patch extracted: depth 48, height 16, width 16\n",
      "Patch extracted: depth 48, height 16, width 32\n",
      "Patch extracted: depth 48, height 32, width 0\n",
      "Patch extracted: depth 48, height 32, width 16\n",
      "Patch extracted: depth 48, height 32, width 32\n",
      "Patch extracted: depth 48, height 48, width 0\n",
      "Patch extracted: depth 48, height 48, width 16\n",
      "Patch extracted: depth 48, height 48, width 32\n",
      "Patch extracted: depth 48, height 64, width 0\n",
      "Patch extracted: depth 48, height 64, width 16\n",
      "Patch extracted: depth 48, height 64, width 32\n",
      "Patch extracted: depth 48, height 80, width 0\n",
      "Patch extracted: depth 48, height 80, width 16\n",
      "Patch extracted: depth 48, height 80, width 32\n",
      "Patch extracted: depth 48, height 96, width 0\n",
      "Patch extracted: depth 48, height 96, width 16\n",
      "Patch extracted: depth 48, height 96, width 32\n",
      "Patch extracted: depth 48, height 112, width 0\n",
      "Patch extracted: depth 48, height 112, width 16\n",
      "Patch extracted: depth 48, height 112, width 32\n",
      "Patch extracted: depth 48, height 128, width 0\n",
      "Patch extracted: depth 48, height 128, width 16\n",
      "Patch extracted: depth 48, height 128, width 32\n",
      "Patch extracted: depth 48, height 144, width 0\n",
      "Patch extracted: depth 48, height 144, width 16\n",
      "Patch extracted: depth 48, height 144, width 32\n",
      "Patch extracted: depth 48, height 160, width 0\n",
      "Patch extracted: depth 48, height 160, width 16\n",
      "Patch extracted: depth 48, height 160, width 32\n",
      "Patch extracted: depth 48, height 176, width 0\n",
      "Patch extracted: depth 48, height 176, width 16\n",
      "Patch extracted: depth 48, height 176, width 32\n",
      "Patch extracted: depth 64, height 0, width 0\n",
      "Patch extracted: depth 64, height 0, width 16\n",
      "Patch extracted: depth 64, height 0, width 32\n",
      "Patch extracted: depth 64, height 16, width 0\n",
      "Patch extracted: depth 64, height 16, width 16\n",
      "Patch extracted: depth 64, height 16, width 32\n",
      "Patch extracted: depth 64, height 32, width 0\n",
      "Patch extracted: depth 64, height 32, width 16\n",
      "Patch extracted: depth 64, height 32, width 32\n",
      "Patch extracted: depth 64, height 48, width 0\n",
      "Patch extracted: depth 64, height 48, width 16\n",
      "Patch extracted: depth 64, height 48, width 32\n",
      "Patch extracted: depth 64, height 64, width 0\n",
      "Patch extracted: depth 64, height 64, width 16\n",
      "Patch extracted: depth 64, height 64, width 32\n",
      "Patch extracted: depth 64, height 80, width 0\n",
      "Patch extracted: depth 64, height 80, width 16\n",
      "Patch extracted: depth 64, height 80, width 32\n",
      "Patch extracted: depth 64, height 96, width 0\n",
      "Patch extracted: depth 64, height 96, width 16\n",
      "Patch extracted: depth 64, height 96, width 32\n",
      "Patch extracted: depth 64, height 112, width 0\n",
      "Patch extracted: depth 64, height 112, width 16\n",
      "Patch extracted: depth 64, height 112, width 32\n",
      "Patch extracted: depth 64, height 128, width 0\n",
      "Patch extracted: depth 64, height 128, width 16\n",
      "Patch extracted: depth 64, height 128, width 32\n",
      "Patch extracted: depth 64, height 144, width 0\n",
      "Patch extracted: depth 64, height 144, width 16\n",
      "Patch extracted: depth 64, height 144, width 32\n",
      "Patch extracted: depth 64, height 160, width 0\n",
      "Patch extracted: depth 64, height 160, width 16\n",
      "Patch extracted: depth 64, height 160, width 32\n",
      "Patch extracted: depth 64, height 176, width 0\n",
      "Patch extracted: depth 64, height 176, width 16\n",
      "Patch extracted: depth 64, height 176, width 32\n",
      "Patch extracted: depth 80, height 0, width 0\n",
      "Patch extracted: depth 80, height 0, width 16\n",
      "Patch extracted: depth 80, height 0, width 32\n",
      "Patch extracted: depth 80, height 16, width 0\n",
      "Patch extracted: depth 80, height 16, width 16\n",
      "Patch extracted: depth 80, height 16, width 32\n",
      "Patch extracted: depth 80, height 32, width 0\n",
      "Patch extracted: depth 80, height 32, width 16\n",
      "Patch extracted: depth 80, height 32, width 32\n",
      "Patch extracted: depth 80, height 48, width 0\n",
      "Patch extracted: depth 80, height 48, width 16\n",
      "Patch extracted: depth 80, height 48, width 32\n",
      "Patch extracted: depth 80, height 64, width 0\n",
      "Patch extracted: depth 80, height 64, width 16\n",
      "Patch extracted: depth 80, height 64, width 32\n",
      "Patch extracted: depth 80, height 80, width 0\n",
      "Patch extracted: depth 80, height 80, width 16\n",
      "Patch extracted: depth 80, height 80, width 32\n",
      "Patch extracted: depth 80, height 96, width 0\n",
      "Patch extracted: depth 80, height 96, width 16\n",
      "Patch extracted: depth 80, height 96, width 32\n",
      "Patch extracted: depth 80, height 112, width 0\n",
      "Patch extracted: depth 80, height 112, width 16\n",
      "Patch extracted: depth 80, height 112, width 32\n",
      "Patch extracted: depth 80, height 128, width 0\n",
      "Patch extracted: depth 80, height 128, width 16\n",
      "Patch extracted: depth 80, height 128, width 32\n",
      "Patch extracted: depth 80, height 144, width 0\n",
      "Patch extracted: depth 80, height 144, width 16\n",
      "Patch extracted: depth 80, height 144, width 32\n",
      "Patch extracted: depth 80, height 160, width 0\n",
      "Patch extracted: depth 80, height 160, width 16\n",
      "Patch extracted: depth 80, height 160, width 32\n",
      "Patch extracted: depth 80, height 176, width 0\n",
      "Patch extracted: depth 80, height 176, width 16\n",
      "Patch extracted: depth 80, height 176, width 32\n",
      "Patch extracted: depth 96, height 0, width 0\n",
      "Patch extracted: depth 96, height 0, width 16\n",
      "Patch extracted: depth 96, height 0, width 32\n",
      "Patch extracted: depth 96, height 16, width 0\n",
      "Patch extracted: depth 96, height 16, width 16\n",
      "Patch extracted: depth 96, height 16, width 32\n",
      "Patch extracted: depth 96, height 32, width 0\n",
      "Patch extracted: depth 96, height 32, width 16\n",
      "Patch extracted: depth 96, height 32, width 32\n",
      "Patch extracted: depth 96, height 48, width 0\n",
      "Patch extracted: depth 96, height 48, width 16\n",
      "Patch extracted: depth 96, height 48, width 32\n",
      "Patch extracted: depth 96, height 64, width 0\n",
      "Patch extracted: depth 96, height 64, width 16\n",
      "Patch extracted: depth 96, height 64, width 32\n",
      "Patch extracted: depth 96, height 80, width 0\n",
      "Patch extracted: depth 96, height 80, width 16\n",
      "Patch extracted: depth 96, height 80, width 32\n",
      "Patch extracted: depth 96, height 96, width 0\n",
      "Patch extracted: depth 96, height 96, width 16\n",
      "Patch extracted: depth 96, height 96, width 32\n",
      "Patch extracted: depth 96, height 112, width 0\n",
      "Patch extracted: depth 96, height 112, width 16\n",
      "Patch extracted: depth 96, height 112, width 32\n",
      "Patch extracted: depth 96, height 128, width 0\n",
      "Patch extracted: depth 96, height 128, width 16\n",
      "Patch extracted: depth 96, height 128, width 32\n",
      "Patch extracted: depth 96, height 144, width 0\n",
      "Patch extracted: depth 96, height 144, width 16\n",
      "Patch extracted: depth 96, height 144, width 32\n",
      "Patch extracted: depth 96, height 160, width 0\n",
      "Patch extracted: depth 96, height 160, width 16\n",
      "Patch extracted: depth 96, height 160, width 32\n",
      "Patch extracted: depth 96, height 176, width 0\n",
      "Patch extracted: depth 96, height 176, width 16\n",
      "Patch extracted: depth 96, height 176, width 32\n",
      "Patch extracted: depth 112, height 0, width 0\n",
      "Patch extracted: depth 112, height 0, width 16\n",
      "Patch extracted: depth 112, height 0, width 32\n",
      "Patch extracted: depth 112, height 16, width 0\n",
      "Patch extracted: depth 112, height 16, width 16\n",
      "Patch extracted: depth 112, height 16, width 32\n",
      "Patch extracted: depth 112, height 32, width 0\n",
      "Patch extracted: depth 112, height 32, width 16\n",
      "Patch extracted: depth 112, height 32, width 32\n",
      "Patch extracted: depth 112, height 48, width 0\n",
      "Patch extracted: depth 112, height 48, width 16\n",
      "Patch extracted: depth 112, height 48, width 32\n",
      "Patch extracted: depth 112, height 64, width 0\n",
      "Patch extracted: depth 112, height 64, width 16\n",
      "Patch extracted: depth 112, height 64, width 32\n",
      "Patch extracted: depth 112, height 80, width 0\n",
      "Patch extracted: depth 112, height 80, width 16\n",
      "Patch extracted: depth 112, height 80, width 32\n",
      "Patch extracted: depth 112, height 96, width 0\n",
      "Patch extracted: depth 112, height 96, width 16\n",
      "Patch extracted: depth 112, height 96, width 32\n",
      "Patch extracted: depth 112, height 112, width 0\n",
      "Patch extracted: depth 112, height 112, width 16\n",
      "Patch extracted: depth 112, height 112, width 32\n",
      "Patch extracted: depth 112, height 128, width 0\n",
      "Patch extracted: depth 112, height 128, width 16\n",
      "Patch extracted: depth 112, height 128, width 32\n",
      "Patch extracted: depth 112, height 144, width 0\n",
      "Patch extracted: depth 112, height 144, width 16\n",
      "Patch extracted: depth 112, height 144, width 32\n",
      "Patch extracted: depth 112, height 160, width 0\n",
      "Patch extracted: depth 112, height 160, width 16\n",
      "Patch extracted: depth 112, height 160, width 32\n",
      "Patch extracted: depth 112, height 176, width 0\n",
      "Patch extracted: depth 112, height 176, width 16\n",
      "Patch extracted: depth 112, height 176, width 32\n",
      "Patch extracted: depth 128, height 0, width 0\n",
      "Patch extracted: depth 128, height 0, width 16\n",
      "Patch extracted: depth 128, height 0, width 32\n",
      "Patch extracted: depth 128, height 16, width 0\n",
      "Patch extracted: depth 128, height 16, width 16\n",
      "Patch extracted: depth 128, height 16, width 32\n",
      "Patch extracted: depth 128, height 32, width 0\n",
      "Patch extracted: depth 128, height 32, width 16\n",
      "Patch extracted: depth 128, height 32, width 32\n",
      "Patch extracted: depth 128, height 48, width 0\n",
      "Patch extracted: depth 128, height 48, width 16\n",
      "Patch extracted: depth 128, height 48, width 32\n",
      "Patch extracted: depth 128, height 64, width 0\n",
      "Patch extracted: depth 128, height 64, width 16\n",
      "Patch extracted: depth 128, height 64, width 32\n",
      "Patch extracted: depth 128, height 80, width 0\n",
      "Patch extracted: depth 128, height 80, width 16\n",
      "Patch extracted: depth 128, height 80, width 32\n",
      "Patch extracted: depth 128, height 96, width 0\n",
      "Patch extracted: depth 128, height 96, width 16\n",
      "Patch extracted: depth 128, height 96, width 32\n",
      "Patch extracted: depth 128, height 112, width 0\n",
      "Patch extracted: depth 128, height 112, width 16\n",
      "Patch extracted: depth 128, height 112, width 32\n",
      "Patch extracted: depth 128, height 128, width 0\n",
      "Patch extracted: depth 128, height 128, width 16\n",
      "Patch extracted: depth 128, height 128, width 32\n",
      "Patch extracted: depth 128, height 144, width 0\n",
      "Patch extracted: depth 128, height 144, width 16\n",
      "Patch extracted: depth 128, height 144, width 32\n",
      "Patch extracted: depth 128, height 160, width 0\n",
      "Patch extracted: depth 128, height 160, width 16\n",
      "Patch extracted: depth 128, height 160, width 32\n",
      "Patch extracted: depth 128, height 176, width 0\n",
      "Patch extracted: depth 128, height 176, width 16\n",
      "Patch extracted: depth 128, height 176, width 32\n",
      "Patch extracted: depth 144, height 0, width 0\n",
      "Patch extracted: depth 144, height 0, width 16\n",
      "Patch extracted: depth 144, height 0, width 32\n",
      "Patch extracted: depth 144, height 16, width 0\n",
      "Patch extracted: depth 144, height 16, width 16\n",
      "Patch extracted: depth 144, height 16, width 32\n",
      "Patch extracted: depth 144, height 32, width 0\n",
      "Patch extracted: depth 144, height 32, width 16\n",
      "Patch extracted: depth 144, height 32, width 32\n",
      "Patch extracted: depth 144, height 48, width 0\n",
      "Patch extracted: depth 144, height 48, width 16\n",
      "Patch extracted: depth 144, height 48, width 32\n",
      "Patch extracted: depth 144, height 64, width 0\n",
      "Patch extracted: depth 144, height 64, width 16\n",
      "Patch extracted: depth 144, height 64, width 32\n",
      "Patch extracted: depth 144, height 80, width 0\n",
      "Patch extracted: depth 144, height 80, width 16\n",
      "Patch extracted: depth 144, height 80, width 32\n",
      "Patch extracted: depth 144, height 96, width 0\n",
      "Patch extracted: depth 144, height 96, width 16\n",
      "Patch extracted: depth 144, height 96, width 32\n",
      "Patch extracted: depth 144, height 112, width 0\n",
      "Patch extracted: depth 144, height 112, width 16\n",
      "Patch extracted: depth 144, height 112, width 32\n",
      "Patch extracted: depth 144, height 128, width 0\n",
      "Patch extracted: depth 144, height 128, width 16\n",
      "Patch extracted: depth 144, height 128, width 32\n",
      "Patch extracted: depth 144, height 144, width 0\n",
      "Patch extracted: depth 144, height 144, width 16\n",
      "Patch extracted: depth 144, height 144, width 32\n",
      "Patch extracted: depth 144, height 160, width 0\n",
      "Patch extracted: depth 144, height 160, width 16\n",
      "Patch extracted: depth 144, height 160, width 32\n",
      "Patch extracted: depth 144, height 176, width 0\n",
      "Patch extracted: depth 144, height 176, width 16\n",
      "Patch extracted: depth 144, height 176, width 32\n",
      "Patch extracted: depth 160, height 0, width 0\n",
      "Patch extracted: depth 160, height 0, width 16\n",
      "Patch extracted: depth 160, height 0, width 32\n",
      "Patch extracted: depth 160, height 16, width 0\n",
      "Patch extracted: depth 160, height 16, width 16\n",
      "Patch extracted: depth 160, height 16, width 32\n",
      "Patch extracted: depth 160, height 32, width 0\n",
      "Patch extracted: depth 160, height 32, width 16\n",
      "Patch extracted: depth 160, height 32, width 32\n",
      "Patch extracted: depth 160, height 48, width 0\n",
      "Patch extracted: depth 160, height 48, width 16\n",
      "Patch extracted: depth 160, height 48, width 32\n",
      "Patch extracted: depth 160, height 64, width 0\n",
      "Patch extracted: depth 160, height 64, width 16\n",
      "Patch extracted: depth 160, height 64, width 32\n",
      "Patch extracted: depth 160, height 80, width 0\n",
      "Patch extracted: depth 160, height 80, width 16\n",
      "Patch extracted: depth 160, height 80, width 32\n",
      "Patch extracted: depth 160, height 96, width 0\n",
      "Patch extracted: depth 160, height 96, width 16\n",
      "Patch extracted: depth 160, height 96, width 32\n",
      "Patch extracted: depth 160, height 112, width 0\n",
      "Patch extracted: depth 160, height 112, width 16\n",
      "Patch extracted: depth 160, height 112, width 32\n",
      "Patch extracted: depth 160, height 128, width 0\n",
      "Patch extracted: depth 160, height 128, width 16\n",
      "Patch extracted: depth 160, height 128, width 32\n",
      "Patch extracted: depth 160, height 144, width 0\n",
      "Patch extracted: depth 160, height 144, width 16\n",
      "Patch extracted: depth 160, height 144, width 32\n",
      "Patch extracted: depth 160, height 160, width 0\n",
      "Patch extracted: depth 160, height 160, width 16\n",
      "Patch extracted: depth 160, height 160, width 32\n",
      "Patch extracted: depth 160, height 176, width 0\n",
      "Patch extracted: depth 160, height 176, width 16\n",
      "Patch extracted: depth 160, height 176, width 32\n",
      "Patch extracted: depth 176, height 0, width 0\n",
      "Patch extracted: depth 176, height 0, width 16\n",
      "Patch extracted: depth 176, height 0, width 32\n",
      "Patch extracted: depth 176, height 16, width 0\n",
      "Patch extracted: depth 176, height 16, width 16\n",
      "Patch extracted: depth 176, height 16, width 32\n",
      "Patch extracted: depth 176, height 32, width 0\n",
      "Patch extracted: depth 176, height 32, width 16\n",
      "Patch extracted: depth 176, height 32, width 32\n",
      "Patch extracted: depth 176, height 48, width 0\n",
      "Patch extracted: depth 176, height 48, width 16\n",
      "Patch extracted: depth 176, height 48, width 32\n",
      "Patch extracted: depth 176, height 64, width 0\n",
      "Patch extracted: depth 176, height 64, width 16\n",
      "Patch extracted: depth 176, height 64, width 32\n",
      "Patch extracted: depth 176, height 80, width 0\n",
      "Patch extracted: depth 176, height 80, width 16\n",
      "Patch extracted: depth 176, height 80, width 32\n",
      "Patch extracted: depth 176, height 96, width 0\n",
      "Patch extracted: depth 176, height 96, width 16\n",
      "Patch extracted: depth 176, height 96, width 32\n",
      "Patch extracted: depth 176, height 112, width 0\n",
      "Patch extracted: depth 176, height 112, width 16\n",
      "Patch extracted: depth 176, height 112, width 32\n",
      "Patch extracted: depth 176, height 128, width 0\n",
      "Patch extracted: depth 176, height 128, width 16\n",
      "Patch extracted: depth 176, height 128, width 32\n",
      "Patch extracted: depth 176, height 144, width 0\n",
      "Patch extracted: depth 176, height 144, width 16\n",
      "Patch extracted: depth 176, height 144, width 32\n",
      "Patch extracted: depth 176, height 160, width 0\n",
      "Patch extracted: depth 176, height 160, width 16\n",
      "Patch extracted: depth 176, height 160, width 32\n",
      "Patch extracted: depth 176, height 176, width 0\n",
      "Patch extracted: depth 176, height 176, width 16\n",
      "Patch extracted: depth 176, height 176, width 32\n",
      "Total patches extracted: 432\n",
      " - Number of image patches extracted: 432\n",
      " - Number of mask patches extracted: 432\n",
      "Checking for files in subfolder: /kaggle/working/training_dataset/14\n",
      " - T1 path: /kaggle/working/training_dataset/14/pre/T1.nii/T1.nii\n",
      " - IR path: /kaggle/working/training_dataset/14/pre/IR.nii/IR.nii\n",
      " - FLAIR path: /kaggle/working/training_dataset/14/pre/FLAIR.nii/FLAIR.nii\n",
      " - Segmentation path: /kaggle/working/training_dataset/14/segm.nii/segm.nii\n",
      " - T1 shape after loading: (256, 256, 192)\n",
      " - IR shape after loading: (240, 240, 48)\n",
      " - FLAIR shape after loading: (240, 240, 48)\n",
      " - Segmentation shape after loading: (240, 240, 48)\n",
      " - T1 shape: (240, 240, 48)\n",
      " - IR shape: (240, 240, 48)\n",
      " - FLAIR shape: (240, 240, 48)\n",
      " - Segmentation shape: (240, 240, 48)\n",
      "Stride: 16, Patch size: (64, 64, 16)\n",
      "Depth: 240, Height: 240, Width: 48\n",
      "Patch extracted: depth 0, height 0, width 0\n",
      "Patch extracted: depth 0, height 0, width 16\n",
      "Patch extracted: depth 0, height 0, width 32\n",
      "Patch extracted: depth 0, height 16, width 0\n",
      "Patch extracted: depth 0, height 16, width 16\n",
      "Patch extracted: depth 0, height 16, width 32\n",
      "Patch extracted: depth 0, height 32, width 0\n",
      "Patch extracted: depth 0, height 32, width 16\n",
      "Patch extracted: depth 0, height 32, width 32\n",
      "Patch extracted: depth 0, height 48, width 0\n",
      "Patch extracted: depth 0, height 48, width 16\n",
      "Patch extracted: depth 0, height 48, width 32\n",
      "Patch extracted: depth 0, height 64, width 0\n",
      "Patch extracted: depth 0, height 64, width 16\n",
      "Patch extracted: depth 0, height 64, width 32\n",
      "Patch extracted: depth 0, height 80, width 0\n",
      "Patch extracted: depth 0, height 80, width 16\n",
      "Patch extracted: depth 0, height 80, width 32\n",
      "Patch extracted: depth 0, height 96, width 0\n",
      "Patch extracted: depth 0, height 96, width 16\n",
      "Patch extracted: depth 0, height 96, width 32\n",
      "Patch extracted: depth 0, height 112, width 0\n",
      "Patch extracted: depth 0, height 112, width 16\n",
      "Patch extracted: depth 0, height 112, width 32\n",
      "Patch extracted: depth 0, height 128, width 0\n",
      "Patch extracted: depth 0, height 128, width 16\n",
      "Patch extracted: depth 0, height 128, width 32\n",
      "Patch extracted: depth 0, height 144, width 0\n",
      "Patch extracted: depth 0, height 144, width 16\n",
      "Patch extracted: depth 0, height 144, width 32\n",
      "Patch extracted: depth 0, height 160, width 0\n",
      "Patch extracted: depth 0, height 160, width 16\n",
      "Patch extracted: depth 0, height 160, width 32\n",
      "Patch extracted: depth 0, height 176, width 0\n",
      "Patch extracted: depth 0, height 176, width 16\n",
      "Patch extracted: depth 0, height 176, width 32\n",
      "Patch extracted: depth 16, height 0, width 0\n",
      "Patch extracted: depth 16, height 0, width 16\n",
      "Patch extracted: depth 16, height 0, width 32\n",
      "Patch extracted: depth 16, height 16, width 0\n",
      "Patch extracted: depth 16, height 16, width 16\n",
      "Patch extracted: depth 16, height 16, width 32\n",
      "Patch extracted: depth 16, height 32, width 0\n",
      "Patch extracted: depth 16, height 32, width 16\n",
      "Patch extracted: depth 16, height 32, width 32\n",
      "Patch extracted: depth 16, height 48, width 0\n",
      "Patch extracted: depth 16, height 48, width 16\n",
      "Patch extracted: depth 16, height 48, width 32\n",
      "Patch extracted: depth 16, height 64, width 0\n",
      "Patch extracted: depth 16, height 64, width 16\n",
      "Patch extracted: depth 16, height 64, width 32\n",
      "Patch extracted: depth 16, height 80, width 0\n",
      "Patch extracted: depth 16, height 80, width 16\n",
      "Patch extracted: depth 16, height 80, width 32\n",
      "Patch extracted: depth 16, height 96, width 0\n",
      "Patch extracted: depth 16, height 96, width 16\n",
      "Patch extracted: depth 16, height 96, width 32\n",
      "Patch extracted: depth 16, height 112, width 0\n",
      "Patch extracted: depth 16, height 112, width 16\n",
      "Patch extracted: depth 16, height 112, width 32\n",
      "Patch extracted: depth 16, height 128, width 0\n",
      "Patch extracted: depth 16, height 128, width 16\n",
      "Patch extracted: depth 16, height 128, width 32\n",
      "Patch extracted: depth 16, height 144, width 0\n",
      "Patch extracted: depth 16, height 144, width 16\n",
      "Patch extracted: depth 16, height 144, width 32\n",
      "Patch extracted: depth 16, height 160, width 0\n",
      "Patch extracted: depth 16, height 160, width 16\n",
      "Patch extracted: depth 16, height 160, width 32\n",
      "Patch extracted: depth 16, height 176, width 0\n",
      "Patch extracted: depth 16, height 176, width 16\n",
      "Patch extracted: depth 16, height 176, width 32\n",
      "Patch extracted: depth 32, height 0, width 0\n",
      "Patch extracted: depth 32, height 0, width 16\n",
      "Patch extracted: depth 32, height 0, width 32\n",
      "Patch extracted: depth 32, height 16, width 0\n",
      "Patch extracted: depth 32, height 16, width 16\n",
      "Patch extracted: depth 32, height 16, width 32\n",
      "Patch extracted: depth 32, height 32, width 0\n",
      "Patch extracted: depth 32, height 32, width 16\n",
      "Patch extracted: depth 32, height 32, width 32\n",
      "Patch extracted: depth 32, height 48, width 0\n",
      "Patch extracted: depth 32, height 48, width 16\n",
      "Patch extracted: depth 32, height 48, width 32\n",
      "Patch extracted: depth 32, height 64, width 0\n",
      "Patch extracted: depth 32, height 64, width 16\n",
      "Patch extracted: depth 32, height 64, width 32\n",
      "Patch extracted: depth 32, height 80, width 0\n",
      "Patch extracted: depth 32, height 80, width 16\n",
      "Patch extracted: depth 32, height 80, width 32\n",
      "Patch extracted: depth 32, height 96, width 0\n",
      "Patch extracted: depth 32, height 96, width 16\n",
      "Patch extracted: depth 32, height 96, width 32\n",
      "Patch extracted: depth 32, height 112, width 0\n",
      "Patch extracted: depth 32, height 112, width 16\n",
      "Patch extracted: depth 32, height 112, width 32\n",
      "Patch extracted: depth 32, height 128, width 0\n",
      "Patch extracted: depth 32, height 128, width 16\n",
      "Patch extracted: depth 32, height 128, width 32\n",
      "Patch extracted: depth 32, height 144, width 0\n",
      "Patch extracted: depth 32, height 144, width 16\n",
      "Patch extracted: depth 32, height 144, width 32\n",
      "Patch extracted: depth 32, height 160, width 0\n",
      "Patch extracted: depth 32, height 160, width 16\n",
      "Patch extracted: depth 32, height 160, width 32\n",
      "Patch extracted: depth 32, height 176, width 0\n",
      "Patch extracted: depth 32, height 176, width 16\n",
      "Patch extracted: depth 32, height 176, width 32\n",
      "Patch extracted: depth 48, height 0, width 0\n",
      "Patch extracted: depth 48, height 0, width 16\n",
      "Patch extracted: depth 48, height 0, width 32\n",
      "Patch extracted: depth 48, height 16, width 0\n",
      "Patch extracted: depth 48, height 16, width 16\n",
      "Patch extracted: depth 48, height 16, width 32\n",
      "Patch extracted: depth 48, height 32, width 0\n",
      "Patch extracted: depth 48, height 32, width 16\n",
      "Patch extracted: depth 48, height 32, width 32\n",
      "Patch extracted: depth 48, height 48, width 0\n",
      "Patch extracted: depth 48, height 48, width 16\n",
      "Patch extracted: depth 48, height 48, width 32\n",
      "Patch extracted: depth 48, height 64, width 0\n",
      "Patch extracted: depth 48, height 64, width 16\n",
      "Patch extracted: depth 48, height 64, width 32\n",
      "Patch extracted: depth 48, height 80, width 0\n",
      "Patch extracted: depth 48, height 80, width 16\n",
      "Patch extracted: depth 48, height 80, width 32\n",
      "Patch extracted: depth 48, height 96, width 0\n",
      "Patch extracted: depth 48, height 96, width 16\n",
      "Patch extracted: depth 48, height 96, width 32\n",
      "Patch extracted: depth 48, height 112, width 0\n",
      "Patch extracted: depth 48, height 112, width 16\n",
      "Patch extracted: depth 48, height 112, width 32\n",
      "Patch extracted: depth 48, height 128, width 0\n",
      "Patch extracted: depth 48, height 128, width 16\n",
      "Patch extracted: depth 48, height 128, width 32\n",
      "Patch extracted: depth 48, height 144, width 0\n",
      "Patch extracted: depth 48, height 144, width 16\n",
      "Patch extracted: depth 48, height 144, width 32\n",
      "Patch extracted: depth 48, height 160, width 0\n",
      "Patch extracted: depth 48, height 160, width 16\n",
      "Patch extracted: depth 48, height 160, width 32\n",
      "Patch extracted: depth 48, height 176, width 0\n",
      "Patch extracted: depth 48, height 176, width 16\n",
      "Patch extracted: depth 48, height 176, width 32\n",
      "Patch extracted: depth 64, height 0, width 0\n",
      "Patch extracted: depth 64, height 0, width 16\n",
      "Patch extracted: depth 64, height 0, width 32\n",
      "Patch extracted: depth 64, height 16, width 0\n",
      "Patch extracted: depth 64, height 16, width 16\n",
      "Patch extracted: depth 64, height 16, width 32\n",
      "Patch extracted: depth 64, height 32, width 0\n",
      "Patch extracted: depth 64, height 32, width 16\n",
      "Patch extracted: depth 64, height 32, width 32\n",
      "Patch extracted: depth 64, height 48, width 0\n",
      "Patch extracted: depth 64, height 48, width 16\n",
      "Patch extracted: depth 64, height 48, width 32\n",
      "Patch extracted: depth 64, height 64, width 0\n",
      "Patch extracted: depth 64, height 64, width 16\n",
      "Patch extracted: depth 64, height 64, width 32\n",
      "Patch extracted: depth 64, height 80, width 0\n",
      "Patch extracted: depth 64, height 80, width 16\n",
      "Patch extracted: depth 64, height 80, width 32\n",
      "Patch extracted: depth 64, height 96, width 0\n",
      "Patch extracted: depth 64, height 96, width 16\n",
      "Patch extracted: depth 64, height 96, width 32\n",
      "Patch extracted: depth 64, height 112, width 0\n",
      "Patch extracted: depth 64, height 112, width 16\n",
      "Patch extracted: depth 64, height 112, width 32\n",
      "Patch extracted: depth 64, height 128, width 0\n",
      "Patch extracted: depth 64, height 128, width 16\n",
      "Patch extracted: depth 64, height 128, width 32\n",
      "Patch extracted: depth 64, height 144, width 0\n",
      "Patch extracted: depth 64, height 144, width 16\n",
      "Patch extracted: depth 64, height 144, width 32\n",
      "Patch extracted: depth 64, height 160, width 0\n",
      "Patch extracted: depth 64, height 160, width 16\n",
      "Patch extracted: depth 64, height 160, width 32\n",
      "Patch extracted: depth 64, height 176, width 0\n",
      "Patch extracted: depth 64, height 176, width 16\n",
      "Patch extracted: depth 64, height 176, width 32\n",
      "Patch extracted: depth 80, height 0, width 0\n",
      "Patch extracted: depth 80, height 0, width 16\n",
      "Patch extracted: depth 80, height 0, width 32\n",
      "Patch extracted: depth 80, height 16, width 0\n",
      "Patch extracted: depth 80, height 16, width 16\n",
      "Patch extracted: depth 80, height 16, width 32\n",
      "Patch extracted: depth 80, height 32, width 0\n",
      "Patch extracted: depth 80, height 32, width 16\n",
      "Patch extracted: depth 80, height 32, width 32\n",
      "Patch extracted: depth 80, height 48, width 0\n",
      "Patch extracted: depth 80, height 48, width 16\n",
      "Patch extracted: depth 80, height 48, width 32\n",
      "Patch extracted: depth 80, height 64, width 0\n",
      "Patch extracted: depth 80, height 64, width 16\n",
      "Patch extracted: depth 80, height 64, width 32\n",
      "Patch extracted: depth 80, height 80, width 0\n",
      "Patch extracted: depth 80, height 80, width 16\n",
      "Patch extracted: depth 80, height 80, width 32\n",
      "Patch extracted: depth 80, height 96, width 0\n",
      "Patch extracted: depth 80, height 96, width 16\n",
      "Patch extracted: depth 80, height 96, width 32\n",
      "Patch extracted: depth 80, height 112, width 0\n",
      "Patch extracted: depth 80, height 112, width 16\n",
      "Patch extracted: depth 80, height 112, width 32\n",
      "Patch extracted: depth 80, height 128, width 0\n",
      "Patch extracted: depth 80, height 128, width 16\n",
      "Patch extracted: depth 80, height 128, width 32\n",
      "Patch extracted: depth 80, height 144, width 0\n",
      "Patch extracted: depth 80, height 144, width 16\n",
      "Patch extracted: depth 80, height 144, width 32\n",
      "Patch extracted: depth 80, height 160, width 0\n",
      "Patch extracted: depth 80, height 160, width 16\n",
      "Patch extracted: depth 80, height 160, width 32\n",
      "Patch extracted: depth 80, height 176, width 0\n",
      "Patch extracted: depth 80, height 176, width 16\n",
      "Patch extracted: depth 80, height 176, width 32\n",
      "Patch extracted: depth 96, height 0, width 0\n",
      "Patch extracted: depth 96, height 0, width 16\n",
      "Patch extracted: depth 96, height 0, width 32\n",
      "Patch extracted: depth 96, height 16, width 0\n",
      "Patch extracted: depth 96, height 16, width 16\n",
      "Patch extracted: depth 96, height 16, width 32\n",
      "Patch extracted: depth 96, height 32, width 0\n",
      "Patch extracted: depth 96, height 32, width 16\n",
      "Patch extracted: depth 96, height 32, width 32\n",
      "Patch extracted: depth 96, height 48, width 0\n",
      "Patch extracted: depth 96, height 48, width 16\n",
      "Patch extracted: depth 96, height 48, width 32\n",
      "Patch extracted: depth 96, height 64, width 0\n",
      "Patch extracted: depth 96, height 64, width 16\n",
      "Patch extracted: depth 96, height 64, width 32\n",
      "Patch extracted: depth 96, height 80, width 0\n",
      "Patch extracted: depth 96, height 80, width 16\n",
      "Patch extracted: depth 96, height 80, width 32\n",
      "Patch extracted: depth 96, height 96, width 0\n",
      "Patch extracted: depth 96, height 96, width 16\n",
      "Patch extracted: depth 96, height 96, width 32\n",
      "Patch extracted: depth 96, height 112, width 0\n",
      "Patch extracted: depth 96, height 112, width 16\n",
      "Patch extracted: depth 96, height 112, width 32\n",
      "Patch extracted: depth 96, height 128, width 0\n",
      "Patch extracted: depth 96, height 128, width 16\n",
      "Patch extracted: depth 96, height 128, width 32\n",
      "Patch extracted: depth 96, height 144, width 0\n",
      "Patch extracted: depth 96, height 144, width 16\n",
      "Patch extracted: depth 96, height 144, width 32\n",
      "Patch extracted: depth 96, height 160, width 0\n",
      "Patch extracted: depth 96, height 160, width 16\n",
      "Patch extracted: depth 96, height 160, width 32\n",
      "Patch extracted: depth 96, height 176, width 0\n",
      "Patch extracted: depth 96, height 176, width 16\n",
      "Patch extracted: depth 96, height 176, width 32\n",
      "Patch extracted: depth 112, height 0, width 0\n",
      "Patch extracted: depth 112, height 0, width 16\n",
      "Patch extracted: depth 112, height 0, width 32\n",
      "Patch extracted: depth 112, height 16, width 0\n",
      "Patch extracted: depth 112, height 16, width 16\n",
      "Patch extracted: depth 112, height 16, width 32\n",
      "Patch extracted: depth 112, height 32, width 0\n",
      "Patch extracted: depth 112, height 32, width 16\n",
      "Patch extracted: depth 112, height 32, width 32\n",
      "Patch extracted: depth 112, height 48, width 0\n",
      "Patch extracted: depth 112, height 48, width 16\n",
      "Patch extracted: depth 112, height 48, width 32\n",
      "Patch extracted: depth 112, height 64, width 0\n",
      "Patch extracted: depth 112, height 64, width 16\n",
      "Patch extracted: depth 112, height 64, width 32\n",
      "Patch extracted: depth 112, height 80, width 0\n",
      "Patch extracted: depth 112, height 80, width 16\n",
      "Patch extracted: depth 112, height 80, width 32\n",
      "Patch extracted: depth 112, height 96, width 0\n",
      "Patch extracted: depth 112, height 96, width 16\n",
      "Patch extracted: depth 112, height 96, width 32\n",
      "Patch extracted: depth 112, height 112, width 0\n",
      "Patch extracted: depth 112, height 112, width 16\n",
      "Patch extracted: depth 112, height 112, width 32\n",
      "Patch extracted: depth 112, height 128, width 0\n",
      "Patch extracted: depth 112, height 128, width 16\n",
      "Patch extracted: depth 112, height 128, width 32\n",
      "Patch extracted: depth 112, height 144, width 0\n",
      "Patch extracted: depth 112, height 144, width 16\n",
      "Patch extracted: depth 112, height 144, width 32\n",
      "Patch extracted: depth 112, height 160, width 0\n",
      "Patch extracted: depth 112, height 160, width 16\n",
      "Patch extracted: depth 112, height 160, width 32\n",
      "Patch extracted: depth 112, height 176, width 0\n",
      "Patch extracted: depth 112, height 176, width 16\n",
      "Patch extracted: depth 112, height 176, width 32\n",
      "Patch extracted: depth 128, height 0, width 0\n",
      "Patch extracted: depth 128, height 0, width 16\n",
      "Patch extracted: depth 128, height 0, width 32\n",
      "Patch extracted: depth 128, height 16, width 0\n",
      "Patch extracted: depth 128, height 16, width 16\n",
      "Patch extracted: depth 128, height 16, width 32\n",
      "Patch extracted: depth 128, height 32, width 0\n",
      "Patch extracted: depth 128, height 32, width 16\n",
      "Patch extracted: depth 128, height 32, width 32\n",
      "Patch extracted: depth 128, height 48, width 0\n",
      "Patch extracted: depth 128, height 48, width 16\n",
      "Patch extracted: depth 128, height 48, width 32\n",
      "Patch extracted: depth 128, height 64, width 0\n",
      "Patch extracted: depth 128, height 64, width 16\n",
      "Patch extracted: depth 128, height 64, width 32\n",
      "Patch extracted: depth 128, height 80, width 0\n",
      "Patch extracted: depth 128, height 80, width 16\n",
      "Patch extracted: depth 128, height 80, width 32\n",
      "Patch extracted: depth 128, height 96, width 0\n",
      "Patch extracted: depth 128, height 96, width 16\n",
      "Patch extracted: depth 128, height 96, width 32\n",
      "Patch extracted: depth 128, height 112, width 0\n",
      "Patch extracted: depth 128, height 112, width 16\n",
      "Patch extracted: depth 128, height 112, width 32\n",
      "Patch extracted: depth 128, height 128, width 0\n",
      "Patch extracted: depth 128, height 128, width 16\n",
      "Patch extracted: depth 128, height 128, width 32\n",
      "Patch extracted: depth 128, height 144, width 0\n",
      "Patch extracted: depth 128, height 144, width 16\n",
      "Patch extracted: depth 128, height 144, width 32\n",
      "Patch extracted: depth 128, height 160, width 0\n",
      "Patch extracted: depth 128, height 160, width 16\n",
      "Patch extracted: depth 128, height 160, width 32\n",
      "Patch extracted: depth 128, height 176, width 0\n",
      "Patch extracted: depth 128, height 176, width 16\n",
      "Patch extracted: depth 128, height 176, width 32\n",
      "Patch extracted: depth 144, height 0, width 0\n",
      "Patch extracted: depth 144, height 0, width 16\n",
      "Patch extracted: depth 144, height 0, width 32\n",
      "Patch extracted: depth 144, height 16, width 0\n",
      "Patch extracted: depth 144, height 16, width 16\n",
      "Patch extracted: depth 144, height 16, width 32\n",
      "Patch extracted: depth 144, height 32, width 0\n",
      "Patch extracted: depth 144, height 32, width 16\n",
      "Patch extracted: depth 144, height 32, width 32\n",
      "Patch extracted: depth 144, height 48, width 0\n",
      "Patch extracted: depth 144, height 48, width 16\n",
      "Patch extracted: depth 144, height 48, width 32\n",
      "Patch extracted: depth 144, height 64, width 0\n",
      "Patch extracted: depth 144, height 64, width 16\n",
      "Patch extracted: depth 144, height 64, width 32\n",
      "Patch extracted: depth 144, height 80, width 0\n",
      "Patch extracted: depth 144, height 80, width 16\n",
      "Patch extracted: depth 144, height 80, width 32\n",
      "Patch extracted: depth 144, height 96, width 0\n",
      "Patch extracted: depth 144, height 96, width 16\n",
      "Patch extracted: depth 144, height 96, width 32\n",
      "Patch extracted: depth 144, height 112, width 0\n",
      "Patch extracted: depth 144, height 112, width 16\n",
      "Patch extracted: depth 144, height 112, width 32\n",
      "Patch extracted: depth 144, height 128, width 0\n",
      "Patch extracted: depth 144, height 128, width 16\n",
      "Patch extracted: depth 144, height 128, width 32\n",
      "Patch extracted: depth 144, height 144, width 0\n",
      "Patch extracted: depth 144, height 144, width 16\n",
      "Patch extracted: depth 144, height 144, width 32\n",
      "Patch extracted: depth 144, height 160, width 0\n",
      "Patch extracted: depth 144, height 160, width 16\n",
      "Patch extracted: depth 144, height 160, width 32\n",
      "Patch extracted: depth 144, height 176, width 0\n",
      "Patch extracted: depth 144, height 176, width 16\n",
      "Patch extracted: depth 144, height 176, width 32\n",
      "Patch extracted: depth 160, height 0, width 0\n",
      "Patch extracted: depth 160, height 0, width 16\n",
      "Patch extracted: depth 160, height 0, width 32\n",
      "Patch extracted: depth 160, height 16, width 0\n",
      "Patch extracted: depth 160, height 16, width 16\n",
      "Patch extracted: depth 160, height 16, width 32\n",
      "Patch extracted: depth 160, height 32, width 0\n",
      "Patch extracted: depth 160, height 32, width 16\n",
      "Patch extracted: depth 160, height 32, width 32\n",
      "Patch extracted: depth 160, height 48, width 0\n",
      "Patch extracted: depth 160, height 48, width 16\n",
      "Patch extracted: depth 160, height 48, width 32\n",
      "Patch extracted: depth 160, height 64, width 0\n",
      "Patch extracted: depth 160, height 64, width 16\n",
      "Patch extracted: depth 160, height 64, width 32\n",
      "Patch extracted: depth 160, height 80, width 0\n",
      "Patch extracted: depth 160, height 80, width 16\n",
      "Patch extracted: depth 160, height 80, width 32\n",
      "Patch extracted: depth 160, height 96, width 0\n",
      "Patch extracted: depth 160, height 96, width 16\n",
      "Patch extracted: depth 160, height 96, width 32\n",
      "Patch extracted: depth 160, height 112, width 0\n",
      "Patch extracted: depth 160, height 112, width 16\n",
      "Patch extracted: depth 160, height 112, width 32\n",
      "Patch extracted: depth 160, height 128, width 0\n",
      "Patch extracted: depth 160, height 128, width 16\n",
      "Patch extracted: depth 160, height 128, width 32\n",
      "Patch extracted: depth 160, height 144, width 0\n",
      "Patch extracted: depth 160, height 144, width 16\n",
      "Patch extracted: depth 160, height 144, width 32\n",
      "Patch extracted: depth 160, height 160, width 0\n",
      "Patch extracted: depth 160, height 160, width 16\n",
      "Patch extracted: depth 160, height 160, width 32\n",
      "Patch extracted: depth 160, height 176, width 0\n",
      "Patch extracted: depth 160, height 176, width 16\n",
      "Patch extracted: depth 160, height 176, width 32\n",
      "Patch extracted: depth 176, height 0, width 0\n",
      "Patch extracted: depth 176, height 0, width 16\n",
      "Patch extracted: depth 176, height 0, width 32\n",
      "Patch extracted: depth 176, height 16, width 0\n",
      "Patch extracted: depth 176, height 16, width 16\n",
      "Patch extracted: depth 176, height 16, width 32\n",
      "Patch extracted: depth 176, height 32, width 0\n",
      "Patch extracted: depth 176, height 32, width 16\n",
      "Patch extracted: depth 176, height 32, width 32\n",
      "Patch extracted: depth 176, height 48, width 0\n",
      "Patch extracted: depth 176, height 48, width 16\n",
      "Patch extracted: depth 176, height 48, width 32\n",
      "Patch extracted: depth 176, height 64, width 0\n",
      "Patch extracted: depth 176, height 64, width 16\n",
      "Patch extracted: depth 176, height 64, width 32\n",
      "Patch extracted: depth 176, height 80, width 0\n",
      "Patch extracted: depth 176, height 80, width 16\n",
      "Patch extracted: depth 176, height 80, width 32\n",
      "Patch extracted: depth 176, height 96, width 0\n",
      "Patch extracted: depth 176, height 96, width 16\n",
      "Patch extracted: depth 176, height 96, width 32\n",
      "Patch extracted: depth 176, height 112, width 0\n",
      "Patch extracted: depth 176, height 112, width 16\n",
      "Patch extracted: depth 176, height 112, width 32\n",
      "Patch extracted: depth 176, height 128, width 0\n",
      "Patch extracted: depth 176, height 128, width 16\n",
      "Patch extracted: depth 176, height 128, width 32\n",
      "Patch extracted: depth 176, height 144, width 0\n",
      "Patch extracted: depth 176, height 144, width 16\n",
      "Patch extracted: depth 176, height 144, width 32\n",
      "Patch extracted: depth 176, height 160, width 0\n",
      "Patch extracted: depth 176, height 160, width 16\n",
      "Patch extracted: depth 176, height 160, width 32\n",
      "Patch extracted: depth 176, height 176, width 0\n",
      "Patch extracted: depth 176, height 176, width 16\n",
      "Patch extracted: depth 176, height 176, width 32\n",
      "Total patches extracted: 432\n",
      " - Number of image patches extracted: 432\n",
      " - Number of mask patches extracted: 432\n",
      "Checking for files in subfolder: /kaggle/working/training_dataset/4\n",
      " - T1 path: /kaggle/working/training_dataset/4/pre/T1.nii/T1.nii\n",
      " - IR path: /kaggle/working/training_dataset/4/pre/IR.nii/IR.nii\n",
      " - FLAIR path: /kaggle/working/training_dataset/4/pre/FLAIR.nii/FLAIR.nii\n",
      " - Segmentation path: /kaggle/working/training_dataset/4/segm.nii/segm.nii\n",
      " - T1 shape after loading: (256, 256, 192)\n",
      " - IR shape after loading: (240, 240, 48)\n",
      " - FLAIR shape after loading: (240, 240, 48)\n",
      " - Segmentation shape after loading: (240, 240, 48)\n",
      " - T1 shape: (240, 240, 48)\n",
      " - IR shape: (240, 240, 48)\n",
      " - FLAIR shape: (240, 240, 48)\n",
      " - Segmentation shape: (240, 240, 48)\n",
      "Stride: 16, Patch size: (64, 64, 16)\n",
      "Depth: 240, Height: 240, Width: 48\n",
      "Patch extracted: depth 0, height 0, width 0\n",
      "Patch extracted: depth 0, height 0, width 16\n",
      "Patch extracted: depth 0, height 0, width 32\n",
      "Patch extracted: depth 0, height 16, width 0\n",
      "Patch extracted: depth 0, height 16, width 16\n",
      "Patch extracted: depth 0, height 16, width 32\n",
      "Patch extracted: depth 0, height 32, width 0\n",
      "Patch extracted: depth 0, height 32, width 16\n",
      "Patch extracted: depth 0, height 32, width 32\n",
      "Patch extracted: depth 0, height 48, width 0\n",
      "Patch extracted: depth 0, height 48, width 16\n",
      "Patch extracted: depth 0, height 48, width 32\n",
      "Patch extracted: depth 0, height 64, width 0\n",
      "Patch extracted: depth 0, height 64, width 16\n",
      "Patch extracted: depth 0, height 64, width 32\n",
      "Patch extracted: depth 0, height 80, width 0\n",
      "Patch extracted: depth 0, height 80, width 16\n",
      "Patch extracted: depth 0, height 80, width 32\n",
      "Patch extracted: depth 0, height 96, width 0\n",
      "Patch extracted: depth 0, height 96, width 16\n",
      "Patch extracted: depth 0, height 96, width 32\n",
      "Patch extracted: depth 0, height 112, width 0\n",
      "Patch extracted: depth 0, height 112, width 16\n",
      "Patch extracted: depth 0, height 112, width 32\n",
      "Patch extracted: depth 0, height 128, width 0\n",
      "Patch extracted: depth 0, height 128, width 16\n",
      "Patch extracted: depth 0, height 128, width 32\n",
      "Patch extracted: depth 0, height 144, width 0\n",
      "Patch extracted: depth 0, height 144, width 16\n",
      "Patch extracted: depth 0, height 144, width 32\n",
      "Patch extracted: depth 0, height 160, width 0\n",
      "Patch extracted: depth 0, height 160, width 16\n",
      "Patch extracted: depth 0, height 160, width 32\n",
      "Patch extracted: depth 0, height 176, width 0\n",
      "Patch extracted: depth 0, height 176, width 16\n",
      "Patch extracted: depth 0, height 176, width 32\n",
      "Patch extracted: depth 16, height 0, width 0\n",
      "Patch extracted: depth 16, height 0, width 16\n",
      "Patch extracted: depth 16, height 0, width 32\n",
      "Patch extracted: depth 16, height 16, width 0\n",
      "Patch extracted: depth 16, height 16, width 16\n",
      "Patch extracted: depth 16, height 16, width 32\n",
      "Patch extracted: depth 16, height 32, width 0\n",
      "Patch extracted: depth 16, height 32, width 16\n",
      "Patch extracted: depth 16, height 32, width 32\n",
      "Patch extracted: depth 16, height 48, width 0\n",
      "Patch extracted: depth 16, height 48, width 16\n",
      "Patch extracted: depth 16, height 48, width 32\n",
      "Patch extracted: depth 16, height 64, width 0\n",
      "Patch extracted: depth 16, height 64, width 16\n",
      "Patch extracted: depth 16, height 64, width 32\n",
      "Patch extracted: depth 16, height 80, width 0\n",
      "Patch extracted: depth 16, height 80, width 16\n",
      "Patch extracted: depth 16, height 80, width 32\n",
      "Patch extracted: depth 16, height 96, width 0\n",
      "Patch extracted: depth 16, height 96, width 16\n",
      "Patch extracted: depth 16, height 96, width 32\n",
      "Patch extracted: depth 16, height 112, width 0\n",
      "Patch extracted: depth 16, height 112, width 16\n",
      "Patch extracted: depth 16, height 112, width 32\n",
      "Patch extracted: depth 16, height 128, width 0\n",
      "Patch extracted: depth 16, height 128, width 16\n",
      "Patch extracted: depth 16, height 128, width 32\n",
      "Patch extracted: depth 16, height 144, width 0\n",
      "Patch extracted: depth 16, height 144, width 16\n",
      "Patch extracted: depth 16, height 144, width 32\n",
      "Patch extracted: depth 16, height 160, width 0\n",
      "Patch extracted: depth 16, height 160, width 16\n",
      "Patch extracted: depth 16, height 160, width 32\n",
      "Patch extracted: depth 16, height 176, width 0\n",
      "Patch extracted: depth 16, height 176, width 16\n",
      "Patch extracted: depth 16, height 176, width 32\n",
      "Patch extracted: depth 32, height 0, width 0\n",
      "Patch extracted: depth 32, height 0, width 16\n",
      "Patch extracted: depth 32, height 0, width 32\n",
      "Patch extracted: depth 32, height 16, width 0\n",
      "Patch extracted: depth 32, height 16, width 16\n",
      "Patch extracted: depth 32, height 16, width 32\n",
      "Patch extracted: depth 32, height 32, width 0\n",
      "Patch extracted: depth 32, height 32, width 16\n",
      "Patch extracted: depth 32, height 32, width 32\n",
      "Patch extracted: depth 32, height 48, width 0\n",
      "Patch extracted: depth 32, height 48, width 16\n",
      "Patch extracted: depth 32, height 48, width 32\n",
      "Patch extracted: depth 32, height 64, width 0\n",
      "Patch extracted: depth 32, height 64, width 16\n",
      "Patch extracted: depth 32, height 64, width 32\n",
      "Patch extracted: depth 32, height 80, width 0\n",
      "Patch extracted: depth 32, height 80, width 16\n",
      "Patch extracted: depth 32, height 80, width 32\n",
      "Patch extracted: depth 32, height 96, width 0\n",
      "Patch extracted: depth 32, height 96, width 16\n",
      "Patch extracted: depth 32, height 96, width 32\n",
      "Patch extracted: depth 32, height 112, width 0\n",
      "Patch extracted: depth 32, height 112, width 16\n",
      "Patch extracted: depth 32, height 112, width 32\n",
      "Patch extracted: depth 32, height 128, width 0\n",
      "Patch extracted: depth 32, height 128, width 16\n",
      "Patch extracted: depth 32, height 128, width 32\n",
      "Patch extracted: depth 32, height 144, width 0\n",
      "Patch extracted: depth 32, height 144, width 16\n",
      "Patch extracted: depth 32, height 144, width 32\n",
      "Patch extracted: depth 32, height 160, width 0\n",
      "Patch extracted: depth 32, height 160, width 16\n",
      "Patch extracted: depth 32, height 160, width 32\n",
      "Patch extracted: depth 32, height 176, width 0\n",
      "Patch extracted: depth 32, height 176, width 16\n",
      "Patch extracted: depth 32, height 176, width 32\n",
      "Patch extracted: depth 48, height 0, width 0\n",
      "Patch extracted: depth 48, height 0, width 16\n",
      "Patch extracted: depth 48, height 0, width 32\n",
      "Patch extracted: depth 48, height 16, width 0\n",
      "Patch extracted: depth 48, height 16, width 16\n",
      "Patch extracted: depth 48, height 16, width 32\n",
      "Patch extracted: depth 48, height 32, width 0\n",
      "Patch extracted: depth 48, height 32, width 16\n",
      "Patch extracted: depth 48, height 32, width 32\n",
      "Patch extracted: depth 48, height 48, width 0\n",
      "Patch extracted: depth 48, height 48, width 16\n",
      "Patch extracted: depth 48, height 48, width 32\n",
      "Patch extracted: depth 48, height 64, width 0\n",
      "Patch extracted: depth 48, height 64, width 16\n",
      "Patch extracted: depth 48, height 64, width 32\n",
      "Patch extracted: depth 48, height 80, width 0\n",
      "Patch extracted: depth 48, height 80, width 16\n",
      "Patch extracted: depth 48, height 80, width 32\n",
      "Patch extracted: depth 48, height 96, width 0\n",
      "Patch extracted: depth 48, height 96, width 16\n",
      "Patch extracted: depth 48, height 96, width 32\n",
      "Patch extracted: depth 48, height 112, width 0\n",
      "Patch extracted: depth 48, height 112, width 16\n",
      "Patch extracted: depth 48, height 112, width 32\n",
      "Patch extracted: depth 48, height 128, width 0\n",
      "Patch extracted: depth 48, height 128, width 16\n",
      "Patch extracted: depth 48, height 128, width 32\n",
      "Patch extracted: depth 48, height 144, width 0\n",
      "Patch extracted: depth 48, height 144, width 16\n",
      "Patch extracted: depth 48, height 144, width 32\n",
      "Patch extracted: depth 48, height 160, width 0\n",
      "Patch extracted: depth 48, height 160, width 16\n",
      "Patch extracted: depth 48, height 160, width 32\n",
      "Patch extracted: depth 48, height 176, width 0\n",
      "Patch extracted: depth 48, height 176, width 16\n",
      "Patch extracted: depth 48, height 176, width 32\n",
      "Patch extracted: depth 64, height 0, width 0\n",
      "Patch extracted: depth 64, height 0, width 16\n",
      "Patch extracted: depth 64, height 0, width 32\n",
      "Patch extracted: depth 64, height 16, width 0\n",
      "Patch extracted: depth 64, height 16, width 16\n",
      "Patch extracted: depth 64, height 16, width 32\n",
      "Patch extracted: depth 64, height 32, width 0\n",
      "Patch extracted: depth 64, height 32, width 16\n",
      "Patch extracted: depth 64, height 32, width 32\n",
      "Patch extracted: depth 64, height 48, width 0\n",
      "Patch extracted: depth 64, height 48, width 16\n",
      "Patch extracted: depth 64, height 48, width 32\n",
      "Patch extracted: depth 64, height 64, width 0\n",
      "Patch extracted: depth 64, height 64, width 16\n",
      "Patch extracted: depth 64, height 64, width 32\n",
      "Patch extracted: depth 64, height 80, width 0\n",
      "Patch extracted: depth 64, height 80, width 16\n",
      "Patch extracted: depth 64, height 80, width 32\n",
      "Patch extracted: depth 64, height 96, width 0\n",
      "Patch extracted: depth 64, height 96, width 16\n",
      "Patch extracted: depth 64, height 96, width 32\n",
      "Patch extracted: depth 64, height 112, width 0\n",
      "Patch extracted: depth 64, height 112, width 16\n",
      "Patch extracted: depth 64, height 112, width 32\n",
      "Patch extracted: depth 64, height 128, width 0\n",
      "Patch extracted: depth 64, height 128, width 16\n",
      "Patch extracted: depth 64, height 128, width 32\n",
      "Patch extracted: depth 64, height 144, width 0\n",
      "Patch extracted: depth 64, height 144, width 16\n",
      "Patch extracted: depth 64, height 144, width 32\n",
      "Patch extracted: depth 64, height 160, width 0\n",
      "Patch extracted: depth 64, height 160, width 16\n",
      "Patch extracted: depth 64, height 160, width 32\n",
      "Patch extracted: depth 64, height 176, width 0\n",
      "Patch extracted: depth 64, height 176, width 16\n",
      "Patch extracted: depth 64, height 176, width 32\n",
      "Patch extracted: depth 80, height 0, width 0\n",
      "Patch extracted: depth 80, height 0, width 16\n",
      "Patch extracted: depth 80, height 0, width 32\n",
      "Patch extracted: depth 80, height 16, width 0\n",
      "Patch extracted: depth 80, height 16, width 16\n",
      "Patch extracted: depth 80, height 16, width 32\n",
      "Patch extracted: depth 80, height 32, width 0\n",
      "Patch extracted: depth 80, height 32, width 16\n",
      "Patch extracted: depth 80, height 32, width 32\n",
      "Patch extracted: depth 80, height 48, width 0\n",
      "Patch extracted: depth 80, height 48, width 16\n",
      "Patch extracted: depth 80, height 48, width 32\n",
      "Patch extracted: depth 80, height 64, width 0\n",
      "Patch extracted: depth 80, height 64, width 16\n",
      "Patch extracted: depth 80, height 64, width 32\n",
      "Patch extracted: depth 80, height 80, width 0\n",
      "Patch extracted: depth 80, height 80, width 16\n",
      "Patch extracted: depth 80, height 80, width 32\n",
      "Patch extracted: depth 80, height 96, width 0\n",
      "Patch extracted: depth 80, height 96, width 16\n",
      "Patch extracted: depth 80, height 96, width 32\n",
      "Patch extracted: depth 80, height 112, width 0\n",
      "Patch extracted: depth 80, height 112, width 16\n",
      "Patch extracted: depth 80, height 112, width 32\n",
      "Patch extracted: depth 80, height 128, width 0\n",
      "Patch extracted: depth 80, height 128, width 16\n",
      "Patch extracted: depth 80, height 128, width 32\n",
      "Patch extracted: depth 80, height 144, width 0\n",
      "Patch extracted: depth 80, height 144, width 16\n",
      "Patch extracted: depth 80, height 144, width 32\n",
      "Patch extracted: depth 80, height 160, width 0\n",
      "Patch extracted: depth 80, height 160, width 16\n",
      "Patch extracted: depth 80, height 160, width 32\n",
      "Patch extracted: depth 80, height 176, width 0\n",
      "Patch extracted: depth 80, height 176, width 16\n",
      "Patch extracted: depth 80, height 176, width 32\n",
      "Patch extracted: depth 96, height 0, width 0\n",
      "Patch extracted: depth 96, height 0, width 16\n",
      "Patch extracted: depth 96, height 0, width 32\n",
      "Patch extracted: depth 96, height 16, width 0\n",
      "Patch extracted: depth 96, height 16, width 16\n",
      "Patch extracted: depth 96, height 16, width 32\n",
      "Patch extracted: depth 96, height 32, width 0\n",
      "Patch extracted: depth 96, height 32, width 16\n",
      "Patch extracted: depth 96, height 32, width 32\n",
      "Patch extracted: depth 96, height 48, width 0\n",
      "Patch extracted: depth 96, height 48, width 16\n",
      "Patch extracted: depth 96, height 48, width 32\n",
      "Patch extracted: depth 96, height 64, width 0\n",
      "Patch extracted: depth 96, height 64, width 16\n",
      "Patch extracted: depth 96, height 64, width 32\n",
      "Patch extracted: depth 96, height 80, width 0\n",
      "Patch extracted: depth 96, height 80, width 16\n",
      "Patch extracted: depth 96, height 80, width 32\n",
      "Patch extracted: depth 96, height 96, width 0\n",
      "Patch extracted: depth 96, height 96, width 16\n",
      "Patch extracted: depth 96, height 96, width 32\n",
      "Patch extracted: depth 96, height 112, width 0\n",
      "Patch extracted: depth 96, height 112, width 16\n",
      "Patch extracted: depth 96, height 112, width 32\n",
      "Patch extracted: depth 96, height 128, width 0\n",
      "Patch extracted: depth 96, height 128, width 16\n",
      "Patch extracted: depth 96, height 128, width 32\n",
      "Patch extracted: depth 96, height 144, width 0\n",
      "Patch extracted: depth 96, height 144, width 16\n",
      "Patch extracted: depth 96, height 144, width 32\n",
      "Patch extracted: depth 96, height 160, width 0\n",
      "Patch extracted: depth 96, height 160, width 16\n",
      "Patch extracted: depth 96, height 160, width 32\n",
      "Patch extracted: depth 96, height 176, width 0\n",
      "Patch extracted: depth 96, height 176, width 16\n",
      "Patch extracted: depth 96, height 176, width 32\n",
      "Patch extracted: depth 112, height 0, width 0\n",
      "Patch extracted: depth 112, height 0, width 16\n",
      "Patch extracted: depth 112, height 0, width 32\n",
      "Patch extracted: depth 112, height 16, width 0\n",
      "Patch extracted: depth 112, height 16, width 16\n",
      "Patch extracted: depth 112, height 16, width 32\n",
      "Patch extracted: depth 112, height 32, width 0\n",
      "Patch extracted: depth 112, height 32, width 16\n",
      "Patch extracted: depth 112, height 32, width 32\n",
      "Patch extracted: depth 112, height 48, width 0\n",
      "Patch extracted: depth 112, height 48, width 16\n",
      "Patch extracted: depth 112, height 48, width 32\n",
      "Patch extracted: depth 112, height 64, width 0\n",
      "Patch extracted: depth 112, height 64, width 16\n",
      "Patch extracted: depth 112, height 64, width 32\n",
      "Patch extracted: depth 112, height 80, width 0\n",
      "Patch extracted: depth 112, height 80, width 16\n",
      "Patch extracted: depth 112, height 80, width 32\n",
      "Patch extracted: depth 112, height 96, width 0\n",
      "Patch extracted: depth 112, height 96, width 16\n",
      "Patch extracted: depth 112, height 96, width 32\n",
      "Patch extracted: depth 112, height 112, width 0\n",
      "Patch extracted: depth 112, height 112, width 16\n",
      "Patch extracted: depth 112, height 112, width 32\n",
      "Patch extracted: depth 112, height 128, width 0\n",
      "Patch extracted: depth 112, height 128, width 16\n",
      "Patch extracted: depth 112, height 128, width 32\n",
      "Patch extracted: depth 112, height 144, width 0\n",
      "Patch extracted: depth 112, height 144, width 16\n",
      "Patch extracted: depth 112, height 144, width 32\n",
      "Patch extracted: depth 112, height 160, width 0\n",
      "Patch extracted: depth 112, height 160, width 16\n",
      "Patch extracted: depth 112, height 160, width 32\n",
      "Patch extracted: depth 112, height 176, width 0\n",
      "Patch extracted: depth 112, height 176, width 16\n",
      "Patch extracted: depth 112, height 176, width 32\n",
      "Patch extracted: depth 128, height 0, width 0\n",
      "Patch extracted: depth 128, height 0, width 16\n",
      "Patch extracted: depth 128, height 0, width 32\n",
      "Patch extracted: depth 128, height 16, width 0\n",
      "Patch extracted: depth 128, height 16, width 16\n",
      "Patch extracted: depth 128, height 16, width 32\n",
      "Patch extracted: depth 128, height 32, width 0\n",
      "Patch extracted: depth 128, height 32, width 16\n",
      "Patch extracted: depth 128, height 32, width 32\n",
      "Patch extracted: depth 128, height 48, width 0\n",
      "Patch extracted: depth 128, height 48, width 16\n",
      "Patch extracted: depth 128, height 48, width 32\n",
      "Patch extracted: depth 128, height 64, width 0\n",
      "Patch extracted: depth 128, height 64, width 16\n",
      "Patch extracted: depth 128, height 64, width 32\n",
      "Patch extracted: depth 128, height 80, width 0\n",
      "Patch extracted: depth 128, height 80, width 16\n",
      "Patch extracted: depth 128, height 80, width 32\n",
      "Patch extracted: depth 128, height 96, width 0\n",
      "Patch extracted: depth 128, height 96, width 16\n",
      "Patch extracted: depth 128, height 96, width 32\n",
      "Patch extracted: depth 128, height 112, width 0\n",
      "Patch extracted: depth 128, height 112, width 16\n",
      "Patch extracted: depth 128, height 112, width 32\n",
      "Patch extracted: depth 128, height 128, width 0\n",
      "Patch extracted: depth 128, height 128, width 16\n",
      "Patch extracted: depth 128, height 128, width 32\n",
      "Patch extracted: depth 128, height 144, width 0\n",
      "Patch extracted: depth 128, height 144, width 16\n",
      "Patch extracted: depth 128, height 144, width 32\n",
      "Patch extracted: depth 128, height 160, width 0\n",
      "Patch extracted: depth 128, height 160, width 16\n",
      "Patch extracted: depth 128, height 160, width 32\n",
      "Patch extracted: depth 128, height 176, width 0\n",
      "Patch extracted: depth 128, height 176, width 16\n",
      "Patch extracted: depth 128, height 176, width 32\n",
      "Patch extracted: depth 144, height 0, width 0\n",
      "Patch extracted: depth 144, height 0, width 16\n",
      "Patch extracted: depth 144, height 0, width 32\n",
      "Patch extracted: depth 144, height 16, width 0\n",
      "Patch extracted: depth 144, height 16, width 16\n",
      "Patch extracted: depth 144, height 16, width 32\n",
      "Patch extracted: depth 144, height 32, width 0\n",
      "Patch extracted: depth 144, height 32, width 16\n",
      "Patch extracted: depth 144, height 32, width 32\n",
      "Patch extracted: depth 144, height 48, width 0\n",
      "Patch extracted: depth 144, height 48, width 16\n",
      "Patch extracted: depth 144, height 48, width 32\n",
      "Patch extracted: depth 144, height 64, width 0\n",
      "Patch extracted: depth 144, height 64, width 16\n",
      "Patch extracted: depth 144, height 64, width 32\n",
      "Patch extracted: depth 144, height 80, width 0\n",
      "Patch extracted: depth 144, height 80, width 16\n",
      "Patch extracted: depth 144, height 80, width 32\n",
      "Patch extracted: depth 144, height 96, width 0\n",
      "Patch extracted: depth 144, height 96, width 16\n",
      "Patch extracted: depth 144, height 96, width 32\n",
      "Patch extracted: depth 144, height 112, width 0\n",
      "Patch extracted: depth 144, height 112, width 16\n",
      "Patch extracted: depth 144, height 112, width 32\n",
      "Patch extracted: depth 144, height 128, width 0\n",
      "Patch extracted: depth 144, height 128, width 16\n",
      "Patch extracted: depth 144, height 128, width 32\n",
      "Patch extracted: depth 144, height 144, width 0\n",
      "Patch extracted: depth 144, height 144, width 16\n",
      "Patch extracted: depth 144, height 144, width 32\n",
      "Patch extracted: depth 144, height 160, width 0\n",
      "Patch extracted: depth 144, height 160, width 16\n",
      "Patch extracted: depth 144, height 160, width 32\n",
      "Patch extracted: depth 144, height 176, width 0\n",
      "Patch extracted: depth 144, height 176, width 16\n",
      "Patch extracted: depth 144, height 176, width 32\n",
      "Patch extracted: depth 160, height 0, width 0\n",
      "Patch extracted: depth 160, height 0, width 16\n",
      "Patch extracted: depth 160, height 0, width 32\n",
      "Patch extracted: depth 160, height 16, width 0\n",
      "Patch extracted: depth 160, height 16, width 16\n",
      "Patch extracted: depth 160, height 16, width 32\n",
      "Patch extracted: depth 160, height 32, width 0\n",
      "Patch extracted: depth 160, height 32, width 16\n",
      "Patch extracted: depth 160, height 32, width 32\n",
      "Patch extracted: depth 160, height 48, width 0\n",
      "Patch extracted: depth 160, height 48, width 16\n",
      "Patch extracted: depth 160, height 48, width 32\n",
      "Patch extracted: depth 160, height 64, width 0\n",
      "Patch extracted: depth 160, height 64, width 16\n",
      "Patch extracted: depth 160, height 64, width 32\n",
      "Patch extracted: depth 160, height 80, width 0\n",
      "Patch extracted: depth 160, height 80, width 16\n",
      "Patch extracted: depth 160, height 80, width 32\n",
      "Patch extracted: depth 160, height 96, width 0\n",
      "Patch extracted: depth 160, height 96, width 16\n",
      "Patch extracted: depth 160, height 96, width 32\n",
      "Patch extracted: depth 160, height 112, width 0\n",
      "Patch extracted: depth 160, height 112, width 16\n",
      "Patch extracted: depth 160, height 112, width 32\n",
      "Patch extracted: depth 160, height 128, width 0\n",
      "Patch extracted: depth 160, height 128, width 16\n",
      "Patch extracted: depth 160, height 128, width 32\n",
      "Patch extracted: depth 160, height 144, width 0\n",
      "Patch extracted: depth 160, height 144, width 16\n",
      "Patch extracted: depth 160, height 144, width 32\n",
      "Patch extracted: depth 160, height 160, width 0\n",
      "Patch extracted: depth 160, height 160, width 16\n",
      "Patch extracted: depth 160, height 160, width 32\n",
      "Patch extracted: depth 160, height 176, width 0\n",
      "Patch extracted: depth 160, height 176, width 16\n",
      "Patch extracted: depth 160, height 176, width 32\n",
      "Patch extracted: depth 176, height 0, width 0\n",
      "Patch extracted: depth 176, height 0, width 16\n",
      "Patch extracted: depth 176, height 0, width 32\n",
      "Patch extracted: depth 176, height 16, width 0\n",
      "Patch extracted: depth 176, height 16, width 16\n",
      "Patch extracted: depth 176, height 16, width 32\n",
      "Patch extracted: depth 176, height 32, width 0\n",
      "Patch extracted: depth 176, height 32, width 16\n",
      "Patch extracted: depth 176, height 32, width 32\n",
      "Patch extracted: depth 176, height 48, width 0\n",
      "Patch extracted: depth 176, height 48, width 16\n",
      "Patch extracted: depth 176, height 48, width 32\n",
      "Patch extracted: depth 176, height 64, width 0\n",
      "Patch extracted: depth 176, height 64, width 16\n",
      "Patch extracted: depth 176, height 64, width 32\n",
      "Patch extracted: depth 176, height 80, width 0\n",
      "Patch extracted: depth 176, height 80, width 16\n",
      "Patch extracted: depth 176, height 80, width 32\n",
      "Patch extracted: depth 176, height 96, width 0\n",
      "Patch extracted: depth 176, height 96, width 16\n",
      "Patch extracted: depth 176, height 96, width 32\n",
      "Patch extracted: depth 176, height 112, width 0\n",
      "Patch extracted: depth 176, height 112, width 16\n",
      "Patch extracted: depth 176, height 112, width 32\n",
      "Patch extracted: depth 176, height 128, width 0\n",
      "Patch extracted: depth 176, height 128, width 16\n",
      "Patch extracted: depth 176, height 128, width 32\n",
      "Patch extracted: depth 176, height 144, width 0\n",
      "Patch extracted: depth 176, height 144, width 16\n",
      "Patch extracted: depth 176, height 144, width 32\n",
      "Patch extracted: depth 176, height 160, width 0\n",
      "Patch extracted: depth 176, height 160, width 16\n",
      "Patch extracted: depth 176, height 160, width 32\n",
      "Patch extracted: depth 176, height 176, width 0\n",
      "Patch extracted: depth 176, height 176, width 16\n",
      "Patch extracted: depth 176, height 176, width 32\n",
      "Total patches extracted: 432\n",
      " - Number of image patches extracted: 432\n",
      " - Number of mask patches extracted: 432\n",
      "Checking for files in subfolder: /kaggle/working/training_dataset/7\n",
      " - T1 path: /kaggle/working/training_dataset/7/pre/T1.nii/T1.nii\n",
      " - IR path: /kaggle/working/training_dataset/7/pre/IR.nii/IR.nii\n",
      " - FLAIR path: /kaggle/working/training_dataset/7/pre/FLAIR.nii/FLAIR.nii\n",
      " - Segmentation path: /kaggle/working/training_dataset/7/segm.nii/segm.nii\n",
      " - T1 shape after loading: (256, 256, 192)\n",
      " - IR shape after loading: (240, 240, 48)\n",
      " - FLAIR shape after loading: (240, 240, 48)\n",
      " - Segmentation shape after loading: (240, 240, 48)\n",
      " - T1 shape: (240, 240, 48)\n",
      " - IR shape: (240, 240, 48)\n",
      " - FLAIR shape: (240, 240, 48)\n",
      " - Segmentation shape: (240, 240, 48)\n",
      "Stride: 16, Patch size: (64, 64, 16)\n",
      "Depth: 240, Height: 240, Width: 48\n",
      "Patch extracted: depth 0, height 0, width 0\n",
      "Patch extracted: depth 0, height 0, width 16\n",
      "Patch extracted: depth 0, height 0, width 32\n",
      "Patch extracted: depth 0, height 16, width 0\n",
      "Patch extracted: depth 0, height 16, width 16\n",
      "Patch extracted: depth 0, height 16, width 32\n",
      "Patch extracted: depth 0, height 32, width 0\n",
      "Patch extracted: depth 0, height 32, width 16\n",
      "Patch extracted: depth 0, height 32, width 32\n",
      "Patch extracted: depth 0, height 48, width 0\n",
      "Patch extracted: depth 0, height 48, width 16\n",
      "Patch extracted: depth 0, height 48, width 32\n",
      "Patch extracted: depth 0, height 64, width 0\n",
      "Patch extracted: depth 0, height 64, width 16\n",
      "Patch extracted: depth 0, height 64, width 32\n",
      "Patch extracted: depth 0, height 80, width 0\n",
      "Patch extracted: depth 0, height 80, width 16\n",
      "Patch extracted: depth 0, height 80, width 32\n",
      "Patch extracted: depth 0, height 96, width 0\n",
      "Patch extracted: depth 0, height 96, width 16\n",
      "Patch extracted: depth 0, height 96, width 32\n",
      "Patch extracted: depth 0, height 112, width 0\n",
      "Patch extracted: depth 0, height 112, width 16\n",
      "Patch extracted: depth 0, height 112, width 32\n",
      "Patch extracted: depth 0, height 128, width 0\n",
      "Patch extracted: depth 0, height 128, width 16\n",
      "Patch extracted: depth 0, height 128, width 32\n",
      "Patch extracted: depth 0, height 144, width 0\n",
      "Patch extracted: depth 0, height 144, width 16\n",
      "Patch extracted: depth 0, height 144, width 32\n",
      "Patch extracted: depth 0, height 160, width 0\n",
      "Patch extracted: depth 0, height 160, width 16\n",
      "Patch extracted: depth 0, height 160, width 32\n",
      "Patch extracted: depth 0, height 176, width 0\n",
      "Patch extracted: depth 0, height 176, width 16\n",
      "Patch extracted: depth 0, height 176, width 32\n",
      "Patch extracted: depth 16, height 0, width 0\n",
      "Patch extracted: depth 16, height 0, width 16\n",
      "Patch extracted: depth 16, height 0, width 32\n",
      "Patch extracted: depth 16, height 16, width 0\n",
      "Patch extracted: depth 16, height 16, width 16\n",
      "Patch extracted: depth 16, height 16, width 32\n",
      "Patch extracted: depth 16, height 32, width 0\n",
      "Patch extracted: depth 16, height 32, width 16\n",
      "Patch extracted: depth 16, height 32, width 32\n",
      "Patch extracted: depth 16, height 48, width 0\n",
      "Patch extracted: depth 16, height 48, width 16\n",
      "Patch extracted: depth 16, height 48, width 32\n",
      "Patch extracted: depth 16, height 64, width 0\n",
      "Patch extracted: depth 16, height 64, width 16\n",
      "Patch extracted: depth 16, height 64, width 32\n",
      "Patch extracted: depth 16, height 80, width 0\n",
      "Patch extracted: depth 16, height 80, width 16\n",
      "Patch extracted: depth 16, height 80, width 32\n",
      "Patch extracted: depth 16, height 96, width 0\n",
      "Patch extracted: depth 16, height 96, width 16\n",
      "Patch extracted: depth 16, height 96, width 32\n",
      "Patch extracted: depth 16, height 112, width 0\n",
      "Patch extracted: depth 16, height 112, width 16\n",
      "Patch extracted: depth 16, height 112, width 32\n",
      "Patch extracted: depth 16, height 128, width 0\n",
      "Patch extracted: depth 16, height 128, width 16\n",
      "Patch extracted: depth 16, height 128, width 32\n",
      "Patch extracted: depth 16, height 144, width 0\n",
      "Patch extracted: depth 16, height 144, width 16\n",
      "Patch extracted: depth 16, height 144, width 32\n",
      "Patch extracted: depth 16, height 160, width 0\n",
      "Patch extracted: depth 16, height 160, width 16\n",
      "Patch extracted: depth 16, height 160, width 32\n",
      "Patch extracted: depth 16, height 176, width 0\n",
      "Patch extracted: depth 16, height 176, width 16\n",
      "Patch extracted: depth 16, height 176, width 32\n",
      "Patch extracted: depth 32, height 0, width 0\n",
      "Patch extracted: depth 32, height 0, width 16\n",
      "Patch extracted: depth 32, height 0, width 32\n",
      "Patch extracted: depth 32, height 16, width 0\n",
      "Patch extracted: depth 32, height 16, width 16\n",
      "Patch extracted: depth 32, height 16, width 32\n",
      "Patch extracted: depth 32, height 32, width 0\n",
      "Patch extracted: depth 32, height 32, width 16\n",
      "Patch extracted: depth 32, height 32, width 32\n",
      "Patch extracted: depth 32, height 48, width 0\n",
      "Patch extracted: depth 32, height 48, width 16\n",
      "Patch extracted: depth 32, height 48, width 32\n",
      "Patch extracted: depth 32, height 64, width 0\n",
      "Patch extracted: depth 32, height 64, width 16\n",
      "Patch extracted: depth 32, height 64, width 32\n",
      "Patch extracted: depth 32, height 80, width 0\n",
      "Patch extracted: depth 32, height 80, width 16\n",
      "Patch extracted: depth 32, height 80, width 32\n",
      "Patch extracted: depth 32, height 96, width 0\n",
      "Patch extracted: depth 32, height 96, width 16\n",
      "Patch extracted: depth 32, height 96, width 32\n",
      "Patch extracted: depth 32, height 112, width 0\n",
      "Patch extracted: depth 32, height 112, width 16\n",
      "Patch extracted: depth 32, height 112, width 32\n",
      "Patch extracted: depth 32, height 128, width 0\n",
      "Patch extracted: depth 32, height 128, width 16\n",
      "Patch extracted: depth 32, height 128, width 32\n",
      "Patch extracted: depth 32, height 144, width 0\n",
      "Patch extracted: depth 32, height 144, width 16\n",
      "Patch extracted: depth 32, height 144, width 32\n",
      "Patch extracted: depth 32, height 160, width 0\n",
      "Patch extracted: depth 32, height 160, width 16\n",
      "Patch extracted: depth 32, height 160, width 32\n",
      "Patch extracted: depth 32, height 176, width 0\n",
      "Patch extracted: depth 32, height 176, width 16\n",
      "Patch extracted: depth 32, height 176, width 32\n",
      "Patch extracted: depth 48, height 0, width 0\n",
      "Patch extracted: depth 48, height 0, width 16\n",
      "Patch extracted: depth 48, height 0, width 32\n",
      "Patch extracted: depth 48, height 16, width 0\n",
      "Patch extracted: depth 48, height 16, width 16\n",
      "Patch extracted: depth 48, height 16, width 32\n",
      "Patch extracted: depth 48, height 32, width 0\n",
      "Patch extracted: depth 48, height 32, width 16\n",
      "Patch extracted: depth 48, height 32, width 32\n",
      "Patch extracted: depth 48, height 48, width 0\n",
      "Patch extracted: depth 48, height 48, width 16\n",
      "Patch extracted: depth 48, height 48, width 32\n",
      "Patch extracted: depth 48, height 64, width 0\n",
      "Patch extracted: depth 48, height 64, width 16\n",
      "Patch extracted: depth 48, height 64, width 32\n",
      "Patch extracted: depth 48, height 80, width 0\n",
      "Patch extracted: depth 48, height 80, width 16\n",
      "Patch extracted: depth 48, height 80, width 32\n",
      "Patch extracted: depth 48, height 96, width 0\n",
      "Patch extracted: depth 48, height 96, width 16\n",
      "Patch extracted: depth 48, height 96, width 32\n",
      "Patch extracted: depth 48, height 112, width 0\n",
      "Patch extracted: depth 48, height 112, width 16\n",
      "Patch extracted: depth 48, height 112, width 32\n",
      "Patch extracted: depth 48, height 128, width 0\n",
      "Patch extracted: depth 48, height 128, width 16\n",
      "Patch extracted: depth 48, height 128, width 32\n",
      "Patch extracted: depth 48, height 144, width 0\n",
      "Patch extracted: depth 48, height 144, width 16\n",
      "Patch extracted: depth 48, height 144, width 32\n",
      "Patch extracted: depth 48, height 160, width 0\n",
      "Patch extracted: depth 48, height 160, width 16\n",
      "Patch extracted: depth 48, height 160, width 32\n",
      "Patch extracted: depth 48, height 176, width 0\n",
      "Patch extracted: depth 48, height 176, width 16\n",
      "Patch extracted: depth 48, height 176, width 32\n",
      "Patch extracted: depth 64, height 0, width 0\n",
      "Patch extracted: depth 64, height 0, width 16\n",
      "Patch extracted: depth 64, height 0, width 32\n",
      "Patch extracted: depth 64, height 16, width 0\n",
      "Patch extracted: depth 64, height 16, width 16\n",
      "Patch extracted: depth 64, height 16, width 32\n",
      "Patch extracted: depth 64, height 32, width 0\n",
      "Patch extracted: depth 64, height 32, width 16\n",
      "Patch extracted: depth 64, height 32, width 32\n",
      "Patch extracted: depth 64, height 48, width 0\n",
      "Patch extracted: depth 64, height 48, width 16\n",
      "Patch extracted: depth 64, height 48, width 32\n",
      "Patch extracted: depth 64, height 64, width 0\n",
      "Patch extracted: depth 64, height 64, width 16\n",
      "Patch extracted: depth 64, height 64, width 32\n",
      "Patch extracted: depth 64, height 80, width 0\n",
      "Patch extracted: depth 64, height 80, width 16\n",
      "Patch extracted: depth 64, height 80, width 32\n",
      "Patch extracted: depth 64, height 96, width 0\n",
      "Patch extracted: depth 64, height 96, width 16\n",
      "Patch extracted: depth 64, height 96, width 32\n",
      "Patch extracted: depth 64, height 112, width 0\n",
      "Patch extracted: depth 64, height 112, width 16\n",
      "Patch extracted: depth 64, height 112, width 32\n",
      "Patch extracted: depth 64, height 128, width 0\n",
      "Patch extracted: depth 64, height 128, width 16\n",
      "Patch extracted: depth 64, height 128, width 32\n",
      "Patch extracted: depth 64, height 144, width 0\n",
      "Patch extracted: depth 64, height 144, width 16\n",
      "Patch extracted: depth 64, height 144, width 32\n",
      "Patch extracted: depth 64, height 160, width 0\n",
      "Patch extracted: depth 64, height 160, width 16\n",
      "Patch extracted: depth 64, height 160, width 32\n",
      "Patch extracted: depth 64, height 176, width 0\n",
      "Patch extracted: depth 64, height 176, width 16\n",
      "Patch extracted: depth 64, height 176, width 32\n",
      "Patch extracted: depth 80, height 0, width 0\n",
      "Patch extracted: depth 80, height 0, width 16\n",
      "Patch extracted: depth 80, height 0, width 32\n",
      "Patch extracted: depth 80, height 16, width 0\n",
      "Patch extracted: depth 80, height 16, width 16\n",
      "Patch extracted: depth 80, height 16, width 32\n",
      "Patch extracted: depth 80, height 32, width 0\n",
      "Patch extracted: depth 80, height 32, width 16\n",
      "Patch extracted: depth 80, height 32, width 32\n",
      "Patch extracted: depth 80, height 48, width 0\n",
      "Patch extracted: depth 80, height 48, width 16\n",
      "Patch extracted: depth 80, height 48, width 32\n",
      "Patch extracted: depth 80, height 64, width 0\n",
      "Patch extracted: depth 80, height 64, width 16\n",
      "Patch extracted: depth 80, height 64, width 32\n",
      "Patch extracted: depth 80, height 80, width 0\n",
      "Patch extracted: depth 80, height 80, width 16\n",
      "Patch extracted: depth 80, height 80, width 32\n",
      "Patch extracted: depth 80, height 96, width 0\n",
      "Patch extracted: depth 80, height 96, width 16\n",
      "Patch extracted: depth 80, height 96, width 32\n",
      "Patch extracted: depth 80, height 112, width 0\n",
      "Patch extracted: depth 80, height 112, width 16\n",
      "Patch extracted: depth 80, height 112, width 32\n",
      "Patch extracted: depth 80, height 128, width 0\n",
      "Patch extracted: depth 80, height 128, width 16\n",
      "Patch extracted: depth 80, height 128, width 32\n",
      "Patch extracted: depth 80, height 144, width 0\n",
      "Patch extracted: depth 80, height 144, width 16\n",
      "Patch extracted: depth 80, height 144, width 32\n",
      "Patch extracted: depth 80, height 160, width 0\n",
      "Patch extracted: depth 80, height 160, width 16\n",
      "Patch extracted: depth 80, height 160, width 32\n",
      "Patch extracted: depth 80, height 176, width 0\n",
      "Patch extracted: depth 80, height 176, width 16\n",
      "Patch extracted: depth 80, height 176, width 32\n",
      "Patch extracted: depth 96, height 0, width 0\n",
      "Patch extracted: depth 96, height 0, width 16\n",
      "Patch extracted: depth 96, height 0, width 32\n",
      "Patch extracted: depth 96, height 16, width 0\n",
      "Patch extracted: depth 96, height 16, width 16\n",
      "Patch extracted: depth 96, height 16, width 32\n",
      "Patch extracted: depth 96, height 32, width 0\n",
      "Patch extracted: depth 96, height 32, width 16\n",
      "Patch extracted: depth 96, height 32, width 32\n",
      "Patch extracted: depth 96, height 48, width 0\n",
      "Patch extracted: depth 96, height 48, width 16\n",
      "Patch extracted: depth 96, height 48, width 32\n",
      "Patch extracted: depth 96, height 64, width 0\n",
      "Patch extracted: depth 96, height 64, width 16\n",
      "Patch extracted: depth 96, height 64, width 32\n",
      "Patch extracted: depth 96, height 80, width 0\n",
      "Patch extracted: depth 96, height 80, width 16\n",
      "Patch extracted: depth 96, height 80, width 32\n",
      "Patch extracted: depth 96, height 96, width 0\n",
      "Patch extracted: depth 96, height 96, width 16\n",
      "Patch extracted: depth 96, height 96, width 32\n",
      "Patch extracted: depth 96, height 112, width 0\n",
      "Patch extracted: depth 96, height 112, width 16\n",
      "Patch extracted: depth 96, height 112, width 32\n",
      "Patch extracted: depth 96, height 128, width 0\n",
      "Patch extracted: depth 96, height 128, width 16\n",
      "Patch extracted: depth 96, height 128, width 32\n",
      "Patch extracted: depth 96, height 144, width 0\n",
      "Patch extracted: depth 96, height 144, width 16\n",
      "Patch extracted: depth 96, height 144, width 32\n",
      "Patch extracted: depth 96, height 160, width 0\n",
      "Patch extracted: depth 96, height 160, width 16\n",
      "Patch extracted: depth 96, height 160, width 32\n",
      "Patch extracted: depth 96, height 176, width 0\n",
      "Patch extracted: depth 96, height 176, width 16\n",
      "Patch extracted: depth 96, height 176, width 32\n",
      "Patch extracted: depth 112, height 0, width 0\n",
      "Patch extracted: depth 112, height 0, width 16\n",
      "Patch extracted: depth 112, height 0, width 32\n",
      "Patch extracted: depth 112, height 16, width 0\n",
      "Patch extracted: depth 112, height 16, width 16\n",
      "Patch extracted: depth 112, height 16, width 32\n",
      "Patch extracted: depth 112, height 32, width 0\n",
      "Patch extracted: depth 112, height 32, width 16\n",
      "Patch extracted: depth 112, height 32, width 32\n",
      "Patch extracted: depth 112, height 48, width 0\n",
      "Patch extracted: depth 112, height 48, width 16\n",
      "Patch extracted: depth 112, height 48, width 32\n",
      "Patch extracted: depth 112, height 64, width 0\n",
      "Patch extracted: depth 112, height 64, width 16\n",
      "Patch extracted: depth 112, height 64, width 32\n",
      "Patch extracted: depth 112, height 80, width 0\n",
      "Patch extracted: depth 112, height 80, width 16\n",
      "Patch extracted: depth 112, height 80, width 32\n",
      "Patch extracted: depth 112, height 96, width 0\n",
      "Patch extracted: depth 112, height 96, width 16\n",
      "Patch extracted: depth 112, height 96, width 32\n",
      "Patch extracted: depth 112, height 112, width 0\n",
      "Patch extracted: depth 112, height 112, width 16\n",
      "Patch extracted: depth 112, height 112, width 32\n",
      "Patch extracted: depth 112, height 128, width 0\n",
      "Patch extracted: depth 112, height 128, width 16\n",
      "Patch extracted: depth 112, height 128, width 32\n",
      "Patch extracted: depth 112, height 144, width 0\n",
      "Patch extracted: depth 112, height 144, width 16\n",
      "Patch extracted: depth 112, height 144, width 32\n",
      "Patch extracted: depth 112, height 160, width 0\n",
      "Patch extracted: depth 112, height 160, width 16\n",
      "Patch extracted: depth 112, height 160, width 32\n",
      "Patch extracted: depth 112, height 176, width 0\n",
      "Patch extracted: depth 112, height 176, width 16\n",
      "Patch extracted: depth 112, height 176, width 32\n",
      "Patch extracted: depth 128, height 0, width 0\n",
      "Patch extracted: depth 128, height 0, width 16\n",
      "Patch extracted: depth 128, height 0, width 32\n",
      "Patch extracted: depth 128, height 16, width 0\n",
      "Patch extracted: depth 128, height 16, width 16\n",
      "Patch extracted: depth 128, height 16, width 32\n",
      "Patch extracted: depth 128, height 32, width 0\n",
      "Patch extracted: depth 128, height 32, width 16\n",
      "Patch extracted: depth 128, height 32, width 32\n",
      "Patch extracted: depth 128, height 48, width 0\n",
      "Patch extracted: depth 128, height 48, width 16\n",
      "Patch extracted: depth 128, height 48, width 32\n",
      "Patch extracted: depth 128, height 64, width 0\n",
      "Patch extracted: depth 128, height 64, width 16\n",
      "Patch extracted: depth 128, height 64, width 32\n",
      "Patch extracted: depth 128, height 80, width 0\n",
      "Patch extracted: depth 128, height 80, width 16\n",
      "Patch extracted: depth 128, height 80, width 32\n",
      "Patch extracted: depth 128, height 96, width 0\n",
      "Patch extracted: depth 128, height 96, width 16\n",
      "Patch extracted: depth 128, height 96, width 32\n",
      "Patch extracted: depth 128, height 112, width 0\n",
      "Patch extracted: depth 128, height 112, width 16\n",
      "Patch extracted: depth 128, height 112, width 32\n",
      "Patch extracted: depth 128, height 128, width 0\n",
      "Patch extracted: depth 128, height 128, width 16\n",
      "Patch extracted: depth 128, height 128, width 32\n",
      "Patch extracted: depth 128, height 144, width 0\n",
      "Patch extracted: depth 128, height 144, width 16\n",
      "Patch extracted: depth 128, height 144, width 32\n",
      "Patch extracted: depth 128, height 160, width 0\n",
      "Patch extracted: depth 128, height 160, width 16\n",
      "Patch extracted: depth 128, height 160, width 32\n",
      "Patch extracted: depth 128, height 176, width 0\n",
      "Patch extracted: depth 128, height 176, width 16\n",
      "Patch extracted: depth 128, height 176, width 32\n",
      "Patch extracted: depth 144, height 0, width 0\n",
      "Patch extracted: depth 144, height 0, width 16\n",
      "Patch extracted: depth 144, height 0, width 32\n",
      "Patch extracted: depth 144, height 16, width 0\n",
      "Patch extracted: depth 144, height 16, width 16\n",
      "Patch extracted: depth 144, height 16, width 32\n",
      "Patch extracted: depth 144, height 32, width 0\n",
      "Patch extracted: depth 144, height 32, width 16\n",
      "Patch extracted: depth 144, height 32, width 32\n",
      "Patch extracted: depth 144, height 48, width 0\n",
      "Patch extracted: depth 144, height 48, width 16\n",
      "Patch extracted: depth 144, height 48, width 32\n",
      "Patch extracted: depth 144, height 64, width 0\n",
      "Patch extracted: depth 144, height 64, width 16\n",
      "Patch extracted: depth 144, height 64, width 32\n",
      "Patch extracted: depth 144, height 80, width 0\n",
      "Patch extracted: depth 144, height 80, width 16\n",
      "Patch extracted: depth 144, height 80, width 32\n",
      "Patch extracted: depth 144, height 96, width 0\n",
      "Patch extracted: depth 144, height 96, width 16\n",
      "Patch extracted: depth 144, height 96, width 32\n",
      "Patch extracted: depth 144, height 112, width 0\n",
      "Patch extracted: depth 144, height 112, width 16\n",
      "Patch extracted: depth 144, height 112, width 32\n",
      "Patch extracted: depth 144, height 128, width 0\n",
      "Patch extracted: depth 144, height 128, width 16\n",
      "Patch extracted: depth 144, height 128, width 32\n",
      "Patch extracted: depth 144, height 144, width 0\n",
      "Patch extracted: depth 144, height 144, width 16\n",
      "Patch extracted: depth 144, height 144, width 32\n",
      "Patch extracted: depth 144, height 160, width 0\n",
      "Patch extracted: depth 144, height 160, width 16\n",
      "Patch extracted: depth 144, height 160, width 32\n",
      "Patch extracted: depth 144, height 176, width 0\n",
      "Patch extracted: depth 144, height 176, width 16\n",
      "Patch extracted: depth 144, height 176, width 32\n",
      "Patch extracted: depth 160, height 0, width 0\n",
      "Patch extracted: depth 160, height 0, width 16\n",
      "Patch extracted: depth 160, height 0, width 32\n",
      "Patch extracted: depth 160, height 16, width 0\n",
      "Patch extracted: depth 160, height 16, width 16\n",
      "Patch extracted: depth 160, height 16, width 32\n",
      "Patch extracted: depth 160, height 32, width 0\n",
      "Patch extracted: depth 160, height 32, width 16\n",
      "Patch extracted: depth 160, height 32, width 32\n",
      "Patch extracted: depth 160, height 48, width 0\n",
      "Patch extracted: depth 160, height 48, width 16\n",
      "Patch extracted: depth 160, height 48, width 32\n",
      "Patch extracted: depth 160, height 64, width 0\n",
      "Patch extracted: depth 160, height 64, width 16\n",
      "Patch extracted: depth 160, height 64, width 32\n",
      "Patch extracted: depth 160, height 80, width 0\n",
      "Patch extracted: depth 160, height 80, width 16\n",
      "Patch extracted: depth 160, height 80, width 32\n",
      "Patch extracted: depth 160, height 96, width 0\n",
      "Patch extracted: depth 160, height 96, width 16\n",
      "Patch extracted: depth 160, height 96, width 32\n",
      "Patch extracted: depth 160, height 112, width 0\n",
      "Patch extracted: depth 160, height 112, width 16\n",
      "Patch extracted: depth 160, height 112, width 32\n",
      "Patch extracted: depth 160, height 128, width 0\n",
      "Patch extracted: depth 160, height 128, width 16\n",
      "Patch extracted: depth 160, height 128, width 32\n",
      "Patch extracted: depth 160, height 144, width 0\n",
      "Patch extracted: depth 160, height 144, width 16\n",
      "Patch extracted: depth 160, height 144, width 32\n",
      "Patch extracted: depth 160, height 160, width 0\n",
      "Patch extracted: depth 160, height 160, width 16\n",
      "Patch extracted: depth 160, height 160, width 32\n",
      "Patch extracted: depth 160, height 176, width 0\n",
      "Patch extracted: depth 160, height 176, width 16\n",
      "Patch extracted: depth 160, height 176, width 32\n",
      "Patch extracted: depth 176, height 0, width 0\n",
      "Patch extracted: depth 176, height 0, width 16\n",
      "Patch extracted: depth 176, height 0, width 32\n",
      "Patch extracted: depth 176, height 16, width 0\n",
      "Patch extracted: depth 176, height 16, width 16\n",
      "Patch extracted: depth 176, height 16, width 32\n",
      "Patch extracted: depth 176, height 32, width 0\n",
      "Patch extracted: depth 176, height 32, width 16\n",
      "Patch extracted: depth 176, height 32, width 32\n",
      "Patch extracted: depth 176, height 48, width 0\n",
      "Patch extracted: depth 176, height 48, width 16\n",
      "Patch extracted: depth 176, height 48, width 32\n",
      "Patch extracted: depth 176, height 64, width 0\n",
      "Patch extracted: depth 176, height 64, width 16\n",
      "Patch extracted: depth 176, height 64, width 32\n",
      "Patch extracted: depth 176, height 80, width 0\n",
      "Patch extracted: depth 176, height 80, width 16\n",
      "Patch extracted: depth 176, height 80, width 32\n",
      "Patch extracted: depth 176, height 96, width 0\n",
      "Patch extracted: depth 176, height 96, width 16\n",
      "Patch extracted: depth 176, height 96, width 32\n",
      "Patch extracted: depth 176, height 112, width 0\n",
      "Patch extracted: depth 176, height 112, width 16\n",
      "Patch extracted: depth 176, height 112, width 32\n",
      "Patch extracted: depth 176, height 128, width 0\n",
      "Patch extracted: depth 176, height 128, width 16\n",
      "Patch extracted: depth 176, height 128, width 32\n",
      "Patch extracted: depth 176, height 144, width 0\n",
      "Patch extracted: depth 176, height 144, width 16\n",
      "Patch extracted: depth 176, height 144, width 32\n",
      "Patch extracted: depth 176, height 160, width 0\n",
      "Patch extracted: depth 176, height 160, width 16\n",
      "Patch extracted: depth 176, height 160, width 32\n",
      "Patch extracted: depth 176, height 176, width 0\n",
      "Patch extracted: depth 176, height 176, width 16\n",
      "Patch extracted: depth 176, height 176, width 32\n",
      "Total patches extracted: 432\n",
      " - Number of image patches extracted: 432\n",
      " - Number of mask patches extracted: 432\n",
      "Checking for files in subfolder: /kaggle/working/training_dataset/5\n",
      " - T1 path: /kaggle/working/training_dataset/5/pre/T1.nii/T1.nii\n",
      " - IR path: /kaggle/working/training_dataset/5/pre/IR.nii/IR.nii\n",
      " - FLAIR path: /kaggle/working/training_dataset/5/pre/FLAIR.nii/FLAIR.nii\n",
      " - Segmentation path: /kaggle/working/training_dataset/5/segm.nii/segm.nii\n",
      " - T1 shape after loading: (256, 256, 192)\n",
      " - IR shape after loading: (240, 240, 48)\n",
      " - FLAIR shape after loading: (240, 240, 48)\n",
      " - Segmentation shape after loading: (240, 240, 48)\n",
      " - T1 shape: (240, 240, 48)\n",
      " - IR shape: (240, 240, 48)\n",
      " - FLAIR shape: (240, 240, 48)\n",
      " - Segmentation shape: (240, 240, 48)\n",
      "Stride: 16, Patch size: (64, 64, 16)\n",
      "Depth: 240, Height: 240, Width: 48\n",
      "Patch extracted: depth 0, height 0, width 0\n",
      "Patch extracted: depth 0, height 0, width 16\n",
      "Patch extracted: depth 0, height 0, width 32\n",
      "Patch extracted: depth 0, height 16, width 0\n",
      "Patch extracted: depth 0, height 16, width 16\n",
      "Patch extracted: depth 0, height 16, width 32\n",
      "Patch extracted: depth 0, height 32, width 0\n",
      "Patch extracted: depth 0, height 32, width 16\n",
      "Patch extracted: depth 0, height 32, width 32\n",
      "Patch extracted: depth 0, height 48, width 0\n",
      "Patch extracted: depth 0, height 48, width 16\n",
      "Patch extracted: depth 0, height 48, width 32\n",
      "Patch extracted: depth 0, height 64, width 0\n",
      "Patch extracted: depth 0, height 64, width 16\n",
      "Patch extracted: depth 0, height 64, width 32\n",
      "Patch extracted: depth 0, height 80, width 0\n",
      "Patch extracted: depth 0, height 80, width 16\n",
      "Patch extracted: depth 0, height 80, width 32\n",
      "Patch extracted: depth 0, height 96, width 0\n",
      "Patch extracted: depth 0, height 96, width 16\n",
      "Patch extracted: depth 0, height 96, width 32\n",
      "Patch extracted: depth 0, height 112, width 0\n",
      "Patch extracted: depth 0, height 112, width 16\n",
      "Patch extracted: depth 0, height 112, width 32\n",
      "Patch extracted: depth 0, height 128, width 0\n",
      "Patch extracted: depth 0, height 128, width 16\n",
      "Patch extracted: depth 0, height 128, width 32\n",
      "Patch extracted: depth 0, height 144, width 0\n",
      "Patch extracted: depth 0, height 144, width 16\n",
      "Patch extracted: depth 0, height 144, width 32\n",
      "Patch extracted: depth 0, height 160, width 0\n",
      "Patch extracted: depth 0, height 160, width 16\n",
      "Patch extracted: depth 0, height 160, width 32\n",
      "Patch extracted: depth 0, height 176, width 0\n",
      "Patch extracted: depth 0, height 176, width 16\n",
      "Patch extracted: depth 0, height 176, width 32\n",
      "Patch extracted: depth 16, height 0, width 0\n",
      "Patch extracted: depth 16, height 0, width 16\n",
      "Patch extracted: depth 16, height 0, width 32\n",
      "Patch extracted: depth 16, height 16, width 0\n",
      "Patch extracted: depth 16, height 16, width 16\n",
      "Patch extracted: depth 16, height 16, width 32\n",
      "Patch extracted: depth 16, height 32, width 0\n",
      "Patch extracted: depth 16, height 32, width 16\n",
      "Patch extracted: depth 16, height 32, width 32\n",
      "Patch extracted: depth 16, height 48, width 0\n",
      "Patch extracted: depth 16, height 48, width 16\n",
      "Patch extracted: depth 16, height 48, width 32\n",
      "Patch extracted: depth 16, height 64, width 0\n",
      "Patch extracted: depth 16, height 64, width 16\n",
      "Patch extracted: depth 16, height 64, width 32\n",
      "Patch extracted: depth 16, height 80, width 0\n",
      "Patch extracted: depth 16, height 80, width 16\n",
      "Patch extracted: depth 16, height 80, width 32\n",
      "Patch extracted: depth 16, height 96, width 0\n",
      "Patch extracted: depth 16, height 96, width 16\n",
      "Patch extracted: depth 16, height 96, width 32\n",
      "Patch extracted: depth 16, height 112, width 0\n",
      "Patch extracted: depth 16, height 112, width 16\n",
      "Patch extracted: depth 16, height 112, width 32\n",
      "Patch extracted: depth 16, height 128, width 0\n",
      "Patch extracted: depth 16, height 128, width 16\n",
      "Patch extracted: depth 16, height 128, width 32\n",
      "Patch extracted: depth 16, height 144, width 0\n",
      "Patch extracted: depth 16, height 144, width 16\n",
      "Patch extracted: depth 16, height 144, width 32\n",
      "Patch extracted: depth 16, height 160, width 0\n",
      "Patch extracted: depth 16, height 160, width 16\n",
      "Patch extracted: depth 16, height 160, width 32\n",
      "Patch extracted: depth 16, height 176, width 0\n",
      "Patch extracted: depth 16, height 176, width 16\n",
      "Patch extracted: depth 16, height 176, width 32\n",
      "Patch extracted: depth 32, height 0, width 0\n",
      "Patch extracted: depth 32, height 0, width 16\n",
      "Patch extracted: depth 32, height 0, width 32\n",
      "Patch extracted: depth 32, height 16, width 0\n",
      "Patch extracted: depth 32, height 16, width 16\n",
      "Patch extracted: depth 32, height 16, width 32\n",
      "Patch extracted: depth 32, height 32, width 0\n",
      "Patch extracted: depth 32, height 32, width 16\n",
      "Patch extracted: depth 32, height 32, width 32\n",
      "Patch extracted: depth 32, height 48, width 0\n",
      "Patch extracted: depth 32, height 48, width 16\n",
      "Patch extracted: depth 32, height 48, width 32\n",
      "Patch extracted: depth 32, height 64, width 0\n",
      "Patch extracted: depth 32, height 64, width 16\n",
      "Patch extracted: depth 32, height 64, width 32\n",
      "Patch extracted: depth 32, height 80, width 0\n",
      "Patch extracted: depth 32, height 80, width 16\n",
      "Patch extracted: depth 32, height 80, width 32\n",
      "Patch extracted: depth 32, height 96, width 0\n",
      "Patch extracted: depth 32, height 96, width 16\n",
      "Patch extracted: depth 32, height 96, width 32\n",
      "Patch extracted: depth 32, height 112, width 0\n",
      "Patch extracted: depth 32, height 112, width 16\n",
      "Patch extracted: depth 32, height 112, width 32\n",
      "Patch extracted: depth 32, height 128, width 0\n",
      "Patch extracted: depth 32, height 128, width 16\n",
      "Patch extracted: depth 32, height 128, width 32\n",
      "Patch extracted: depth 32, height 144, width 0\n",
      "Patch extracted: depth 32, height 144, width 16\n",
      "Patch extracted: depth 32, height 144, width 32\n",
      "Patch extracted: depth 32, height 160, width 0\n",
      "Patch extracted: depth 32, height 160, width 16\n",
      "Patch extracted: depth 32, height 160, width 32\n",
      "Patch extracted: depth 32, height 176, width 0\n",
      "Patch extracted: depth 32, height 176, width 16\n",
      "Patch extracted: depth 32, height 176, width 32\n",
      "Patch extracted: depth 48, height 0, width 0\n",
      "Patch extracted: depth 48, height 0, width 16\n",
      "Patch extracted: depth 48, height 0, width 32\n",
      "Patch extracted: depth 48, height 16, width 0\n",
      "Patch extracted: depth 48, height 16, width 16\n",
      "Patch extracted: depth 48, height 16, width 32\n",
      "Patch extracted: depth 48, height 32, width 0\n",
      "Patch extracted: depth 48, height 32, width 16\n",
      "Patch extracted: depth 48, height 32, width 32\n",
      "Patch extracted: depth 48, height 48, width 0\n",
      "Patch extracted: depth 48, height 48, width 16\n",
      "Patch extracted: depth 48, height 48, width 32\n",
      "Patch extracted: depth 48, height 64, width 0\n",
      "Patch extracted: depth 48, height 64, width 16\n",
      "Patch extracted: depth 48, height 64, width 32\n",
      "Patch extracted: depth 48, height 80, width 0\n",
      "Patch extracted: depth 48, height 80, width 16\n",
      "Patch extracted: depth 48, height 80, width 32\n",
      "Patch extracted: depth 48, height 96, width 0\n",
      "Patch extracted: depth 48, height 96, width 16\n",
      "Patch extracted: depth 48, height 96, width 32\n",
      "Patch extracted: depth 48, height 112, width 0\n",
      "Patch extracted: depth 48, height 112, width 16\n",
      "Patch extracted: depth 48, height 112, width 32\n",
      "Patch extracted: depth 48, height 128, width 0\n",
      "Patch extracted: depth 48, height 128, width 16\n",
      "Patch extracted: depth 48, height 128, width 32\n",
      "Patch extracted: depth 48, height 144, width 0\n",
      "Patch extracted: depth 48, height 144, width 16\n",
      "Patch extracted: depth 48, height 144, width 32\n",
      "Patch extracted: depth 48, height 160, width 0\n",
      "Patch extracted: depth 48, height 160, width 16\n",
      "Patch extracted: depth 48, height 160, width 32\n",
      "Patch extracted: depth 48, height 176, width 0\n",
      "Patch extracted: depth 48, height 176, width 16\n",
      "Patch extracted: depth 48, height 176, width 32\n",
      "Patch extracted: depth 64, height 0, width 0\n",
      "Patch extracted: depth 64, height 0, width 16\n",
      "Patch extracted: depth 64, height 0, width 32\n",
      "Patch extracted: depth 64, height 16, width 0\n",
      "Patch extracted: depth 64, height 16, width 16\n",
      "Patch extracted: depth 64, height 16, width 32\n",
      "Patch extracted: depth 64, height 32, width 0\n",
      "Patch extracted: depth 64, height 32, width 16\n",
      "Patch extracted: depth 64, height 32, width 32\n",
      "Patch extracted: depth 64, height 48, width 0\n",
      "Patch extracted: depth 64, height 48, width 16\n",
      "Patch extracted: depth 64, height 48, width 32\n",
      "Patch extracted: depth 64, height 64, width 0\n",
      "Patch extracted: depth 64, height 64, width 16\n",
      "Patch extracted: depth 64, height 64, width 32\n",
      "Patch extracted: depth 64, height 80, width 0\n",
      "Patch extracted: depth 64, height 80, width 16\n",
      "Patch extracted: depth 64, height 80, width 32\n",
      "Patch extracted: depth 64, height 96, width 0\n",
      "Patch extracted: depth 64, height 96, width 16\n",
      "Patch extracted: depth 64, height 96, width 32\n",
      "Patch extracted: depth 64, height 112, width 0\n",
      "Patch extracted: depth 64, height 112, width 16\n",
      "Patch extracted: depth 64, height 112, width 32\n",
      "Patch extracted: depth 64, height 128, width 0\n",
      "Patch extracted: depth 64, height 128, width 16\n",
      "Patch extracted: depth 64, height 128, width 32\n",
      "Patch extracted: depth 64, height 144, width 0\n",
      "Patch extracted: depth 64, height 144, width 16\n",
      "Patch extracted: depth 64, height 144, width 32\n",
      "Patch extracted: depth 64, height 160, width 0\n",
      "Patch extracted: depth 64, height 160, width 16\n",
      "Patch extracted: depth 64, height 160, width 32\n",
      "Patch extracted: depth 64, height 176, width 0\n",
      "Patch extracted: depth 64, height 176, width 16\n",
      "Patch extracted: depth 64, height 176, width 32\n",
      "Patch extracted: depth 80, height 0, width 0\n",
      "Patch extracted: depth 80, height 0, width 16\n",
      "Patch extracted: depth 80, height 0, width 32\n",
      "Patch extracted: depth 80, height 16, width 0\n",
      "Patch extracted: depth 80, height 16, width 16\n",
      "Patch extracted: depth 80, height 16, width 32\n",
      "Patch extracted: depth 80, height 32, width 0\n",
      "Patch extracted: depth 80, height 32, width 16\n",
      "Patch extracted: depth 80, height 32, width 32\n",
      "Patch extracted: depth 80, height 48, width 0\n",
      "Patch extracted: depth 80, height 48, width 16\n",
      "Patch extracted: depth 80, height 48, width 32\n",
      "Patch extracted: depth 80, height 64, width 0\n",
      "Patch extracted: depth 80, height 64, width 16\n",
      "Patch extracted: depth 80, height 64, width 32\n",
      "Patch extracted: depth 80, height 80, width 0\n",
      "Patch extracted: depth 80, height 80, width 16\n",
      "Patch extracted: depth 80, height 80, width 32\n",
      "Patch extracted: depth 80, height 96, width 0\n",
      "Patch extracted: depth 80, height 96, width 16\n",
      "Patch extracted: depth 80, height 96, width 32\n",
      "Patch extracted: depth 80, height 112, width 0\n",
      "Patch extracted: depth 80, height 112, width 16\n",
      "Patch extracted: depth 80, height 112, width 32\n",
      "Patch extracted: depth 80, height 128, width 0\n",
      "Patch extracted: depth 80, height 128, width 16\n",
      "Patch extracted: depth 80, height 128, width 32\n",
      "Patch extracted: depth 80, height 144, width 0\n",
      "Patch extracted: depth 80, height 144, width 16\n",
      "Patch extracted: depth 80, height 144, width 32\n",
      "Patch extracted: depth 80, height 160, width 0\n",
      "Patch extracted: depth 80, height 160, width 16\n",
      "Patch extracted: depth 80, height 160, width 32\n",
      "Patch extracted: depth 80, height 176, width 0\n",
      "Patch extracted: depth 80, height 176, width 16\n",
      "Patch extracted: depth 80, height 176, width 32\n",
      "Patch extracted: depth 96, height 0, width 0\n",
      "Patch extracted: depth 96, height 0, width 16\n",
      "Patch extracted: depth 96, height 0, width 32\n",
      "Patch extracted: depth 96, height 16, width 0\n",
      "Patch extracted: depth 96, height 16, width 16\n",
      "Patch extracted: depth 96, height 16, width 32\n",
      "Patch extracted: depth 96, height 32, width 0\n",
      "Patch extracted: depth 96, height 32, width 16\n",
      "Patch extracted: depth 96, height 32, width 32\n",
      "Patch extracted: depth 96, height 48, width 0\n",
      "Patch extracted: depth 96, height 48, width 16\n",
      "Patch extracted: depth 96, height 48, width 32\n",
      "Patch extracted: depth 96, height 64, width 0\n",
      "Patch extracted: depth 96, height 64, width 16\n",
      "Patch extracted: depth 96, height 64, width 32\n",
      "Patch extracted: depth 96, height 80, width 0\n",
      "Patch extracted: depth 96, height 80, width 16\n",
      "Patch extracted: depth 96, height 80, width 32\n",
      "Patch extracted: depth 96, height 96, width 0\n",
      "Patch extracted: depth 96, height 96, width 16\n",
      "Patch extracted: depth 96, height 96, width 32\n",
      "Patch extracted: depth 96, height 112, width 0\n",
      "Patch extracted: depth 96, height 112, width 16\n",
      "Patch extracted: depth 96, height 112, width 32\n",
      "Patch extracted: depth 96, height 128, width 0\n",
      "Patch extracted: depth 96, height 128, width 16\n",
      "Patch extracted: depth 96, height 128, width 32\n",
      "Patch extracted: depth 96, height 144, width 0\n",
      "Patch extracted: depth 96, height 144, width 16\n",
      "Patch extracted: depth 96, height 144, width 32\n",
      "Patch extracted: depth 96, height 160, width 0\n",
      "Patch extracted: depth 96, height 160, width 16\n",
      "Patch extracted: depth 96, height 160, width 32\n",
      "Patch extracted: depth 96, height 176, width 0\n",
      "Patch extracted: depth 96, height 176, width 16\n",
      "Patch extracted: depth 96, height 176, width 32\n",
      "Patch extracted: depth 112, height 0, width 0\n",
      "Patch extracted: depth 112, height 0, width 16\n",
      "Patch extracted: depth 112, height 0, width 32\n",
      "Patch extracted: depth 112, height 16, width 0\n",
      "Patch extracted: depth 112, height 16, width 16\n",
      "Patch extracted: depth 112, height 16, width 32\n",
      "Patch extracted: depth 112, height 32, width 0\n",
      "Patch extracted: depth 112, height 32, width 16\n",
      "Patch extracted: depth 112, height 32, width 32\n",
      "Patch extracted: depth 112, height 48, width 0\n",
      "Patch extracted: depth 112, height 48, width 16\n",
      "Patch extracted: depth 112, height 48, width 32\n",
      "Patch extracted: depth 112, height 64, width 0\n",
      "Patch extracted: depth 112, height 64, width 16\n",
      "Patch extracted: depth 112, height 64, width 32\n",
      "Patch extracted: depth 112, height 80, width 0\n",
      "Patch extracted: depth 112, height 80, width 16\n",
      "Patch extracted: depth 112, height 80, width 32\n",
      "Patch extracted: depth 112, height 96, width 0\n",
      "Patch extracted: depth 112, height 96, width 16\n",
      "Patch extracted: depth 112, height 96, width 32\n",
      "Patch extracted: depth 112, height 112, width 0\n",
      "Patch extracted: depth 112, height 112, width 16\n",
      "Patch extracted: depth 112, height 112, width 32\n",
      "Patch extracted: depth 112, height 128, width 0\n",
      "Patch extracted: depth 112, height 128, width 16\n",
      "Patch extracted: depth 112, height 128, width 32\n",
      "Patch extracted: depth 112, height 144, width 0\n",
      "Patch extracted: depth 112, height 144, width 16\n",
      "Patch extracted: depth 112, height 144, width 32\n",
      "Patch extracted: depth 112, height 160, width 0\n",
      "Patch extracted: depth 112, height 160, width 16\n",
      "Patch extracted: depth 112, height 160, width 32\n",
      "Patch extracted: depth 112, height 176, width 0\n",
      "Patch extracted: depth 112, height 176, width 16\n",
      "Patch extracted: depth 112, height 176, width 32\n",
      "Patch extracted: depth 128, height 0, width 0\n",
      "Patch extracted: depth 128, height 0, width 16\n",
      "Patch extracted: depth 128, height 0, width 32\n",
      "Patch extracted: depth 128, height 16, width 0\n",
      "Patch extracted: depth 128, height 16, width 16\n",
      "Patch extracted: depth 128, height 16, width 32\n",
      "Patch extracted: depth 128, height 32, width 0\n",
      "Patch extracted: depth 128, height 32, width 16\n",
      "Patch extracted: depth 128, height 32, width 32\n",
      "Patch extracted: depth 128, height 48, width 0\n",
      "Patch extracted: depth 128, height 48, width 16\n",
      "Patch extracted: depth 128, height 48, width 32\n",
      "Patch extracted: depth 128, height 64, width 0\n",
      "Patch extracted: depth 128, height 64, width 16\n",
      "Patch extracted: depth 128, height 64, width 32\n",
      "Patch extracted: depth 128, height 80, width 0\n",
      "Patch extracted: depth 128, height 80, width 16\n",
      "Patch extracted: depth 128, height 80, width 32\n",
      "Patch extracted: depth 128, height 96, width 0\n",
      "Patch extracted: depth 128, height 96, width 16\n",
      "Patch extracted: depth 128, height 96, width 32\n",
      "Patch extracted: depth 128, height 112, width 0\n",
      "Patch extracted: depth 128, height 112, width 16\n",
      "Patch extracted: depth 128, height 112, width 32\n",
      "Patch extracted: depth 128, height 128, width 0\n",
      "Patch extracted: depth 128, height 128, width 16\n",
      "Patch extracted: depth 128, height 128, width 32\n",
      "Patch extracted: depth 128, height 144, width 0\n",
      "Patch extracted: depth 128, height 144, width 16\n",
      "Patch extracted: depth 128, height 144, width 32\n",
      "Patch extracted: depth 128, height 160, width 0\n",
      "Patch extracted: depth 128, height 160, width 16\n",
      "Patch extracted: depth 128, height 160, width 32\n",
      "Patch extracted: depth 128, height 176, width 0\n",
      "Patch extracted: depth 128, height 176, width 16\n",
      "Patch extracted: depth 128, height 176, width 32\n",
      "Patch extracted: depth 144, height 0, width 0\n",
      "Patch extracted: depth 144, height 0, width 16\n",
      "Patch extracted: depth 144, height 0, width 32\n",
      "Patch extracted: depth 144, height 16, width 0\n",
      "Patch extracted: depth 144, height 16, width 16\n",
      "Patch extracted: depth 144, height 16, width 32\n",
      "Patch extracted: depth 144, height 32, width 0\n",
      "Patch extracted: depth 144, height 32, width 16\n",
      "Patch extracted: depth 144, height 32, width 32\n",
      "Patch extracted: depth 144, height 48, width 0\n",
      "Patch extracted: depth 144, height 48, width 16\n",
      "Patch extracted: depth 144, height 48, width 32\n",
      "Patch extracted: depth 144, height 64, width 0\n",
      "Patch extracted: depth 144, height 64, width 16\n",
      "Patch extracted: depth 144, height 64, width 32\n",
      "Patch extracted: depth 144, height 80, width 0\n",
      "Patch extracted: depth 144, height 80, width 16\n",
      "Patch extracted: depth 144, height 80, width 32\n",
      "Patch extracted: depth 144, height 96, width 0\n",
      "Patch extracted: depth 144, height 96, width 16\n",
      "Patch extracted: depth 144, height 96, width 32\n",
      "Patch extracted: depth 144, height 112, width 0\n",
      "Patch extracted: depth 144, height 112, width 16\n",
      "Patch extracted: depth 144, height 112, width 32\n",
      "Patch extracted: depth 144, height 128, width 0\n",
      "Patch extracted: depth 144, height 128, width 16\n",
      "Patch extracted: depth 144, height 128, width 32\n",
      "Patch extracted: depth 144, height 144, width 0\n",
      "Patch extracted: depth 144, height 144, width 16\n",
      "Patch extracted: depth 144, height 144, width 32\n",
      "Patch extracted: depth 144, height 160, width 0\n",
      "Patch extracted: depth 144, height 160, width 16\n",
      "Patch extracted: depth 144, height 160, width 32\n",
      "Patch extracted: depth 144, height 176, width 0\n",
      "Patch extracted: depth 144, height 176, width 16\n",
      "Patch extracted: depth 144, height 176, width 32\n",
      "Patch extracted: depth 160, height 0, width 0\n",
      "Patch extracted: depth 160, height 0, width 16\n",
      "Patch extracted: depth 160, height 0, width 32\n",
      "Patch extracted: depth 160, height 16, width 0\n",
      "Patch extracted: depth 160, height 16, width 16\n",
      "Patch extracted: depth 160, height 16, width 32\n",
      "Patch extracted: depth 160, height 32, width 0\n",
      "Patch extracted: depth 160, height 32, width 16\n",
      "Patch extracted: depth 160, height 32, width 32\n",
      "Patch extracted: depth 160, height 48, width 0\n",
      "Patch extracted: depth 160, height 48, width 16\n",
      "Patch extracted: depth 160, height 48, width 32\n",
      "Patch extracted: depth 160, height 64, width 0\n",
      "Patch extracted: depth 160, height 64, width 16\n",
      "Patch extracted: depth 160, height 64, width 32\n",
      "Patch extracted: depth 160, height 80, width 0\n",
      "Patch extracted: depth 160, height 80, width 16\n",
      "Patch extracted: depth 160, height 80, width 32\n",
      "Patch extracted: depth 160, height 96, width 0\n",
      "Patch extracted: depth 160, height 96, width 16\n",
      "Patch extracted: depth 160, height 96, width 32\n",
      "Patch extracted: depth 160, height 112, width 0\n",
      "Patch extracted: depth 160, height 112, width 16\n",
      "Patch extracted: depth 160, height 112, width 32\n",
      "Patch extracted: depth 160, height 128, width 0\n",
      "Patch extracted: depth 160, height 128, width 16\n",
      "Patch extracted: depth 160, height 128, width 32\n",
      "Patch extracted: depth 160, height 144, width 0\n",
      "Patch extracted: depth 160, height 144, width 16\n",
      "Patch extracted: depth 160, height 144, width 32\n",
      "Patch extracted: depth 160, height 160, width 0\n",
      "Patch extracted: depth 160, height 160, width 16\n",
      "Patch extracted: depth 160, height 160, width 32\n",
      "Patch extracted: depth 160, height 176, width 0\n",
      "Patch extracted: depth 160, height 176, width 16\n",
      "Patch extracted: depth 160, height 176, width 32\n",
      "Patch extracted: depth 176, height 0, width 0\n",
      "Patch extracted: depth 176, height 0, width 16\n",
      "Patch extracted: depth 176, height 0, width 32\n",
      "Patch extracted: depth 176, height 16, width 0\n",
      "Patch extracted: depth 176, height 16, width 16\n",
      "Patch extracted: depth 176, height 16, width 32\n",
      "Patch extracted: depth 176, height 32, width 0\n",
      "Patch extracted: depth 176, height 32, width 16\n",
      "Patch extracted: depth 176, height 32, width 32\n",
      "Patch extracted: depth 176, height 48, width 0\n",
      "Patch extracted: depth 176, height 48, width 16\n",
      "Patch extracted: depth 176, height 48, width 32\n",
      "Patch extracted: depth 176, height 64, width 0\n",
      "Patch extracted: depth 176, height 64, width 16\n",
      "Patch extracted: depth 176, height 64, width 32\n",
      "Patch extracted: depth 176, height 80, width 0\n",
      "Patch extracted: depth 176, height 80, width 16\n",
      "Patch extracted: depth 176, height 80, width 32\n",
      "Patch extracted: depth 176, height 96, width 0\n",
      "Patch extracted: depth 176, height 96, width 16\n",
      "Patch extracted: depth 176, height 96, width 32\n",
      "Patch extracted: depth 176, height 112, width 0\n",
      "Patch extracted: depth 176, height 112, width 16\n",
      "Patch extracted: depth 176, height 112, width 32\n",
      "Patch extracted: depth 176, height 128, width 0\n",
      "Patch extracted: depth 176, height 128, width 16\n",
      "Patch extracted: depth 176, height 128, width 32\n",
      "Patch extracted: depth 176, height 144, width 0\n",
      "Patch extracted: depth 176, height 144, width 16\n",
      "Patch extracted: depth 176, height 144, width 32\n",
      "Patch extracted: depth 176, height 160, width 0\n",
      "Patch extracted: depth 176, height 160, width 16\n",
      "Patch extracted: depth 176, height 160, width 32\n",
      "Patch extracted: depth 176, height 176, width 0\n",
      "Patch extracted: depth 176, height 176, width 16\n",
      "Patch extracted: depth 176, height 176, width 32\n",
      "Total patches extracted: 432\n",
      " - Number of image patches extracted: 432\n",
      " - Number of mask patches extracted: 432\n",
      "Number of image patches: 3024\n"
     ]
    }
   ],
   "source": [
    "dataset = BrainSegmentationDataset(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6901037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.011753Z",
     "iopub.status.busy": "2024-10-21T06:17:47.010690Z",
     "iopub.status.idle": "2024-10-21T06:17:47.016917Z",
     "shell.execute_reply": "2024-10-21T06:17:47.015883Z"
    },
    "id": "FM-ePgNRhl7s",
    "outputId": "ae92b33a-4af5-48a8-a1a0-5b19465148e4",
    "papermill": {
     "duration": 0.033915,
     "end_time": "2024-10-21T06:17:47.019345",
     "exception": false,
     "start_time": "2024-10-21T06:17:46.985430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3024\n",
      "3024\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.patches_img))\n",
    "print(len(dataset.patches_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b5e5905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.070205Z",
     "iopub.status.busy": "2024-10-21T06:17:47.069728Z",
     "iopub.status.idle": "2024-10-21T06:17:47.082260Z",
     "shell.execute_reply": "2024-10-21T06:17:47.081417Z"
    },
    "id": "YbXxcm6sd0Km",
    "papermill": {
     "duration": 0.04029,
     "end_time": "2024-10-21T06:17:47.084346",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.044056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Validation split from dataset (20% validation, 80% training)\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8444ac39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.130791Z",
     "iopub.status.busy": "2024-10-21T06:17:47.130377Z",
     "iopub.status.idle": "2024-10-21T06:17:47.218957Z",
     "shell.execute_reply": "2024-10-21T06:17:47.217833Z"
    },
    "id": "XyUtNlVEGoCS",
    "outputId": "c7556226-8562-48ff-f859-95a10a36dd4e",
    "papermill": {
     "duration": 0.115232,
     "end_time": "2024-10-21T06:17:47.221731",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.106499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([16, 3, 64, 64, 16])\n",
      "Label shape: torch.Size([16, 64, 64, 16])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    # Print shapes of inputs and labels\n",
    "    print(f\"Input shape: {inputs.shape}\")\n",
    "    print(f\"Label shape: {labels.shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d62e52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.273906Z",
     "iopub.status.busy": "2024-10-21T06:17:47.273335Z",
     "iopub.status.idle": "2024-10-21T06:17:47.292827Z",
     "shell.execute_reply": "2024-10-21T06:17:47.291852Z"
    },
    "id": "UBimiRfQgG5E",
    "papermill": {
     "duration": 0.0476,
     "end_time": "2024-10-21T06:17:47.295138",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.247538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the 3D U-Net model with transition layers\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "\n",
    "        # Encoder with transition layers\n",
    "        self.encoder1 = self.contract_block(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.trans1 = nn.MaxPool3d(2)  # Downsampling layer\n",
    "        self.encoder2 = self.contract_block(32, 64, kernel_size=3, padding=1)\n",
    "        self.trans2 = nn.MaxPool3d(2)  # Downsampling layer\n",
    "        self.encoder3 = self.contract_block(64, 128, kernel_size=3, padding=1)\n",
    "        self.trans3 = nn.MaxPool3d(2)  # Downsampling layer\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Decoder with transition layers\n",
    "        self.uptrans3 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)  # Upsampling layer\n",
    "        self.decoder3 = self.expand_block(256, 128, kernel_size=3, padding=1)\n",
    "        self.uptrans2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)   # Upsampling layer\n",
    "        self.decoder2 = self.expand_block(128, 64, kernel_size=3, padding=1)\n",
    "        self.uptrans1 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)    # Upsampling layer\n",
    "        self.decoder1 = self.expand_block(64, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer - out_channels = number of classes (no softmax here)\n",
    "        self.out = nn.Conv3d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def expand_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.trans1(enc1))\n",
    "        enc3 = self.encoder3(self.trans2(enc2))\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.trans3(enc3))\n",
    "\n",
    "        # Decoder\n",
    "        dec3 = self.uptrans3(bottleneck)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)  # Skip connection\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.uptrans2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)  # Skip connection\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.uptrans1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)  # Skip connection\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        # Output layer with raw logits (no activation)\n",
    "        out = self.out(dec1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc018242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.346882Z",
     "iopub.status.busy": "2024-10-21T06:17:47.345900Z",
     "iopub.status.idle": "2024-10-21T06:17:47.351630Z",
     "shell.execute_reply": "2024-10-21T06:17:47.350558Z"
    },
    "id": "KvnEZbc3J_qV",
    "outputId": "a2d9e8e2-7739-406c-8077-302f98289d9b",
    "papermill": {
     "duration": 0.033957,
     "end_time": "2024-10-21T06:17:47.354487",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.320530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d59d812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.405895Z",
     "iopub.status.busy": "2024-10-21T06:17:47.405025Z",
     "iopub.status.idle": "2024-10-21T06:17:47.410669Z",
     "shell.execute_reply": "2024-10-21T06:17:47.409511Z"
    },
    "id": "rO2hIBClnqpG",
    "papermill": {
     "duration": 0.03517,
     "end_time": "2024-10-21T06:17:47.412898",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.377728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training settings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016f8cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.462257Z",
     "iopub.status.busy": "2024-10-21T06:17:47.461799Z",
     "iopub.status.idle": "2024-10-21T06:17:47.693687Z",
     "shell.execute_reply": "2024-10-21T06:17:47.692712Z"
    },
    "id": "Lc1FVehJUlqc",
    "outputId": "bcc11140-dc7d-4c16-e99b-129dfcd626fd",
    "papermill": {
     "duration": 0.25935,
     "end_time": "2024-10-21T06:17:47.695909",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.436559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (encoder1): Sequential(\n",
       "    (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (trans1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder2): Sequential(\n",
       "    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (trans2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder3): Sequential(\n",
       "    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (trans3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uptrans3): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder3): Sequential(\n",
       "    (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uptrans2): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder2): Sequential(\n",
       "    (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uptrans1): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder1): Sequential(\n",
       "    (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (out): Conv3d(32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = UNet3D(in_channels=3, out_channels=8)  # 8 labels to segment (excluding background)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e9f56d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.745383Z",
     "iopub.status.busy": "2024-10-21T06:17:47.744472Z",
     "iopub.status.idle": "2024-10-21T06:17:47.750393Z",
     "shell.execute_reply": "2024-10-21T06:17:47.749333Z"
    },
    "id": "9zQJOWd_UopF",
    "papermill": {
     "duration": 0.033419,
     "end_time": "2024-10-21T06:17:47.752606",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.719187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00000001, weight_decay=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97671a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.802284Z",
     "iopub.status.busy": "2024-10-21T06:17:47.801527Z",
     "iopub.status.idle": "2024-10-21T06:17:47.870614Z",
     "shell.execute_reply": "2024-10-21T06:17:47.869712Z"
    },
    "id": "S80H49-TrJhT",
    "papermill": {
     "duration": 0.096903,
     "end_time": "2024-10-21T06:17:47.873265",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.776362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"NaN detected in weights: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec3489a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.923786Z",
     "iopub.status.busy": "2024-10-21T06:17:47.923344Z",
     "iopub.status.idle": "2024-10-21T06:17:47.928373Z",
     "shell.execute_reply": "2024-10-21T06:17:47.927313Z"
    },
    "id": "PNCXNTN3hEeh",
    "papermill": {
     "duration": 0.033086,
     "end_time": "2024-10-21T06:17:47.930544",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.897458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4afef292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:47.977733Z",
     "iopub.status.busy": "2024-10-21T06:17:47.976883Z",
     "iopub.status.idle": "2024-10-21T06:17:47.981641Z",
     "shell.execute_reply": "2024-10-21T06:17:47.980618Z"
    },
    "id": "fHReW9a_hHaD",
    "papermill": {
     "duration": 0.029655,
     "end_time": "2024-10-21T06:17:47.983785",
     "exception": false,
     "start_time": "2024-10-21T06:17:47.954130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7cf670c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:48.033421Z",
     "iopub.status.busy": "2024-10-21T06:17:48.032695Z",
     "iopub.status.idle": "2024-10-21T06:17:48.037533Z",
     "shell.execute_reply": "2024-10-21T06:17:48.036525Z"
    },
    "id": "hbXqjbmOiguz",
    "papermill": {
     "duration": 0.032275,
     "end_time": "2024-10-21T06:17:48.039721",
     "exception": false,
     "start_time": "2024-10-21T06:17:48.007446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88acf6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:48.090071Z",
     "iopub.status.busy": "2024-10-21T06:17:48.089594Z",
     "iopub.status.idle": "2024-10-21T06:17:48.094599Z",
     "shell.execute_reply": "2024-10-21T06:17:48.093679Z"
    },
    "id": "qNY90SBnUpJ4",
    "papermill": {
     "duration": 0.032855,
     "end_time": "2024-10-21T06:17:48.096782",
     "exception": false,
     "start_time": "2024-10-21T06:17:48.063927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and validation loop\n",
    "scaler = GradScaler()  # For mixed precision training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05e0b62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:48.146268Z",
     "iopub.status.busy": "2024-10-21T06:17:48.145880Z",
     "iopub.status.idle": "2024-10-21T06:17:48.151529Z",
     "shell.execute_reply": "2024-10-21T06:17:48.150498Z"
    },
    "id": "j60JMUbHup9_",
    "papermill": {
     "duration": 0.032628,
     "end_time": "2024-10-21T06:17:48.153678",
     "exception": false,
     "start_time": "2024-10-21T06:17:48.121050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv3d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da83f02a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:48.202061Z",
     "iopub.status.busy": "2024-10-21T06:17:48.201316Z",
     "iopub.status.idle": "2024-10-21T06:17:48.239833Z",
     "shell.execute_reply": "2024-10-21T06:17:48.238864Z"
    },
    "id": "XzPdwFyBuq-y",
    "outputId": "cbcfac21-91d5-40d4-edc4-090cb59aaac3",
    "papermill": {
     "duration": 0.065187,
     "end_time": "2024-10-21T06:17:48.242230",
     "exception": false,
     "start_time": "2024-10-21T06:17:48.177043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (encoder1): Sequential(\n",
       "    (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (trans1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder2): Sequential(\n",
       "    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (trans2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder3): Sequential(\n",
       "    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (trans3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uptrans3): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder3): Sequential(\n",
       "    (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uptrans2): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder2): Sequential(\n",
       "    (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (uptrans1): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder1): Sequential(\n",
       "    (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (out): Conv3d(32, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "280527ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:48.292117Z",
     "iopub.status.busy": "2024-10-21T06:17:48.291024Z",
     "iopub.status.idle": "2024-10-21T06:17:48.297927Z",
     "shell.execute_reply": "2024-10-21T06:17:48.297078Z"
    },
    "id": "riEXZWjniN8a",
    "papermill": {
     "duration": 0.034158,
     "end_time": "2024-10-21T06:17:48.300135",
     "exception": false,
     "start_time": "2024-10-21T06:17:48.265977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(preds, labels):\n",
    "    # Apply softmax to get class probabilities\n",
    "    preds = torch.argmax(preds, dim=1)  # Get the class with the highest score along the channel dimension (class dimension)\n",
    "    \n",
    "    # Ensure labels have the correct shape (if labels are one-hot encoded, convert to class indices)\n",
    "    if labels.dim() == 4:  # For one-hot encoded labels\n",
    "        labels = torch.argmax(labels, dim=1)  # Convert one-hot encoded labels to class indices\n",
    "    \n",
    "    # Ensure preds and labels have the same shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise RuntimeError(f\"Shape mismatch: preds {preds.shape}, labels {labels.shape}\")\n",
    "    \n",
    "    # Calculate the number of correct predictions\n",
    "    correct = (preds == labels).float().sum()  # Count the correct pixel predictions\n",
    "    accuracy = correct / labels.numel()  # Normalize by the total number of pixels\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d58a4166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T06:17:48.349403Z",
     "iopub.status.busy": "2024-10-21T06:17:48.348438Z",
     "iopub.status.idle": "2024-10-21T14:06:35.959542Z",
     "shell.execute_reply": "2024-10-21T14:06:35.958212Z"
    },
    "papermill": {
     "duration": 28127.637791,
     "end_time": "2024-10-21T14:06:35.961982",
     "exception": false,
     "start_time": "2024-10-21T06:17:48.324191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Training Loss: 269.0076, Training Accuracy: 0.0297\n",
      "Validation Loss: 242.5052, Validation Accuracy: 0.0299\n",
      "New best validation loss: 242.5052, saving model.\n",
      "Epoch 2/1000\n",
      "Training Loss: 269.0257, Training Accuracy: 0.0297\n",
      "Validation Loss: 242.5034, Validation Accuracy: 0.0300\n",
      "New best validation loss: 242.5034, saving model.\n",
      "Epoch 3/1000\n",
      "Training Loss: 267.4359, Training Accuracy: 0.0298\n",
      "Validation Loss: 242.5016, Validation Accuracy: 0.0300\n",
      "New best validation loss: 242.5016, saving model.\n",
      "Epoch 4/1000\n",
      "Training Loss: 269.1222, Training Accuracy: 0.0300\n",
      "Validation Loss: 242.4998, Validation Accuracy: 0.0301\n",
      "New best validation loss: 242.4998, saving model.\n",
      "Epoch 5/1000\n",
      "Training Loss: 267.4166, Training Accuracy: 0.0300\n",
      "Validation Loss: 242.4979, Validation Accuracy: 0.0301\n",
      "New best validation loss: 242.4979, saving model.\n",
      "Epoch 6/1000\n",
      "Training Loss: 268.2319, Training Accuracy: 0.0300\n",
      "Validation Loss: 242.4961, Validation Accuracy: 0.0302\n",
      "New best validation loss: 242.4961, saving model.\n",
      "Epoch 7/1000\n",
      "Training Loss: 268.2274, Training Accuracy: 0.0301\n",
      "Validation Loss: 242.4943, Validation Accuracy: 0.0302\n",
      "New best validation loss: 242.4943, saving model.\n",
      "Epoch 8/1000\n",
      "Training Loss: 267.3227, Training Accuracy: 0.0301\n",
      "Validation Loss: 242.4925, Validation Accuracy: 0.0303\n",
      "New best validation loss: 242.4925, saving model.\n",
      "Epoch 9/1000\n",
      "Training Loss: 267.3518, Training Accuracy: 0.0304\n",
      "Validation Loss: 242.4907, Validation Accuracy: 0.0304\n",
      "New best validation loss: 242.4907, saving model.\n",
      "Epoch 10/1000\n",
      "Training Loss: 267.7273, Training Accuracy: 0.0304\n",
      "Validation Loss: 242.4889, Validation Accuracy: 0.0305\n",
      "New best validation loss: 242.4889, saving model.\n",
      "Epoch 11/1000\n",
      "Training Loss: 267.4639, Training Accuracy: 0.0304\n",
      "Validation Loss: 242.4871, Validation Accuracy: 0.0305\n",
      "New best validation loss: 242.4871, saving model.\n",
      "Epoch 12/1000\n",
      "Training Loss: 267.8913, Training Accuracy: 0.0304\n",
      "Validation Loss: 242.4853, Validation Accuracy: 0.0306\n",
      "New best validation loss: 242.4853, saving model.\n",
      "Epoch 13/1000\n",
      "Training Loss: 268.4309, Training Accuracy: 0.0306\n",
      "Validation Loss: 242.4835, Validation Accuracy: 0.0307\n",
      "New best validation loss: 242.4835, saving model.\n",
      "Epoch 14/1000\n",
      "Training Loss: 267.9108, Training Accuracy: 0.0307\n",
      "Validation Loss: 242.4817, Validation Accuracy: 0.0307\n",
      "New best validation loss: 242.4817, saving model.\n",
      "Epoch 15/1000\n",
      "Training Loss: 268.8014, Training Accuracy: 0.0307\n",
      "Validation Loss: 242.4799, Validation Accuracy: 0.0308\n",
      "New best validation loss: 242.4799, saving model.\n",
      "Epoch 16/1000\n",
      "Training Loss: 267.4368, Training Accuracy: 0.0308\n",
      "Validation Loss: 242.4781, Validation Accuracy: 0.0309\n",
      "New best validation loss: 242.4781, saving model.\n",
      "Epoch 17/1000\n",
      "Training Loss: 267.8343, Training Accuracy: 0.0309\n",
      "Validation Loss: 242.4763, Validation Accuracy: 0.0309\n",
      "New best validation loss: 242.4763, saving model.\n",
      "Epoch 18/1000\n",
      "Training Loss: 267.4089, Training Accuracy: 0.0309\n",
      "Validation Loss: 242.4745, Validation Accuracy: 0.0310\n",
      "New best validation loss: 242.4745, saving model.\n",
      "Epoch 19/1000\n",
      "Training Loss: 267.7032, Training Accuracy: 0.0311\n",
      "Validation Loss: 242.4727, Validation Accuracy: 0.0311\n",
      "New best validation loss: 242.4727, saving model.\n",
      "Epoch 20/1000\n",
      "Training Loss: 268.4441, Training Accuracy: 0.0310\n",
      "Validation Loss: 242.4710, Validation Accuracy: 0.0311\n",
      "New best validation loss: 242.4710, saving model.\n",
      "Epoch 21/1000\n",
      "Training Loss: 269.0707, Training Accuracy: 0.0313\n",
      "Validation Loss: 242.4692, Validation Accuracy: 0.0312\n",
      "New best validation loss: 242.4692, saving model.\n",
      "Epoch 22/1000\n",
      "Training Loss: 267.7397, Training Accuracy: 0.0311\n",
      "Validation Loss: 242.4674, Validation Accuracy: 0.0313\n",
      "New best validation loss: 242.4674, saving model.\n",
      "Epoch 23/1000\n",
      "Training Loss: 267.9449, Training Accuracy: 0.0313\n",
      "Validation Loss: 242.4656, Validation Accuracy: 0.0314\n",
      "New best validation loss: 242.4656, saving model.\n",
      "Epoch 24/1000\n",
      "Training Loss: 267.6472, Training Accuracy: 0.0314\n",
      "Validation Loss: 242.4639, Validation Accuracy: 0.0315\n",
      "New best validation loss: 242.4639, saving model.\n",
      "Epoch 25/1000\n",
      "Training Loss: 267.7154, Training Accuracy: 0.0314\n",
      "Validation Loss: 242.4621, Validation Accuracy: 0.0316\n",
      "New best validation loss: 242.4621, saving model.\n",
      "Epoch 26/1000\n",
      "Training Loss: 267.9029, Training Accuracy: 0.0314\n",
      "Validation Loss: 242.4603, Validation Accuracy: 0.0316\n",
      "New best validation loss: 242.4603, saving model.\n",
      "Epoch 27/1000\n",
      "Training Loss: 268.5293, Training Accuracy: 0.0316\n",
      "Validation Loss: 242.4586, Validation Accuracy: 0.0317\n",
      "New best validation loss: 242.4586, saving model.\n",
      "Epoch 28/1000\n",
      "Training Loss: 269.8810, Training Accuracy: 0.0316\n",
      "Validation Loss: 242.4568, Validation Accuracy: 0.0318\n",
      "New best validation loss: 242.4568, saving model.\n",
      "Epoch 29/1000\n",
      "Training Loss: 269.4767, Training Accuracy: 0.0318\n",
      "Validation Loss: 242.4551, Validation Accuracy: 0.0319\n",
      "New best validation loss: 242.4551, saving model.\n",
      "Epoch 30/1000\n",
      "Training Loss: 267.4552, Training Accuracy: 0.0317\n",
      "Validation Loss: 242.4533, Validation Accuracy: 0.0319\n",
      "New best validation loss: 242.4533, saving model.\n",
      "Epoch 31/1000\n",
      "Training Loss: 267.0511, Training Accuracy: 0.0317\n",
      "Validation Loss: 242.4516, Validation Accuracy: 0.0320\n",
      "New best validation loss: 242.4516, saving model.\n",
      "Epoch 32/1000\n",
      "Training Loss: 269.7595, Training Accuracy: 0.0318\n",
      "Validation Loss: 242.4498, Validation Accuracy: 0.0321\n",
      "New best validation loss: 242.4498, saving model.\n",
      "Epoch 33/1000\n",
      "Training Loss: 269.4547, Training Accuracy: 0.0320\n",
      "Validation Loss: 242.4481, Validation Accuracy: 0.0322\n",
      "New best validation loss: 242.4481, saving model.\n",
      "Epoch 34/1000\n",
      "Training Loss: 267.7080, Training Accuracy: 0.0322\n",
      "Validation Loss: 242.4464, Validation Accuracy: 0.0322\n",
      "New best validation loss: 242.4464, saving model.\n",
      "Epoch 35/1000\n",
      "Training Loss: 268.2545, Training Accuracy: 0.0322\n",
      "Validation Loss: 242.4446, Validation Accuracy: 0.0323\n",
      "New best validation loss: 242.4446, saving model.\n",
      "Epoch 36/1000\n",
      "Training Loss: 269.0569, Training Accuracy: 0.0321\n",
      "Validation Loss: 242.4429, Validation Accuracy: 0.0324\n",
      "New best validation loss: 242.4429, saving model.\n",
      "Epoch 37/1000\n",
      "Training Loss: 270.4130, Training Accuracy: 0.0321\n",
      "Validation Loss: 242.4412, Validation Accuracy: 0.0324\n",
      "New best validation loss: 242.4412, saving model.\n",
      "Epoch 38/1000\n",
      "Training Loss: 268.3223, Training Accuracy: 0.0322\n",
      "Validation Loss: 242.4394, Validation Accuracy: 0.0325\n",
      "New best validation loss: 242.4394, saving model.\n",
      "Epoch 39/1000\n",
      "Training Loss: 268.0051, Training Accuracy: 0.0322\n",
      "Validation Loss: 242.4377, Validation Accuracy: 0.0326\n",
      "New best validation loss: 242.4377, saving model.\n",
      "Epoch 40/1000\n",
      "Training Loss: 270.0095, Training Accuracy: 0.0323\n",
      "Validation Loss: 242.4360, Validation Accuracy: 0.0326\n",
      "New best validation loss: 242.4360, saving model.\n",
      "Epoch 41/1000\n",
      "Training Loss: 268.7143, Training Accuracy: 0.0323\n",
      "Validation Loss: 242.4343, Validation Accuracy: 0.0327\n",
      "New best validation loss: 242.4343, saving model.\n",
      "Epoch 42/1000\n",
      "Training Loss: 267.6072, Training Accuracy: 0.0324\n",
      "Validation Loss: 242.4325, Validation Accuracy: 0.0327\n",
      "New best validation loss: 242.4325, saving model.\n",
      "Epoch 43/1000\n",
      "Training Loss: 267.9750, Training Accuracy: 0.0325\n",
      "Validation Loss: 242.4308, Validation Accuracy: 0.0328\n",
      "New best validation loss: 242.4308, saving model.\n",
      "Epoch 44/1000\n",
      "Training Loss: 269.2767, Training Accuracy: 0.0327\n",
      "Validation Loss: 242.4291, Validation Accuracy: 0.0328\n",
      "New best validation loss: 242.4291, saving model.\n",
      "Epoch 45/1000\n",
      "Training Loss: 267.4563, Training Accuracy: 0.0327\n",
      "Validation Loss: 242.4273, Validation Accuracy: 0.0329\n",
      "New best validation loss: 242.4273, saving model.\n",
      "Epoch 46/1000\n",
      "Training Loss: 268.4498, Training Accuracy: 0.0329\n",
      "Validation Loss: 242.4256, Validation Accuracy: 0.0329\n",
      "New best validation loss: 242.4256, saving model.\n",
      "Epoch 47/1000\n",
      "Training Loss: 268.5162, Training Accuracy: 0.0327\n",
      "Validation Loss: 242.4239, Validation Accuracy: 0.0330\n",
      "New best validation loss: 242.4239, saving model.\n",
      "Epoch 48/1000\n",
      "Training Loss: 268.9739, Training Accuracy: 0.0327\n",
      "Validation Loss: 242.4222, Validation Accuracy: 0.0331\n",
      "New best validation loss: 242.4222, saving model.\n",
      "Epoch 49/1000\n",
      "Training Loss: 268.0578, Training Accuracy: 0.0328\n",
      "Validation Loss: 242.4204, Validation Accuracy: 0.0331\n",
      "New best validation loss: 242.4204, saving model.\n",
      "Epoch 50/1000\n",
      "Training Loss: 267.3452, Training Accuracy: 0.0328\n",
      "Validation Loss: 242.4187, Validation Accuracy: 0.0332\n",
      "New best validation loss: 242.4187, saving model.\n",
      "Epoch 51/1000\n",
      "Training Loss: 268.0105, Training Accuracy: 0.0330\n",
      "Validation Loss: 242.4170, Validation Accuracy: 0.0333\n",
      "New best validation loss: 242.4170, saving model.\n",
      "Epoch 52/1000\n",
      "Training Loss: 268.1208, Training Accuracy: 0.0330\n",
      "Validation Loss: 242.4153, Validation Accuracy: 0.0333\n",
      "New best validation loss: 242.4153, saving model.\n",
      "Epoch 53/1000\n",
      "Training Loss: 267.8499, Training Accuracy: 0.0331\n",
      "Validation Loss: 242.4136, Validation Accuracy: 0.0334\n",
      "New best validation loss: 242.4136, saving model.\n",
      "Epoch 54/1000\n",
      "Training Loss: 269.1833, Training Accuracy: 0.0332\n",
      "Validation Loss: 242.4120, Validation Accuracy: 0.0334\n",
      "New best validation loss: 242.4120, saving model.\n",
      "Epoch 55/1000\n",
      "Training Loss: 268.5994, Training Accuracy: 0.0332\n",
      "Validation Loss: 242.4103, Validation Accuracy: 0.0334\n",
      "New best validation loss: 242.4103, saving model.\n",
      "Epoch 56/1000\n",
      "Training Loss: 268.8761, Training Accuracy: 0.0332\n",
      "Validation Loss: 242.4086, Validation Accuracy: 0.0335\n",
      "New best validation loss: 242.4086, saving model.\n",
      "Epoch 57/1000\n",
      "Training Loss: 267.8838, Training Accuracy: 0.0334\n",
      "Validation Loss: 242.4070, Validation Accuracy: 0.0335\n",
      "New best validation loss: 242.4070, saving model.\n",
      "Epoch 58/1000\n",
      "Training Loss: 268.9389, Training Accuracy: 0.0334\n",
      "Validation Loss: 242.4053, Validation Accuracy: 0.0336\n",
      "New best validation loss: 242.4053, saving model.\n",
      "Epoch 59/1000\n",
      "Training Loss: 268.8408, Training Accuracy: 0.0335\n",
      "Validation Loss: 242.4037, Validation Accuracy: 0.0336\n",
      "New best validation loss: 242.4037, saving model.\n",
      "Epoch 60/1000\n",
      "Training Loss: 270.0993, Training Accuracy: 0.0334\n",
      "Validation Loss: 242.4020, Validation Accuracy: 0.0336\n",
      "New best validation loss: 242.4020, saving model.\n",
      "Epoch 61/1000\n",
      "Training Loss: 267.3803, Training Accuracy: 0.0335\n",
      "Validation Loss: 242.4004, Validation Accuracy: 0.0337\n",
      "New best validation loss: 242.4004, saving model.\n",
      "Epoch 62/1000\n",
      "Training Loss: 268.8723, Training Accuracy: 0.0335\n",
      "Validation Loss: 242.3988, Validation Accuracy: 0.0337\n",
      "New best validation loss: 242.3988, saving model.\n",
      "Epoch 63/1000\n",
      "Training Loss: 268.7306, Training Accuracy: 0.0336\n",
      "Validation Loss: 242.3971, Validation Accuracy: 0.0337\n",
      "New best validation loss: 242.3971, saving model.\n",
      "Epoch 64/1000\n",
      "Training Loss: 269.1308, Training Accuracy: 0.0339\n",
      "Validation Loss: 242.3955, Validation Accuracy: 0.0338\n",
      "New best validation loss: 242.3955, saving model.\n",
      "Epoch 65/1000\n",
      "Training Loss: 267.6415, Training Accuracy: 0.0338\n",
      "Validation Loss: 242.3939, Validation Accuracy: 0.0338\n",
      "New best validation loss: 242.3939, saving model.\n",
      "Epoch 66/1000\n",
      "Training Loss: 268.6962, Training Accuracy: 0.0338\n",
      "Validation Loss: 242.3923, Validation Accuracy: 0.0338\n",
      "New best validation loss: 242.3923, saving model.\n",
      "Epoch 67/1000\n",
      "Training Loss: 267.7140, Training Accuracy: 0.0338\n",
      "Validation Loss: 242.3908, Validation Accuracy: 0.0339\n",
      "New best validation loss: 242.3908, saving model.\n",
      "Epoch 68/1000\n",
      "Training Loss: 268.0878, Training Accuracy: 0.0338\n",
      "Validation Loss: 242.3892, Validation Accuracy: 0.0340\n",
      "New best validation loss: 242.3892, saving model.\n",
      "Epoch 69/1000\n",
      "Training Loss: 267.5158, Training Accuracy: 0.0341\n",
      "Validation Loss: 242.3876, Validation Accuracy: 0.0340\n",
      "New best validation loss: 242.3876, saving model.\n",
      "Epoch 70/1000\n",
      "Training Loss: 267.6564, Training Accuracy: 0.0341\n",
      "Validation Loss: 242.3861, Validation Accuracy: 0.0340\n",
      "New best validation loss: 242.3861, saving model.\n",
      "Epoch 71/1000\n",
      "Training Loss: 267.1866, Training Accuracy: 0.0340\n",
      "Validation Loss: 242.3845, Validation Accuracy: 0.0341\n",
      "New best validation loss: 242.3845, saving model.\n",
      "Epoch 72/1000\n",
      "Training Loss: 267.4814, Training Accuracy: 0.0340\n",
      "Validation Loss: 242.3830, Validation Accuracy: 0.0341\n",
      "New best validation loss: 242.3830, saving model.\n",
      "Epoch 73/1000\n",
      "Training Loss: 268.0040, Training Accuracy: 0.0341\n",
      "Validation Loss: 242.3814, Validation Accuracy: 0.0341\n",
      "New best validation loss: 242.3814, saving model.\n",
      "Epoch 74/1000\n",
      "Training Loss: 268.3731, Training Accuracy: 0.0343\n",
      "Validation Loss: 242.3799, Validation Accuracy: 0.0342\n",
      "New best validation loss: 242.3799, saving model.\n",
      "Epoch 75/1000\n",
      "Training Loss: 267.0677, Training Accuracy: 0.0342\n",
      "Validation Loss: 242.3783, Validation Accuracy: 0.0342\n",
      "New best validation loss: 242.3783, saving model.\n",
      "Epoch 76/1000\n",
      "Training Loss: 269.0322, Training Accuracy: 0.0343\n",
      "Validation Loss: 242.3768, Validation Accuracy: 0.0343\n",
      "New best validation loss: 242.3768, saving model.\n",
      "Epoch 77/1000\n",
      "Training Loss: 267.9429, Training Accuracy: 0.0343\n",
      "Validation Loss: 242.3753, Validation Accuracy: 0.0343\n",
      "New best validation loss: 242.3753, saving model.\n",
      "Epoch 78/1000\n",
      "Training Loss: 268.4272, Training Accuracy: 0.0343\n",
      "Validation Loss: 242.3738, Validation Accuracy: 0.0344\n",
      "New best validation loss: 242.3738, saving model.\n",
      "Epoch 79/1000\n",
      "Training Loss: 267.5515, Training Accuracy: 0.0343\n",
      "Validation Loss: 242.3723, Validation Accuracy: 0.0345\n",
      "New best validation loss: 242.3723, saving model.\n",
      "Epoch 80/1000\n",
      "Training Loss: 268.5858, Training Accuracy: 0.0345\n",
      "Validation Loss: 242.3708, Validation Accuracy: 0.0345\n",
      "New best validation loss: 242.3708, saving model.\n",
      "Epoch 81/1000\n",
      "Training Loss: 267.9648, Training Accuracy: 0.0346\n",
      "Validation Loss: 242.3693, Validation Accuracy: 0.0346\n",
      "New best validation loss: 242.3693, saving model.\n",
      "Epoch 82/1000\n",
      "Training Loss: 267.5227, Training Accuracy: 0.0346\n",
      "Validation Loss: 242.3678, Validation Accuracy: 0.0346\n",
      "New best validation loss: 242.3678, saving model.\n",
      "Epoch 83/1000\n",
      "Training Loss: 267.6633, Training Accuracy: 0.0349\n",
      "Validation Loss: 242.3663, Validation Accuracy: 0.0347\n",
      "New best validation loss: 242.3663, saving model.\n",
      "Epoch 84/1000\n",
      "Training Loss: 268.0056, Training Accuracy: 0.0347\n",
      "Validation Loss: 242.3648, Validation Accuracy: 0.0348\n",
      "New best validation loss: 242.3648, saving model.\n",
      "Epoch 85/1000\n",
      "Training Loss: 267.5012, Training Accuracy: 0.0349\n",
      "Validation Loss: 242.3633, Validation Accuracy: 0.0348\n",
      "New best validation loss: 242.3633, saving model.\n",
      "Epoch 86/1000\n",
      "Training Loss: 267.9270, Training Accuracy: 0.0349\n",
      "Validation Loss: 242.3618, Validation Accuracy: 0.0348\n",
      "New best validation loss: 242.3618, saving model.\n",
      "Epoch 87/1000\n",
      "Training Loss: 268.3296, Training Accuracy: 0.0348\n",
      "Validation Loss: 242.3603, Validation Accuracy: 0.0349\n",
      "New best validation loss: 242.3603, saving model.\n",
      "Epoch 88/1000\n",
      "Training Loss: 267.1886, Training Accuracy: 0.0349\n",
      "Validation Loss: 242.3589, Validation Accuracy: 0.0349\n",
      "New best validation loss: 242.3589, saving model.\n",
      "Epoch 89/1000\n",
      "Training Loss: 269.2245, Training Accuracy: 0.0349\n",
      "Validation Loss: 242.3574, Validation Accuracy: 0.0350\n",
      "New best validation loss: 242.3574, saving model.\n",
      "Epoch 90/1000\n",
      "Training Loss: 267.8369, Training Accuracy: 0.0350\n",
      "Validation Loss: 242.3559, Validation Accuracy: 0.0351\n",
      "New best validation loss: 242.3559, saving model.\n",
      "Epoch 91/1000\n",
      "Training Loss: 267.5457, Training Accuracy: 0.0351\n",
      "Validation Loss: 242.3545, Validation Accuracy: 0.0351\n",
      "New best validation loss: 242.3545, saving model.\n",
      "Epoch 92/1000\n",
      "Training Loss: 268.4471, Training Accuracy: 0.0352\n",
      "Validation Loss: 242.3530, Validation Accuracy: 0.0351\n",
      "New best validation loss: 242.3530, saving model.\n",
      "Epoch 93/1000\n",
      "Training Loss: 268.9155, Training Accuracy: 0.0353\n",
      "Validation Loss: 242.3516, Validation Accuracy: 0.0352\n",
      "New best validation loss: 242.3516, saving model.\n",
      "Epoch 94/1000\n",
      "Training Loss: 267.4188, Training Accuracy: 0.0354\n",
      "Validation Loss: 242.3501, Validation Accuracy: 0.0353\n",
      "New best validation loss: 242.3501, saving model.\n",
      "Epoch 95/1000\n",
      "Training Loss: 267.7834, Training Accuracy: 0.0353\n",
      "Validation Loss: 242.3487, Validation Accuracy: 0.0353\n",
      "New best validation loss: 242.3487, saving model.\n",
      "Epoch 96/1000\n",
      "Training Loss: 270.4871, Training Accuracy: 0.0355\n",
      "Validation Loss: 242.3472, Validation Accuracy: 0.0354\n",
      "New best validation loss: 242.3472, saving model.\n",
      "Epoch 97/1000\n",
      "Training Loss: 267.3609, Training Accuracy: 0.0354\n",
      "Validation Loss: 242.3458, Validation Accuracy: 0.0354\n",
      "New best validation loss: 242.3458, saving model.\n",
      "Epoch 98/1000\n",
      "Training Loss: 269.5706, Training Accuracy: 0.0355\n",
      "Validation Loss: 242.3443, Validation Accuracy: 0.0355\n",
      "New best validation loss: 242.3443, saving model.\n",
      "Epoch 99/1000\n",
      "Training Loss: 267.6830, Training Accuracy: 0.0355\n",
      "Validation Loss: 242.3429, Validation Accuracy: 0.0355\n",
      "New best validation loss: 242.3429, saving model.\n",
      "Epoch 100/1000\n",
      "Training Loss: 269.2404, Training Accuracy: 0.0357\n",
      "Validation Loss: 242.3415, Validation Accuracy: 0.0356\n",
      "New best validation loss: 242.3415, saving model.\n",
      "Epoch 101/1000\n",
      "Training Loss: 269.8541, Training Accuracy: 0.0357\n",
      "Validation Loss: 242.3400, Validation Accuracy: 0.0356\n",
      "New best validation loss: 242.3400, saving model.\n",
      "Epoch 102/1000\n",
      "Training Loss: 267.1388, Training Accuracy: 0.0357\n",
      "Validation Loss: 242.3386, Validation Accuracy: 0.0357\n",
      "New best validation loss: 242.3386, saving model.\n",
      "Epoch 103/1000\n",
      "Training Loss: 267.2611, Training Accuracy: 0.0358\n",
      "Validation Loss: 242.3372, Validation Accuracy: 0.0358\n",
      "New best validation loss: 242.3372, saving model.\n",
      "Epoch 104/1000\n",
      "Training Loss: 268.4696, Training Accuracy: 0.0358\n",
      "Validation Loss: 242.3358, Validation Accuracy: 0.0358\n",
      "New best validation loss: 242.3358, saving model.\n",
      "Epoch 105/1000\n",
      "Training Loss: 268.0643, Training Accuracy: 0.0360\n",
      "Validation Loss: 242.3344, Validation Accuracy: 0.0359\n",
      "New best validation loss: 242.3344, saving model.\n",
      "Epoch 106/1000\n",
      "Training Loss: 267.2312, Training Accuracy: 0.0360\n",
      "Validation Loss: 242.3329, Validation Accuracy: 0.0359\n",
      "New best validation loss: 242.3329, saving model.\n",
      "Epoch 107/1000\n",
      "Training Loss: 267.1773, Training Accuracy: 0.0360\n",
      "Validation Loss: 242.3315, Validation Accuracy: 0.0360\n",
      "New best validation loss: 242.3315, saving model.\n",
      "Epoch 108/1000\n",
      "Training Loss: 267.7246, Training Accuracy: 0.0360\n",
      "Validation Loss: 242.3301, Validation Accuracy: 0.0361\n",
      "New best validation loss: 242.3301, saving model.\n",
      "Epoch 109/1000\n",
      "Training Loss: 268.1459, Training Accuracy: 0.0362\n",
      "Validation Loss: 242.3287, Validation Accuracy: 0.0361\n",
      "New best validation loss: 242.3287, saving model.\n",
      "Epoch 110/1000\n",
      "Training Loss: 269.4692, Training Accuracy: 0.0362\n",
      "Validation Loss: 242.3273, Validation Accuracy: 0.0362\n",
      "New best validation loss: 242.3273, saving model.\n",
      "Epoch 111/1000\n",
      "Training Loss: 267.6458, Training Accuracy: 0.0362\n",
      "Validation Loss: 242.3259, Validation Accuracy: 0.0362\n",
      "New best validation loss: 242.3259, saving model.\n",
      "Epoch 112/1000\n",
      "Training Loss: 269.6441, Training Accuracy: 0.0362\n",
      "Validation Loss: 242.3245, Validation Accuracy: 0.0362\n",
      "New best validation loss: 242.3245, saving model.\n",
      "Epoch 113/1000\n",
      "Training Loss: 268.5781, Training Accuracy: 0.0363\n",
      "Validation Loss: 242.3231, Validation Accuracy: 0.0363\n",
      "New best validation loss: 242.3231, saving model.\n",
      "Epoch 114/1000\n",
      "Training Loss: 267.4000, Training Accuracy: 0.0364\n",
      "Validation Loss: 242.3218, Validation Accuracy: 0.0363\n",
      "New best validation loss: 242.3218, saving model.\n",
      "Epoch 115/1000\n",
      "Training Loss: 267.2115, Training Accuracy: 0.0365\n",
      "Validation Loss: 242.3204, Validation Accuracy: 0.0364\n",
      "New best validation loss: 242.3204, saving model.\n",
      "Epoch 116/1000\n",
      "Training Loss: 267.2072, Training Accuracy: 0.0365\n",
      "Validation Loss: 242.3190, Validation Accuracy: 0.0364\n",
      "New best validation loss: 242.3190, saving model.\n",
      "Epoch 117/1000\n",
      "Training Loss: 269.1310, Training Accuracy: 0.0365\n",
      "Validation Loss: 242.3176, Validation Accuracy: 0.0365\n",
      "New best validation loss: 242.3176, saving model.\n",
      "Epoch 118/1000\n",
      "Training Loss: 268.7406, Training Accuracy: 0.0366\n",
      "Validation Loss: 242.3162, Validation Accuracy: 0.0365\n",
      "New best validation loss: 242.3162, saving model.\n",
      "Epoch 119/1000\n",
      "Training Loss: 267.2967, Training Accuracy: 0.0367\n",
      "Validation Loss: 242.3148, Validation Accuracy: 0.0366\n",
      "New best validation loss: 242.3148, saving model.\n",
      "Epoch 120/1000\n",
      "Training Loss: 266.8711, Training Accuracy: 0.0368\n",
      "Validation Loss: 242.3135, Validation Accuracy: 0.0367\n",
      "New best validation loss: 242.3135, saving model.\n",
      "Epoch 121/1000\n",
      "Training Loss: 267.8825, Training Accuracy: 0.0367\n",
      "Validation Loss: 242.3121, Validation Accuracy: 0.0368\n",
      "New best validation loss: 242.3121, saving model.\n",
      "Epoch 122/1000\n",
      "Training Loss: 267.8897, Training Accuracy: 0.0368\n",
      "Validation Loss: 242.3107, Validation Accuracy: 0.0368\n",
      "New best validation loss: 242.3107, saving model.\n",
      "Epoch 123/1000\n",
      "Training Loss: 267.1802, Training Accuracy: 0.0370\n",
      "Validation Loss: 242.3093, Validation Accuracy: 0.0369\n",
      "New best validation loss: 242.3093, saving model.\n",
      "Epoch 124/1000\n",
      "Training Loss: 267.5332, Training Accuracy: 0.0369\n",
      "Validation Loss: 242.3080, Validation Accuracy: 0.0370\n",
      "New best validation loss: 242.3080, saving model.\n",
      "Epoch 125/1000\n",
      "Training Loss: 267.3405, Training Accuracy: 0.0371\n",
      "Validation Loss: 242.3066, Validation Accuracy: 0.0370\n",
      "New best validation loss: 242.3066, saving model.\n",
      "Epoch 126/1000\n",
      "Training Loss: 268.9286, Training Accuracy: 0.0371\n",
      "Validation Loss: 242.3052, Validation Accuracy: 0.0371\n",
      "New best validation loss: 242.3052, saving model.\n",
      "Epoch 127/1000\n",
      "Training Loss: 266.8414, Training Accuracy: 0.0371\n",
      "Validation Loss: 242.3039, Validation Accuracy: 0.0372\n",
      "New best validation loss: 242.3039, saving model.\n",
      "Epoch 128/1000\n",
      "Training Loss: 268.8635, Training Accuracy: 0.0373\n",
      "Validation Loss: 242.3025, Validation Accuracy: 0.0372\n",
      "New best validation loss: 242.3025, saving model.\n",
      "Epoch 129/1000\n",
      "Training Loss: 267.7152, Training Accuracy: 0.0375\n",
      "Validation Loss: 242.3012, Validation Accuracy: 0.0373\n",
      "New best validation loss: 242.3012, saving model.\n",
      "Epoch 130/1000\n",
      "Training Loss: 267.9024, Training Accuracy: 0.0374\n",
      "Validation Loss: 242.2998, Validation Accuracy: 0.0374\n",
      "New best validation loss: 242.2998, saving model.\n",
      "Epoch 131/1000\n",
      "Training Loss: 267.7060, Training Accuracy: 0.0375\n",
      "Validation Loss: 242.2985, Validation Accuracy: 0.0375\n",
      "New best validation loss: 242.2985, saving model.\n",
      "Epoch 132/1000\n",
      "Training Loss: 267.5276, Training Accuracy: 0.0375\n",
      "Validation Loss: 242.2971, Validation Accuracy: 0.0376\n",
      "New best validation loss: 242.2971, saving model.\n",
      "Epoch 133/1000\n",
      "Training Loss: 269.2648, Training Accuracy: 0.0375\n",
      "Validation Loss: 242.2958, Validation Accuracy: 0.0377\n",
      "New best validation loss: 242.2958, saving model.\n",
      "Epoch 134/1000\n",
      "Training Loss: 269.5090, Training Accuracy: 0.0377\n",
      "Validation Loss: 242.2944, Validation Accuracy: 0.0378\n",
      "New best validation loss: 242.2944, saving model.\n",
      "Epoch 135/1000\n",
      "Training Loss: 270.6555, Training Accuracy: 0.0378\n",
      "Validation Loss: 242.2931, Validation Accuracy: 0.0378\n",
      "New best validation loss: 242.2931, saving model.\n",
      "Epoch 136/1000\n",
      "Training Loss: 268.9700, Training Accuracy: 0.0378\n",
      "Validation Loss: 242.2917, Validation Accuracy: 0.0379\n",
      "New best validation loss: 242.2917, saving model.\n",
      "Epoch 137/1000\n",
      "Training Loss: 267.8307, Training Accuracy: 0.0379\n",
      "Validation Loss: 242.2904, Validation Accuracy: 0.0380\n",
      "New best validation loss: 242.2904, saving model.\n",
      "Epoch 138/1000\n",
      "Training Loss: 268.0776, Training Accuracy: 0.0380\n",
      "Validation Loss: 242.2890, Validation Accuracy: 0.0381\n",
      "New best validation loss: 242.2890, saving model.\n",
      "Epoch 139/1000\n",
      "Training Loss: 268.7713, Training Accuracy: 0.0381\n",
      "Validation Loss: 242.2877, Validation Accuracy: 0.0382\n",
      "New best validation loss: 242.2877, saving model.\n",
      "Epoch 140/1000\n",
      "Training Loss: 269.1769, Training Accuracy: 0.0383\n",
      "Validation Loss: 242.2864, Validation Accuracy: 0.0382\n",
      "New best validation loss: 242.2864, saving model.\n",
      "Epoch 141/1000\n",
      "Training Loss: 269.1631, Training Accuracy: 0.0382\n",
      "Validation Loss: 242.2850, Validation Accuracy: 0.0383\n",
      "New best validation loss: 242.2850, saving model.\n",
      "Epoch 142/1000\n",
      "Training Loss: 267.6113, Training Accuracy: 0.0383\n",
      "Validation Loss: 242.2837, Validation Accuracy: 0.0384\n",
      "New best validation loss: 242.2837, saving model.\n",
      "Epoch 143/1000\n",
      "Training Loss: 268.1083, Training Accuracy: 0.0386\n",
      "Validation Loss: 242.2823, Validation Accuracy: 0.0384\n",
      "New best validation loss: 242.2823, saving model.\n",
      "Epoch 144/1000\n",
      "Training Loss: 268.4774, Training Accuracy: 0.0384\n",
      "Validation Loss: 242.2810, Validation Accuracy: 0.0385\n",
      "New best validation loss: 242.2810, saving model.\n",
      "Epoch 145/1000\n",
      "Training Loss: 268.5039, Training Accuracy: 0.0386\n",
      "Validation Loss: 242.2797, Validation Accuracy: 0.0386\n",
      "New best validation loss: 242.2797, saving model.\n",
      "Epoch 146/1000\n",
      "Training Loss: 267.8666, Training Accuracy: 0.0386\n",
      "Validation Loss: 242.2784, Validation Accuracy: 0.0387\n",
      "New best validation loss: 242.2784, saving model.\n",
      "Epoch 147/1000\n",
      "Training Loss: 267.0292, Training Accuracy: 0.0386\n",
      "Validation Loss: 242.2770, Validation Accuracy: 0.0388\n",
      "New best validation loss: 242.2770, saving model.\n",
      "Epoch 148/1000\n",
      "Training Loss: 269.6724, Training Accuracy: 0.0389\n",
      "Validation Loss: 242.2757, Validation Accuracy: 0.0388\n",
      "New best validation loss: 242.2757, saving model.\n",
      "Epoch 149/1000\n",
      "Training Loss: 268.0985, Training Accuracy: 0.0388\n",
      "Validation Loss: 242.2744, Validation Accuracy: 0.0390\n",
      "New best validation loss: 242.2744, saving model.\n",
      "Epoch 150/1000\n",
      "Training Loss: 269.7852, Training Accuracy: 0.0390\n",
      "Validation Loss: 242.2731, Validation Accuracy: 0.0390\n",
      "New best validation loss: 242.2731, saving model.\n",
      "Epoch 151/1000\n",
      "Training Loss: 267.3207, Training Accuracy: 0.0392\n",
      "Validation Loss: 242.2718, Validation Accuracy: 0.0391\n",
      "New best validation loss: 242.2718, saving model.\n",
      "Epoch 152/1000\n",
      "Training Loss: 268.6983, Training Accuracy: 0.0392\n",
      "Validation Loss: 242.2704, Validation Accuracy: 0.0392\n",
      "New best validation loss: 242.2704, saving model.\n",
      "Epoch 153/1000\n",
      "Training Loss: 267.6446, Training Accuracy: 0.0393\n",
      "Validation Loss: 242.2691, Validation Accuracy: 0.0393\n",
      "New best validation loss: 242.2691, saving model.\n",
      "Epoch 154/1000\n",
      "Training Loss: 266.8306, Training Accuracy: 0.0394\n",
      "Validation Loss: 242.2678, Validation Accuracy: 0.0394\n",
      "New best validation loss: 242.2678, saving model.\n",
      "Epoch 155/1000\n",
      "Training Loss: 270.3022, Training Accuracy: 0.0396\n",
      "Validation Loss: 242.2665, Validation Accuracy: 0.0395\n",
      "New best validation loss: 242.2665, saving model.\n",
      "Epoch 156/1000\n",
      "Training Loss: 267.2714, Training Accuracy: 0.0395\n",
      "Validation Loss: 242.2652, Validation Accuracy: 0.0395\n",
      "New best validation loss: 242.2652, saving model.\n",
      "Epoch 157/1000\n",
      "Training Loss: 266.9974, Training Accuracy: 0.0397\n",
      "Validation Loss: 242.2639, Validation Accuracy: 0.0396\n",
      "New best validation loss: 242.2639, saving model.\n",
      "Epoch 158/1000\n",
      "Training Loss: 269.5473, Training Accuracy: 0.0398\n",
      "Validation Loss: 242.2626, Validation Accuracy: 0.0398\n",
      "New best validation loss: 242.2626, saving model.\n",
      "Epoch 159/1000\n",
      "Training Loss: 267.0339, Training Accuracy: 0.0399\n",
      "Validation Loss: 242.2612, Validation Accuracy: 0.0399\n",
      "New best validation loss: 242.2612, saving model.\n",
      "Epoch 160/1000\n",
      "Training Loss: 269.5164, Training Accuracy: 0.0400\n",
      "Validation Loss: 242.2600, Validation Accuracy: 0.0400\n",
      "New best validation loss: 242.2600, saving model.\n",
      "Epoch 161/1000\n",
      "Training Loss: 269.1255, Training Accuracy: 0.0400\n",
      "Validation Loss: 242.2586, Validation Accuracy: 0.0402\n",
      "New best validation loss: 242.2586, saving model.\n",
      "Epoch 162/1000\n",
      "Training Loss: 267.5074, Training Accuracy: 0.0403\n",
      "Validation Loss: 242.2573, Validation Accuracy: 0.0402\n",
      "New best validation loss: 242.2573, saving model.\n",
      "Epoch 163/1000\n",
      "Training Loss: 267.0657, Training Accuracy: 0.0404\n",
      "Validation Loss: 242.2560, Validation Accuracy: 0.0404\n",
      "New best validation loss: 242.2560, saving model.\n",
      "Epoch 164/1000\n",
      "Training Loss: 267.6415, Training Accuracy: 0.0404\n",
      "Validation Loss: 242.2547, Validation Accuracy: 0.0405\n",
      "New best validation loss: 242.2547, saving model.\n",
      "Epoch 165/1000\n",
      "Training Loss: 269.0218, Training Accuracy: 0.0405\n",
      "Validation Loss: 242.2534, Validation Accuracy: 0.0406\n",
      "New best validation loss: 242.2534, saving model.\n",
      "Epoch 166/1000\n",
      "Training Loss: 267.6683, Training Accuracy: 0.0407\n",
      "Validation Loss: 242.2521, Validation Accuracy: 0.0408\n",
      "New best validation loss: 242.2521, saving model.\n",
      "Epoch 167/1000\n",
      "Training Loss: 267.9019, Training Accuracy: 0.0408\n",
      "Validation Loss: 242.2508, Validation Accuracy: 0.0409\n",
      "New best validation loss: 242.2508, saving model.\n",
      "Epoch 168/1000\n",
      "Training Loss: 267.7234, Training Accuracy: 0.0411\n",
      "Validation Loss: 242.2495, Validation Accuracy: 0.0411\n",
      "New best validation loss: 242.2495, saving model.\n",
      "Epoch 169/1000\n",
      "Training Loss: 267.7239, Training Accuracy: 0.0411\n",
      "Validation Loss: 242.2481, Validation Accuracy: 0.0412\n",
      "New best validation loss: 242.2481, saving model.\n",
      "Epoch 170/1000\n",
      "Training Loss: 268.3606, Training Accuracy: 0.0412\n",
      "Validation Loss: 242.2469, Validation Accuracy: 0.0413\n",
      "New best validation loss: 242.2469, saving model.\n",
      "Epoch 171/1000\n",
      "Training Loss: 267.5856, Training Accuracy: 0.0415\n",
      "Validation Loss: 242.2455, Validation Accuracy: 0.0416\n",
      "New best validation loss: 242.2455, saving model.\n",
      "Epoch 172/1000\n",
      "Training Loss: 269.2174, Training Accuracy: 0.0416\n",
      "Validation Loss: 242.2442, Validation Accuracy: 0.0417\n",
      "New best validation loss: 242.2442, saving model.\n",
      "Epoch 173/1000\n",
      "Training Loss: 269.0695, Training Accuracy: 0.0417\n",
      "Validation Loss: 242.2429, Validation Accuracy: 0.0419\n",
      "New best validation loss: 242.2429, saving model.\n",
      "Epoch 174/1000\n",
      "Training Loss: 266.9768, Training Accuracy: 0.0419\n",
      "Validation Loss: 242.2416, Validation Accuracy: 0.0421\n",
      "New best validation loss: 242.2416, saving model.\n",
      "Epoch 175/1000\n",
      "Training Loss: 268.9482, Training Accuracy: 0.0421\n",
      "Validation Loss: 242.2403, Validation Accuracy: 0.0423\n",
      "New best validation loss: 242.2403, saving model.\n",
      "Epoch 176/1000\n",
      "Training Loss: 269.1081, Training Accuracy: 0.0423\n",
      "Validation Loss: 242.2390, Validation Accuracy: 0.0425\n",
      "New best validation loss: 242.2390, saving model.\n",
      "Epoch 177/1000\n",
      "Training Loss: 268.6420, Training Accuracy: 0.0425\n",
      "Validation Loss: 242.2377, Validation Accuracy: 0.0427\n",
      "New best validation loss: 242.2377, saving model.\n",
      "Epoch 178/1000\n",
      "Training Loss: 267.2305, Training Accuracy: 0.0425\n",
      "Validation Loss: 242.2364, Validation Accuracy: 0.0430\n",
      "New best validation loss: 242.2364, saving model.\n",
      "Epoch 179/1000\n",
      "Training Loss: 268.1297, Training Accuracy: 0.0429\n",
      "Validation Loss: 242.2351, Validation Accuracy: 0.0431\n",
      "New best validation loss: 242.2351, saving model.\n",
      "Epoch 180/1000\n",
      "Training Loss: 267.6766, Training Accuracy: 0.0430\n",
      "Validation Loss: 242.2338, Validation Accuracy: 0.0433\n",
      "New best validation loss: 242.2338, saving model.\n",
      "Epoch 181/1000\n",
      "Training Loss: 267.4309, Training Accuracy: 0.0433\n",
      "Validation Loss: 242.2325, Validation Accuracy: 0.0436\n",
      "New best validation loss: 242.2325, saving model.\n",
      "Epoch 182/1000\n",
      "Training Loss: 270.4778, Training Accuracy: 0.0435\n",
      "Validation Loss: 242.2312, Validation Accuracy: 0.0438\n",
      "New best validation loss: 242.2312, saving model.\n",
      "Epoch 183/1000\n",
      "Training Loss: 267.7647, Training Accuracy: 0.0439\n",
      "Validation Loss: 242.2298, Validation Accuracy: 0.0442\n",
      "New best validation loss: 242.2298, saving model.\n",
      "Epoch 184/1000\n",
      "Training Loss: 268.7222, Training Accuracy: 0.0442\n",
      "Validation Loss: 242.2285, Validation Accuracy: 0.0445\n",
      "New best validation loss: 242.2285, saving model.\n",
      "Epoch 185/1000\n",
      "Training Loss: 268.2757, Training Accuracy: 0.0444\n",
      "Validation Loss: 242.2272, Validation Accuracy: 0.0449\n",
      "New best validation loss: 242.2272, saving model.\n",
      "Epoch 186/1000\n",
      "Training Loss: 267.2403, Training Accuracy: 0.0447\n",
      "Validation Loss: 242.2259, Validation Accuracy: 0.0452\n",
      "New best validation loss: 242.2259, saving model.\n",
      "Epoch 187/1000\n",
      "Training Loss: 267.5335, Training Accuracy: 0.0452\n",
      "Validation Loss: 242.2246, Validation Accuracy: 0.0457\n",
      "New best validation loss: 242.2246, saving model.\n",
      "Epoch 188/1000\n",
      "Training Loss: 270.0642, Training Accuracy: 0.0456\n",
      "Validation Loss: 242.2233, Validation Accuracy: 0.0460\n",
      "New best validation loss: 242.2233, saving model.\n",
      "Epoch 189/1000\n",
      "Training Loss: 268.5754, Training Accuracy: 0.0461\n",
      "Validation Loss: 242.2219, Validation Accuracy: 0.0464\n",
      "New best validation loss: 242.2219, saving model.\n",
      "Epoch 190/1000\n",
      "Training Loss: 267.5060, Training Accuracy: 0.0464\n",
      "Validation Loss: 242.2206, Validation Accuracy: 0.0468\n",
      "New best validation loss: 242.2206, saving model.\n",
      "Epoch 191/1000\n",
      "Training Loss: 269.4939, Training Accuracy: 0.0467\n",
      "Validation Loss: 242.2193, Validation Accuracy: 0.0472\n",
      "New best validation loss: 242.2193, saving model.\n",
      "Epoch 192/1000\n",
      "Training Loss: 268.4794, Training Accuracy: 0.0472\n",
      "Validation Loss: 242.2180, Validation Accuracy: 0.0476\n",
      "New best validation loss: 242.2180, saving model.\n",
      "Epoch 193/1000\n",
      "Training Loss: 267.6110, Training Accuracy: 0.0475\n",
      "Validation Loss: 242.2166, Validation Accuracy: 0.0481\n",
      "New best validation loss: 242.2166, saving model.\n",
      "Epoch 194/1000\n",
      "Training Loss: 269.8079, Training Accuracy: 0.0480\n",
      "Validation Loss: 242.2153, Validation Accuracy: 0.0485\n",
      "New best validation loss: 242.2153, saving model.\n",
      "Epoch 195/1000\n",
      "Training Loss: 267.7549, Training Accuracy: 0.0484\n",
      "Validation Loss: 242.2140, Validation Accuracy: 0.0489\n",
      "New best validation loss: 242.2140, saving model.\n",
      "Epoch 196/1000\n",
      "Training Loss: 267.3841, Training Accuracy: 0.0488\n",
      "Validation Loss: 242.2126, Validation Accuracy: 0.0493\n",
      "New best validation loss: 242.2126, saving model.\n",
      "Epoch 197/1000\n",
      "Training Loss: 269.5781, Training Accuracy: 0.0492\n",
      "Validation Loss: 242.2113, Validation Accuracy: 0.0498\n",
      "New best validation loss: 242.2113, saving model.\n",
      "Epoch 198/1000\n",
      "Training Loss: 267.2332, Training Accuracy: 0.0496\n",
      "Validation Loss: 242.2100, Validation Accuracy: 0.0503\n",
      "New best validation loss: 242.2100, saving model.\n",
      "Epoch 199/1000\n",
      "Training Loss: 268.8061, Training Accuracy: 0.0503\n",
      "Validation Loss: 242.2087, Validation Accuracy: 0.0507\n",
      "New best validation loss: 242.2087, saving model.\n",
      "Epoch 200/1000\n",
      "Training Loss: 269.0830, Training Accuracy: 0.0503\n",
      "Validation Loss: 242.2073, Validation Accuracy: 0.0513\n",
      "New best validation loss: 242.2073, saving model.\n",
      "Epoch 201/1000\n",
      "Training Loss: 267.2521, Training Accuracy: 0.0509\n",
      "Validation Loss: 242.2060, Validation Accuracy: 0.0517\n",
      "New best validation loss: 242.2060, saving model.\n",
      "Epoch 202/1000\n",
      "Training Loss: 268.3183, Training Accuracy: 0.0513\n",
      "Validation Loss: 242.2047, Validation Accuracy: 0.0522\n",
      "New best validation loss: 242.2047, saving model.\n",
      "Epoch 203/1000\n",
      "Training Loss: 268.2190, Training Accuracy: 0.0517\n",
      "Validation Loss: 242.2034, Validation Accuracy: 0.0526\n",
      "New best validation loss: 242.2034, saving model.\n",
      "Epoch 204/1000\n",
      "Training Loss: 269.2399, Training Accuracy: 0.0524\n",
      "Validation Loss: 242.2021, Validation Accuracy: 0.0532\n",
      "New best validation loss: 242.2021, saving model.\n",
      "Epoch 205/1000\n",
      "Training Loss: 266.9676, Training Accuracy: 0.0527\n",
      "Validation Loss: 242.2008, Validation Accuracy: 0.0537\n",
      "New best validation loss: 242.2008, saving model.\n",
      "Epoch 206/1000\n",
      "Training Loss: 267.6603, Training Accuracy: 0.0532\n",
      "Validation Loss: 242.1995, Validation Accuracy: 0.0541\n",
      "New best validation loss: 242.1995, saving model.\n",
      "Epoch 207/1000\n",
      "Training Loss: 266.6426, Training Accuracy: 0.0538\n",
      "Validation Loss: 242.1981, Validation Accuracy: 0.0546\n",
      "New best validation loss: 242.1981, saving model.\n",
      "Epoch 208/1000\n",
      "Training Loss: 267.7322, Training Accuracy: 0.0539\n",
      "Validation Loss: 242.1968, Validation Accuracy: 0.0551\n",
      "New best validation loss: 242.1968, saving model.\n",
      "Epoch 209/1000\n",
      "Training Loss: 267.9569, Training Accuracy: 0.0544\n",
      "Validation Loss: 242.1955, Validation Accuracy: 0.0556\n",
      "New best validation loss: 242.1955, saving model.\n",
      "Epoch 210/1000\n",
      "Training Loss: 266.8810, Training Accuracy: 0.0554\n",
      "Validation Loss: 242.1942, Validation Accuracy: 0.0561\n",
      "New best validation loss: 242.1942, saving model.\n",
      "Epoch 211/1000\n",
      "Training Loss: 267.9295, Training Accuracy: 0.0553\n",
      "Validation Loss: 242.1929, Validation Accuracy: 0.0565\n",
      "New best validation loss: 242.1929, saving model.\n",
      "Epoch 212/1000\n",
      "Training Loss: 266.5555, Training Accuracy: 0.0560\n",
      "Validation Loss: 242.1915, Validation Accuracy: 0.0569\n",
      "New best validation loss: 242.1915, saving model.\n",
      "Epoch 213/1000\n",
      "Training Loss: 267.9594, Training Accuracy: 0.0559\n",
      "Validation Loss: 242.1902, Validation Accuracy: 0.0575\n",
      "New best validation loss: 242.1902, saving model.\n",
      "Epoch 214/1000\n",
      "Training Loss: 266.5020, Training Accuracy: 0.0567\n",
      "Validation Loss: 242.1889, Validation Accuracy: 0.0580\n",
      "New best validation loss: 242.1889, saving model.\n",
      "Epoch 215/1000\n",
      "Training Loss: 268.2713, Training Accuracy: 0.0574\n",
      "Validation Loss: 242.1876, Validation Accuracy: 0.0584\n",
      "New best validation loss: 242.1876, saving model.\n",
      "Epoch 216/1000\n",
      "Training Loss: 266.7678, Training Accuracy: 0.0582\n",
      "Validation Loss: 242.1862, Validation Accuracy: 0.0590\n",
      "New best validation loss: 242.1862, saving model.\n",
      "Epoch 217/1000\n",
      "Training Loss: 266.6344, Training Accuracy: 0.0580\n",
      "Validation Loss: 242.1849, Validation Accuracy: 0.0594\n",
      "New best validation loss: 242.1849, saving model.\n",
      "Epoch 218/1000\n",
      "Training Loss: 266.9676, Training Accuracy: 0.0586\n",
      "Validation Loss: 242.1836, Validation Accuracy: 0.0599\n",
      "New best validation loss: 242.1836, saving model.\n",
      "Epoch 219/1000\n",
      "Training Loss: 267.0566, Training Accuracy: 0.0590\n",
      "Validation Loss: 242.1823, Validation Accuracy: 0.0604\n",
      "New best validation loss: 242.1823, saving model.\n",
      "Epoch 220/1000\n",
      "Training Loss: 266.8710, Training Accuracy: 0.0595\n",
      "Validation Loss: 242.1810, Validation Accuracy: 0.0610\n",
      "New best validation loss: 242.1810, saving model.\n",
      "Epoch 221/1000\n",
      "Training Loss: 267.1792, Training Accuracy: 0.0600\n",
      "Validation Loss: 242.1797, Validation Accuracy: 0.0615\n",
      "New best validation loss: 242.1797, saving model.\n",
      "Epoch 222/1000\n",
      "Training Loss: 267.5276, Training Accuracy: 0.0607\n",
      "Validation Loss: 242.1784, Validation Accuracy: 0.0621\n",
      "New best validation loss: 242.1784, saving model.\n",
      "Epoch 223/1000\n",
      "Training Loss: 267.1624, Training Accuracy: 0.0612\n",
      "Validation Loss: 242.1771, Validation Accuracy: 0.0626\n",
      "New best validation loss: 242.1771, saving model.\n",
      "Epoch 224/1000\n",
      "Training Loss: 266.5833, Training Accuracy: 0.0616\n",
      "Validation Loss: 242.1757, Validation Accuracy: 0.0632\n",
      "New best validation loss: 242.1757, saving model.\n",
      "Epoch 225/1000\n",
      "Training Loss: 266.6361, Training Accuracy: 0.0620\n",
      "Validation Loss: 242.1744, Validation Accuracy: 0.0637\n",
      "New best validation loss: 242.1744, saving model.\n",
      "Epoch 226/1000\n",
      "Training Loss: 267.4138, Training Accuracy: 0.0627\n",
      "Validation Loss: 242.1731, Validation Accuracy: 0.0644\n",
      "New best validation loss: 242.1731, saving model.\n",
      "Epoch 227/1000\n",
      "Training Loss: 268.1314, Training Accuracy: 0.0631\n",
      "Validation Loss: 242.1718, Validation Accuracy: 0.0651\n",
      "New best validation loss: 242.1718, saving model.\n",
      "Epoch 228/1000\n",
      "Training Loss: 268.9754, Training Accuracy: 0.0640\n",
      "Validation Loss: 242.1705, Validation Accuracy: 0.0657\n",
      "New best validation loss: 242.1705, saving model.\n",
      "Epoch 229/1000\n",
      "Training Loss: 267.8078, Training Accuracy: 0.0648\n",
      "Validation Loss: 242.1691, Validation Accuracy: 0.0663\n",
      "New best validation loss: 242.1691, saving model.\n",
      "Epoch 230/1000\n",
      "Training Loss: 268.9118, Training Accuracy: 0.0649\n",
      "Validation Loss: 242.1678, Validation Accuracy: 0.0670\n",
      "New best validation loss: 242.1678, saving model.\n",
      "Epoch 231/1000\n",
      "Training Loss: 269.0215, Training Accuracy: 0.0657\n",
      "Validation Loss: 242.1665, Validation Accuracy: 0.0676\n",
      "New best validation loss: 242.1665, saving model.\n",
      "Epoch 232/1000\n",
      "Training Loss: 268.9415, Training Accuracy: 0.0662\n",
      "Validation Loss: 242.1652, Validation Accuracy: 0.0683\n",
      "New best validation loss: 242.1652, saving model.\n",
      "Epoch 233/1000\n",
      "Training Loss: 267.9272, Training Accuracy: 0.0667\n",
      "Validation Loss: 242.1639, Validation Accuracy: 0.0689\n",
      "New best validation loss: 242.1639, saving model.\n",
      "Epoch 234/1000\n",
      "Training Loss: 269.7975, Training Accuracy: 0.0668\n",
      "Validation Loss: 242.1626, Validation Accuracy: 0.0695\n",
      "New best validation loss: 242.1626, saving model.\n",
      "Epoch 235/1000\n",
      "Training Loss: 266.7866, Training Accuracy: 0.0680\n",
      "Validation Loss: 242.1613, Validation Accuracy: 0.0701\n",
      "New best validation loss: 242.1613, saving model.\n",
      "Epoch 236/1000\n",
      "Training Loss: 267.2433, Training Accuracy: 0.0685\n",
      "Validation Loss: 242.1599, Validation Accuracy: 0.0707\n",
      "New best validation loss: 242.1599, saving model.\n",
      "Epoch 237/1000\n",
      "Training Loss: 268.2313, Training Accuracy: 0.0691\n",
      "Validation Loss: 242.1586, Validation Accuracy: 0.0713\n",
      "New best validation loss: 242.1586, saving model.\n",
      "Epoch 238/1000\n",
      "Training Loss: 268.0956, Training Accuracy: 0.0697\n",
      "Validation Loss: 242.1573, Validation Accuracy: 0.0720\n",
      "New best validation loss: 242.1573, saving model.\n",
      "Epoch 239/1000\n",
      "Training Loss: 267.2437, Training Accuracy: 0.0698\n",
      "Validation Loss: 242.1560, Validation Accuracy: 0.0726\n",
      "New best validation loss: 242.1560, saving model.\n",
      "Epoch 240/1000\n",
      "Training Loss: 266.8826, Training Accuracy: 0.0711\n",
      "Validation Loss: 242.1547, Validation Accuracy: 0.0733\n",
      "New best validation loss: 242.1547, saving model.\n",
      "Epoch 241/1000\n",
      "Training Loss: 268.0601, Training Accuracy: 0.0715\n",
      "Validation Loss: 242.1534, Validation Accuracy: 0.0741\n",
      "New best validation loss: 242.1534, saving model.\n",
      "Epoch 242/1000\n",
      "Training Loss: 267.2295, Training Accuracy: 0.0727\n",
      "Validation Loss: 242.1520, Validation Accuracy: 0.0748\n",
      "New best validation loss: 242.1520, saving model.\n",
      "Epoch 243/1000\n",
      "Training Loss: 266.7706, Training Accuracy: 0.0723\n",
      "Validation Loss: 242.1507, Validation Accuracy: 0.0757\n",
      "New best validation loss: 242.1507, saving model.\n",
      "Epoch 244/1000\n",
      "Training Loss: 268.8365, Training Accuracy: 0.0733\n",
      "Validation Loss: 242.1494, Validation Accuracy: 0.0765\n",
      "New best validation loss: 242.1494, saving model.\n",
      "Epoch 245/1000\n",
      "Training Loss: 268.6728, Training Accuracy: 0.0739\n",
      "Validation Loss: 242.1481, Validation Accuracy: 0.0774\n",
      "New best validation loss: 242.1481, saving model.\n",
      "Epoch 246/1000\n",
      "Training Loss: 267.9695, Training Accuracy: 0.0754\n",
      "Validation Loss: 242.1468, Validation Accuracy: 0.0782\n",
      "New best validation loss: 242.1468, saving model.\n",
      "Epoch 247/1000\n",
      "Training Loss: 268.2617, Training Accuracy: 0.0758\n",
      "Validation Loss: 242.1455, Validation Accuracy: 0.0790\n",
      "New best validation loss: 242.1455, saving model.\n",
      "Epoch 248/1000\n",
      "Training Loss: 267.6500, Training Accuracy: 0.0772\n",
      "Validation Loss: 242.1441, Validation Accuracy: 0.0798\n",
      "New best validation loss: 242.1441, saving model.\n",
      "Epoch 249/1000\n",
      "Training Loss: 267.8144, Training Accuracy: 0.0775\n",
      "Validation Loss: 242.1428, Validation Accuracy: 0.0807\n",
      "New best validation loss: 242.1428, saving model.\n",
      "Epoch 250/1000\n",
      "Training Loss: 266.6718, Training Accuracy: 0.0783\n",
      "Validation Loss: 242.1415, Validation Accuracy: 0.0816\n",
      "New best validation loss: 242.1415, saving model.\n",
      "Epoch 251/1000\n",
      "Training Loss: 268.9432, Training Accuracy: 0.0787\n",
      "Validation Loss: 242.1401, Validation Accuracy: 0.0824\n",
      "New best validation loss: 242.1401, saving model.\n",
      "Epoch 252/1000\n",
      "Training Loss: 267.1880, Training Accuracy: 0.0793\n",
      "Validation Loss: 242.1388, Validation Accuracy: 0.0833\n",
      "New best validation loss: 242.1388, saving model.\n",
      "Epoch 253/1000\n",
      "Training Loss: 267.9035, Training Accuracy: 0.0807\n",
      "Validation Loss: 242.1375, Validation Accuracy: 0.0841\n",
      "New best validation loss: 242.1375, saving model.\n",
      "Epoch 254/1000\n",
      "Training Loss: 267.9402, Training Accuracy: 0.0812\n",
      "Validation Loss: 242.1361, Validation Accuracy: 0.0851\n",
      "New best validation loss: 242.1361, saving model.\n",
      "Epoch 255/1000\n",
      "Training Loss: 267.4427, Training Accuracy: 0.0819\n",
      "Validation Loss: 242.1348, Validation Accuracy: 0.0862\n",
      "New best validation loss: 242.1348, saving model.\n",
      "Epoch 256/1000\n",
      "Training Loss: 268.5098, Training Accuracy: 0.0833\n",
      "Validation Loss: 242.1335, Validation Accuracy: 0.0871\n",
      "New best validation loss: 242.1335, saving model.\n",
      "Epoch 257/1000\n",
      "Training Loss: 268.9812, Training Accuracy: 0.0840\n",
      "Validation Loss: 242.1322, Validation Accuracy: 0.0879\n",
      "New best validation loss: 242.1322, saving model.\n",
      "Epoch 258/1000\n",
      "Training Loss: 266.8136, Training Accuracy: 0.0849\n",
      "Validation Loss: 242.1308, Validation Accuracy: 0.0889\n",
      "New best validation loss: 242.1308, saving model.\n",
      "Epoch 259/1000\n",
      "Training Loss: 269.2190, Training Accuracy: 0.0855\n",
      "Validation Loss: 242.1295, Validation Accuracy: 0.0900\n",
      "New best validation loss: 242.1295, saving model.\n",
      "Epoch 260/1000\n",
      "Training Loss: 268.0675, Training Accuracy: 0.0868\n",
      "Validation Loss: 242.1282, Validation Accuracy: 0.0910\n",
      "New best validation loss: 242.1282, saving model.\n",
      "Epoch 261/1000\n",
      "Training Loss: 268.5766, Training Accuracy: 0.0876\n",
      "Validation Loss: 242.1268, Validation Accuracy: 0.0920\n",
      "New best validation loss: 242.1268, saving model.\n",
      "Epoch 262/1000\n",
      "Training Loss: 269.4497, Training Accuracy: 0.0882\n",
      "Validation Loss: 242.1255, Validation Accuracy: 0.0929\n",
      "New best validation loss: 242.1255, saving model.\n",
      "Epoch 263/1000\n",
      "Training Loss: 267.1312, Training Accuracy: 0.0890\n",
      "Validation Loss: 242.1241, Validation Accuracy: 0.0940\n",
      "New best validation loss: 242.1241, saving model.\n",
      "Epoch 264/1000\n",
      "Training Loss: 267.7559, Training Accuracy: 0.0900\n",
      "Validation Loss: 242.1228, Validation Accuracy: 0.0951\n",
      "New best validation loss: 242.1228, saving model.\n",
      "Epoch 265/1000\n",
      "Training Loss: 267.9287, Training Accuracy: 0.0919\n",
      "Validation Loss: 242.1215, Validation Accuracy: 0.0962\n",
      "New best validation loss: 242.1215, saving model.\n",
      "Epoch 266/1000\n",
      "Training Loss: 269.1256, Training Accuracy: 0.0923\n",
      "Validation Loss: 242.1201, Validation Accuracy: 0.0972\n",
      "New best validation loss: 242.1201, saving model.\n",
      "Epoch 267/1000\n",
      "Training Loss: 267.4451, Training Accuracy: 0.0929\n",
      "Validation Loss: 242.1188, Validation Accuracy: 0.0984\n",
      "New best validation loss: 242.1188, saving model.\n",
      "Epoch 268/1000\n",
      "Training Loss: 269.2044, Training Accuracy: 0.0937\n",
      "Validation Loss: 242.1175, Validation Accuracy: 0.0995\n",
      "New best validation loss: 242.1175, saving model.\n",
      "Epoch 269/1000\n",
      "Training Loss: 267.6731, Training Accuracy: 0.0953\n",
      "Validation Loss: 242.1161, Validation Accuracy: 0.1004\n",
      "New best validation loss: 242.1161, saving model.\n",
      "Epoch 270/1000\n",
      "Training Loss: 268.2791, Training Accuracy: 0.0960\n",
      "Validation Loss: 242.1148, Validation Accuracy: 0.1015\n",
      "New best validation loss: 242.1148, saving model.\n",
      "Epoch 271/1000\n",
      "Training Loss: 267.8903, Training Accuracy: 0.0975\n",
      "Validation Loss: 242.1134, Validation Accuracy: 0.1025\n",
      "New best validation loss: 242.1134, saving model.\n",
      "Epoch 272/1000\n",
      "Training Loss: 267.1247, Training Accuracy: 0.0995\n",
      "Validation Loss: 242.1121, Validation Accuracy: 0.1037\n",
      "New best validation loss: 242.1121, saving model.\n",
      "Epoch 273/1000\n",
      "Training Loss: 268.5284, Training Accuracy: 0.0999\n",
      "Validation Loss: 242.1107, Validation Accuracy: 0.1047\n",
      "New best validation loss: 242.1107, saving model.\n",
      "Epoch 274/1000\n",
      "Training Loss: 266.6991, Training Accuracy: 0.1006\n",
      "Validation Loss: 242.1094, Validation Accuracy: 0.1057\n",
      "New best validation loss: 242.1094, saving model.\n",
      "Epoch 275/1000\n",
      "Training Loss: 266.7789, Training Accuracy: 0.1007\n",
      "Validation Loss: 242.1080, Validation Accuracy: 0.1067\n",
      "New best validation loss: 242.1080, saving model.\n",
      "Epoch 276/1000\n",
      "Training Loss: 267.6497, Training Accuracy: 0.1018\n",
      "Validation Loss: 242.1066, Validation Accuracy: 0.1077\n",
      "New best validation loss: 242.1066, saving model.\n",
      "Epoch 277/1000\n",
      "Training Loss: 267.0014, Training Accuracy: 0.1039\n",
      "Validation Loss: 242.1053, Validation Accuracy: 0.1087\n",
      "New best validation loss: 242.1053, saving model.\n",
      "Epoch 278/1000\n",
      "Training Loss: 267.2523, Training Accuracy: 0.1038\n",
      "Validation Loss: 242.1039, Validation Accuracy: 0.1096\n",
      "New best validation loss: 242.1039, saving model.\n",
      "Epoch 279/1000\n",
      "Training Loss: 267.0275, Training Accuracy: 0.1049\n",
      "Validation Loss: 242.1025, Validation Accuracy: 0.1106\n",
      "New best validation loss: 242.1025, saving model.\n",
      "Epoch 280/1000\n",
      "Training Loss: 267.9744, Training Accuracy: 0.1060\n",
      "Validation Loss: 242.1012, Validation Accuracy: 0.1116\n",
      "New best validation loss: 242.1012, saving model.\n",
      "Epoch 281/1000\n",
      "Training Loss: 267.2660, Training Accuracy: 0.1062\n",
      "Validation Loss: 242.0998, Validation Accuracy: 0.1125\n",
      "New best validation loss: 242.0998, saving model.\n",
      "Epoch 282/1000\n",
      "Training Loss: 266.8946, Training Accuracy: 0.1076\n",
      "Validation Loss: 242.0984, Validation Accuracy: 0.1134\n",
      "New best validation loss: 242.0984, saving model.\n",
      "Epoch 283/1000\n",
      "Training Loss: 267.3733, Training Accuracy: 0.1080\n",
      "Validation Loss: 242.0970, Validation Accuracy: 0.1143\n",
      "New best validation loss: 242.0970, saving model.\n",
      "Epoch 284/1000\n",
      "Training Loss: 269.4741, Training Accuracy: 0.1089\n",
      "Validation Loss: 242.0956, Validation Accuracy: 0.1152\n",
      "New best validation loss: 242.0956, saving model.\n",
      "Epoch 285/1000\n",
      "Training Loss: 267.4464, Training Accuracy: 0.1100\n",
      "Validation Loss: 242.0943, Validation Accuracy: 0.1161\n",
      "New best validation loss: 242.0943, saving model.\n",
      "Epoch 286/1000\n",
      "Training Loss: 269.8811, Training Accuracy: 0.1108\n",
      "Validation Loss: 242.0929, Validation Accuracy: 0.1170\n",
      "New best validation loss: 242.0929, saving model.\n",
      "Epoch 287/1000\n",
      "Training Loss: 268.5067, Training Accuracy: 0.1117\n",
      "Validation Loss: 242.0915, Validation Accuracy: 0.1178\n",
      "New best validation loss: 242.0915, saving model.\n",
      "Epoch 288/1000\n",
      "Training Loss: 266.7853, Training Accuracy: 0.1121\n",
      "Validation Loss: 242.0901, Validation Accuracy: 0.1186\n",
      "New best validation loss: 242.0901, saving model.\n",
      "Epoch 289/1000\n",
      "Training Loss: 266.4040, Training Accuracy: 0.1138\n",
      "Validation Loss: 242.0887, Validation Accuracy: 0.1193\n",
      "New best validation loss: 242.0887, saving model.\n",
      "Epoch 290/1000\n",
      "Training Loss: 268.6323, Training Accuracy: 0.1140\n",
      "Validation Loss: 242.0873, Validation Accuracy: 0.1202\n",
      "New best validation loss: 242.0873, saving model.\n",
      "Epoch 291/1000\n",
      "Training Loss: 267.2697, Training Accuracy: 0.1145\n",
      "Validation Loss: 242.0859, Validation Accuracy: 0.1211\n",
      "New best validation loss: 242.0859, saving model.\n",
      "Epoch 292/1000\n",
      "Training Loss: 267.5797, Training Accuracy: 0.1162\n",
      "Validation Loss: 242.0845, Validation Accuracy: 0.1219\n",
      "New best validation loss: 242.0845, saving model.\n",
      "Epoch 293/1000\n",
      "Training Loss: 268.5933, Training Accuracy: 0.1165\n",
      "Validation Loss: 242.0831, Validation Accuracy: 0.1228\n",
      "New best validation loss: 242.0831, saving model.\n",
      "Epoch 294/1000\n",
      "Training Loss: 267.0735, Training Accuracy: 0.1167\n",
      "Validation Loss: 242.0817, Validation Accuracy: 0.1236\n",
      "New best validation loss: 242.0817, saving model.\n",
      "Epoch 295/1000\n",
      "Training Loss: 269.8538, Training Accuracy: 0.1176\n",
      "Validation Loss: 242.0803, Validation Accuracy: 0.1243\n",
      "New best validation loss: 242.0803, saving model.\n",
      "Epoch 296/1000\n",
      "Training Loss: 268.3843, Training Accuracy: 0.1187\n",
      "Validation Loss: 242.0789, Validation Accuracy: 0.1252\n",
      "New best validation loss: 242.0789, saving model.\n",
      "Epoch 297/1000\n",
      "Training Loss: 269.9618, Training Accuracy: 0.1190\n",
      "Validation Loss: 242.0775, Validation Accuracy: 0.1259\n",
      "New best validation loss: 242.0775, saving model.\n",
      "Epoch 298/1000\n",
      "Training Loss: 268.2827, Training Accuracy: 0.1193\n",
      "Validation Loss: 242.0761, Validation Accuracy: 0.1266\n",
      "New best validation loss: 242.0761, saving model.\n",
      "Epoch 299/1000\n",
      "Training Loss: 267.2232, Training Accuracy: 0.1205\n",
      "Validation Loss: 242.0747, Validation Accuracy: 0.1275\n",
      "New best validation loss: 242.0747, saving model.\n",
      "Epoch 300/1000\n",
      "Training Loss: 267.9484, Training Accuracy: 0.1205\n",
      "Validation Loss: 242.0732, Validation Accuracy: 0.1282\n",
      "New best validation loss: 242.0732, saving model.\n",
      "Epoch 301/1000\n",
      "Training Loss: 268.8380, Training Accuracy: 0.1220\n",
      "Validation Loss: 242.0718, Validation Accuracy: 0.1290\n",
      "New best validation loss: 242.0718, saving model.\n",
      "Epoch 302/1000\n",
      "Training Loss: 266.9197, Training Accuracy: 0.1225\n",
      "Validation Loss: 242.0703, Validation Accuracy: 0.1298\n",
      "New best validation loss: 242.0703, saving model.\n",
      "Epoch 303/1000\n",
      "Training Loss: 267.2220, Training Accuracy: 0.1230\n",
      "Validation Loss: 242.0689, Validation Accuracy: 0.1305\n",
      "New best validation loss: 242.0689, saving model.\n",
      "Epoch 304/1000\n",
      "Training Loss: 269.2875, Training Accuracy: 0.1236\n",
      "Validation Loss: 242.0675, Validation Accuracy: 0.1312\n",
      "New best validation loss: 242.0675, saving model.\n",
      "Epoch 305/1000\n",
      "Training Loss: 268.1800, Training Accuracy: 0.1251\n",
      "Validation Loss: 242.0660, Validation Accuracy: 0.1320\n",
      "New best validation loss: 242.0660, saving model.\n",
      "Epoch 306/1000\n",
      "Training Loss: 267.2765, Training Accuracy: 0.1252\n",
      "Validation Loss: 242.0646, Validation Accuracy: 0.1328\n",
      "New best validation loss: 242.0646, saving model.\n",
      "Epoch 307/1000\n",
      "Training Loss: 267.4683, Training Accuracy: 0.1262\n",
      "Validation Loss: 242.0631, Validation Accuracy: 0.1336\n",
      "New best validation loss: 242.0631, saving model.\n",
      "Epoch 308/1000\n",
      "Training Loss: 266.6616, Training Accuracy: 0.1267\n",
      "Validation Loss: 242.0616, Validation Accuracy: 0.1344\n",
      "New best validation loss: 242.0616, saving model.\n",
      "Epoch 309/1000\n",
      "Training Loss: 266.8932, Training Accuracy: 0.1276\n",
      "Validation Loss: 242.0602, Validation Accuracy: 0.1351\n",
      "New best validation loss: 242.0602, saving model.\n",
      "Epoch 310/1000\n",
      "Training Loss: 269.3050, Training Accuracy: 0.1279\n",
      "Validation Loss: 242.0587, Validation Accuracy: 0.1358\n",
      "New best validation loss: 242.0587, saving model.\n",
      "Epoch 311/1000\n",
      "Training Loss: 267.6068, Training Accuracy: 0.1286\n",
      "Validation Loss: 242.0572, Validation Accuracy: 0.1364\n",
      "New best validation loss: 242.0572, saving model.\n",
      "Epoch 312/1000\n",
      "Training Loss: 266.8427, Training Accuracy: 0.1294\n",
      "Validation Loss: 242.0558, Validation Accuracy: 0.1370\n",
      "New best validation loss: 242.0558, saving model.\n",
      "Epoch 313/1000\n",
      "Training Loss: 266.9433, Training Accuracy: 0.1298\n",
      "Validation Loss: 242.0543, Validation Accuracy: 0.1377\n",
      "New best validation loss: 242.0543, saving model.\n",
      "Epoch 314/1000\n",
      "Training Loss: 268.3252, Training Accuracy: 0.1300\n",
      "Validation Loss: 242.0528, Validation Accuracy: 0.1384\n",
      "New best validation loss: 242.0528, saving model.\n",
      "Epoch 315/1000\n",
      "Training Loss: 266.9800, Training Accuracy: 0.1313\n",
      "Validation Loss: 242.0513, Validation Accuracy: 0.1390\n",
      "New best validation loss: 242.0513, saving model.\n",
      "Epoch 316/1000\n",
      "Training Loss: 269.0055, Training Accuracy: 0.1314\n",
      "Validation Loss: 242.0498, Validation Accuracy: 0.1397\n",
      "New best validation loss: 242.0498, saving model.\n",
      "Epoch 317/1000\n",
      "Training Loss: 268.4982, Training Accuracy: 0.1321\n",
      "Validation Loss: 242.0484, Validation Accuracy: 0.1403\n",
      "New best validation loss: 242.0484, saving model.\n",
      "Epoch 318/1000\n",
      "Training Loss: 267.4243, Training Accuracy: 0.1333\n",
      "Validation Loss: 242.0469, Validation Accuracy: 0.1410\n",
      "New best validation loss: 242.0469, saving model.\n",
      "Epoch 319/1000\n",
      "Training Loss: 267.2516, Training Accuracy: 0.1338\n",
      "Validation Loss: 242.0454, Validation Accuracy: 0.1416\n",
      "New best validation loss: 242.0454, saving model.\n",
      "Epoch 320/1000\n",
      "Training Loss: 269.4500, Training Accuracy: 0.1341\n",
      "Validation Loss: 242.0439, Validation Accuracy: 0.1423\n",
      "New best validation loss: 242.0439, saving model.\n",
      "Epoch 321/1000\n",
      "Training Loss: 267.1579, Training Accuracy: 0.1347\n",
      "Validation Loss: 242.0424, Validation Accuracy: 0.1429\n",
      "New best validation loss: 242.0424, saving model.\n",
      "Epoch 322/1000\n",
      "Training Loss: 268.4319, Training Accuracy: 0.1352\n",
      "Validation Loss: 242.0409, Validation Accuracy: 0.1436\n",
      "New best validation loss: 242.0409, saving model.\n",
      "Epoch 323/1000\n",
      "Training Loss: 266.6472, Training Accuracy: 0.1352\n",
      "Validation Loss: 242.0394, Validation Accuracy: 0.1442\n",
      "New best validation loss: 242.0394, saving model.\n",
      "Epoch 324/1000\n",
      "Training Loss: 267.7070, Training Accuracy: 0.1366\n",
      "Validation Loss: 242.0379, Validation Accuracy: 0.1449\n",
      "New best validation loss: 242.0379, saving model.\n",
      "Epoch 325/1000\n",
      "Training Loss: 267.1245, Training Accuracy: 0.1374\n",
      "Validation Loss: 242.0363, Validation Accuracy: 0.1456\n",
      "New best validation loss: 242.0363, saving model.\n",
      "Epoch 326/1000\n",
      "Training Loss: 268.4019, Training Accuracy: 0.1371\n",
      "Validation Loss: 242.0348, Validation Accuracy: 0.1462\n",
      "New best validation loss: 242.0348, saving model.\n",
      "Epoch 327/1000\n",
      "Training Loss: 267.9704, Training Accuracy: 0.1381\n",
      "Validation Loss: 242.0333, Validation Accuracy: 0.1468\n",
      "New best validation loss: 242.0333, saving model.\n",
      "Epoch 328/1000\n",
      "Training Loss: 267.0724, Training Accuracy: 0.1388\n",
      "Validation Loss: 242.0318, Validation Accuracy: 0.1473\n",
      "New best validation loss: 242.0318, saving model.\n",
      "Epoch 329/1000\n",
      "Training Loss: 268.2012, Training Accuracy: 0.1394\n",
      "Validation Loss: 242.0302, Validation Accuracy: 0.1479\n",
      "New best validation loss: 242.0302, saving model.\n",
      "Epoch 330/1000\n",
      "Training Loss: 269.0218, Training Accuracy: 0.1390\n",
      "Validation Loss: 242.0287, Validation Accuracy: 0.1484\n",
      "New best validation loss: 242.0287, saving model.\n",
      "Epoch 331/1000\n",
      "Training Loss: 266.7284, Training Accuracy: 0.1408\n",
      "Validation Loss: 242.0272, Validation Accuracy: 0.1491\n",
      "New best validation loss: 242.0272, saving model.\n",
      "Epoch 332/1000\n",
      "Training Loss: 267.3471, Training Accuracy: 0.1413\n",
      "Validation Loss: 242.0257, Validation Accuracy: 0.1497\n",
      "New best validation loss: 242.0257, saving model.\n",
      "Epoch 333/1000\n",
      "Training Loss: 266.6418, Training Accuracy: 0.1422\n",
      "Validation Loss: 242.0241, Validation Accuracy: 0.1505\n",
      "New best validation loss: 242.0241, saving model.\n",
      "Epoch 334/1000\n",
      "Training Loss: 267.8967, Training Accuracy: 0.1419\n",
      "Validation Loss: 242.0226, Validation Accuracy: 0.1511\n",
      "New best validation loss: 242.0226, saving model.\n",
      "Epoch 335/1000\n",
      "Training Loss: 267.9725, Training Accuracy: 0.1425\n",
      "Validation Loss: 242.0210, Validation Accuracy: 0.1517\n",
      "New best validation loss: 242.0210, saving model.\n",
      "Epoch 336/1000\n",
      "Training Loss: 267.5724, Training Accuracy: 0.1434\n",
      "Validation Loss: 242.0195, Validation Accuracy: 0.1522\n",
      "New best validation loss: 242.0195, saving model.\n",
      "Epoch 337/1000\n",
      "Training Loss: 267.8426, Training Accuracy: 0.1439\n",
      "Validation Loss: 242.0179, Validation Accuracy: 0.1529\n",
      "New best validation loss: 242.0179, saving model.\n",
      "Epoch 338/1000\n",
      "Training Loss: 269.6211, Training Accuracy: 0.1443\n",
      "Validation Loss: 242.0164, Validation Accuracy: 0.1535\n",
      "New best validation loss: 242.0164, saving model.\n",
      "Epoch 339/1000\n",
      "Training Loss: 268.3326, Training Accuracy: 0.1456\n",
      "Validation Loss: 242.0148, Validation Accuracy: 0.1541\n",
      "New best validation loss: 242.0148, saving model.\n",
      "Epoch 340/1000\n",
      "Training Loss: 266.6221, Training Accuracy: 0.1471\n",
      "Validation Loss: 242.0132, Validation Accuracy: 0.1546\n",
      "New best validation loss: 242.0132, saving model.\n",
      "Epoch 341/1000\n",
      "Training Loss: 266.8285, Training Accuracy: 0.1472\n",
      "Validation Loss: 242.0116, Validation Accuracy: 0.1553\n",
      "New best validation loss: 242.0116, saving model.\n",
      "Epoch 342/1000\n",
      "Training Loss: 267.9851, Training Accuracy: 0.1467\n",
      "Validation Loss: 242.0101, Validation Accuracy: 0.1559\n",
      "New best validation loss: 242.0101, saving model.\n",
      "Epoch 343/1000\n",
      "Training Loss: 267.3766, Training Accuracy: 0.1476\n",
      "Validation Loss: 242.0085, Validation Accuracy: 0.1566\n",
      "New best validation loss: 242.0085, saving model.\n",
      "Epoch 344/1000\n",
      "Training Loss: 268.2999, Training Accuracy: 0.1486\n",
      "Validation Loss: 242.0069, Validation Accuracy: 0.1571\n",
      "New best validation loss: 242.0069, saving model.\n",
      "Epoch 345/1000\n",
      "Training Loss: 268.7616, Training Accuracy: 0.1489\n",
      "Validation Loss: 242.0054, Validation Accuracy: 0.1577\n",
      "New best validation loss: 242.0054, saving model.\n",
      "Epoch 346/1000\n",
      "Training Loss: 267.3066, Training Accuracy: 0.1498\n",
      "Validation Loss: 242.0038, Validation Accuracy: 0.1583\n",
      "New best validation loss: 242.0038, saving model.\n",
      "Epoch 347/1000\n",
      "Training Loss: 267.3774, Training Accuracy: 0.1504\n",
      "Validation Loss: 242.0022, Validation Accuracy: 0.1588\n",
      "New best validation loss: 242.0022, saving model.\n",
      "Epoch 348/1000\n",
      "Training Loss: 267.7086, Training Accuracy: 0.1505\n",
      "Validation Loss: 242.0006, Validation Accuracy: 0.1594\n",
      "New best validation loss: 242.0006, saving model.\n",
      "Epoch 349/1000\n",
      "Training Loss: 267.2700, Training Accuracy: 0.1524\n",
      "Validation Loss: 241.9991, Validation Accuracy: 0.1600\n",
      "New best validation loss: 241.9991, saving model.\n",
      "Epoch 350/1000\n",
      "Training Loss: 269.4441, Training Accuracy: 0.1513\n",
      "Validation Loss: 241.9975, Validation Accuracy: 0.1606\n",
      "New best validation loss: 241.9975, saving model.\n",
      "Epoch 351/1000\n",
      "Training Loss: 267.8087, Training Accuracy: 0.1518\n",
      "Validation Loss: 241.9959, Validation Accuracy: 0.1610\n",
      "New best validation loss: 241.9959, saving model.\n",
      "Epoch 352/1000\n",
      "Training Loss: 267.3736, Training Accuracy: 0.1523\n",
      "Validation Loss: 241.9943, Validation Accuracy: 0.1617\n",
      "New best validation loss: 241.9943, saving model.\n",
      "Epoch 353/1000\n",
      "Training Loss: 267.3800, Training Accuracy: 0.1540\n",
      "Validation Loss: 241.9927, Validation Accuracy: 0.1621\n",
      "New best validation loss: 241.9927, saving model.\n",
      "Epoch 354/1000\n",
      "Training Loss: 269.1164, Training Accuracy: 0.1535\n",
      "Validation Loss: 241.9911, Validation Accuracy: 0.1627\n",
      "New best validation loss: 241.9911, saving model.\n",
      "Epoch 355/1000\n",
      "Training Loss: 268.2790, Training Accuracy: 0.1547\n",
      "Validation Loss: 241.9895, Validation Accuracy: 0.1632\n",
      "New best validation loss: 241.9895, saving model.\n",
      "Epoch 356/1000\n",
      "Training Loss: 267.0093, Training Accuracy: 0.1554\n",
      "Validation Loss: 241.9879, Validation Accuracy: 0.1637\n",
      "New best validation loss: 241.9879, saving model.\n",
      "Epoch 357/1000\n",
      "Training Loss: 266.9448, Training Accuracy: 0.1552\n",
      "Validation Loss: 241.9863, Validation Accuracy: 0.1642\n",
      "New best validation loss: 241.9863, saving model.\n",
      "Epoch 358/1000\n",
      "Training Loss: 269.4982, Training Accuracy: 0.1554\n",
      "Validation Loss: 241.9847, Validation Accuracy: 0.1647\n",
      "New best validation loss: 241.9847, saving model.\n",
      "Epoch 359/1000\n",
      "Training Loss: 267.5338, Training Accuracy: 0.1566\n",
      "Validation Loss: 241.9831, Validation Accuracy: 0.1653\n",
      "New best validation loss: 241.9831, saving model.\n",
      "Epoch 360/1000\n",
      "Training Loss: 266.8976, Training Accuracy: 0.1567\n",
      "Validation Loss: 241.9815, Validation Accuracy: 0.1658\n",
      "New best validation loss: 241.9815, saving model.\n",
      "Epoch 361/1000\n",
      "Training Loss: 267.5527, Training Accuracy: 0.1572\n",
      "Validation Loss: 241.9799, Validation Accuracy: 0.1664\n",
      "New best validation loss: 241.9799, saving model.\n",
      "Epoch 362/1000\n",
      "Training Loss: 267.5525, Training Accuracy: 0.1577\n",
      "Validation Loss: 241.9783, Validation Accuracy: 0.1669\n",
      "New best validation loss: 241.9783, saving model.\n",
      "Epoch 363/1000\n",
      "Training Loss: 268.7908, Training Accuracy: 0.1588\n",
      "Validation Loss: 241.9766, Validation Accuracy: 0.1675\n",
      "New best validation loss: 241.9766, saving model.\n",
      "Epoch 364/1000\n",
      "Training Loss: 269.4562, Training Accuracy: 0.1587\n",
      "Validation Loss: 241.9750, Validation Accuracy: 0.1681\n",
      "New best validation loss: 241.9750, saving model.\n",
      "Epoch 365/1000\n",
      "Training Loss: 268.7648, Training Accuracy: 0.1589\n",
      "Validation Loss: 241.9734, Validation Accuracy: 0.1685\n",
      "New best validation loss: 241.9734, saving model.\n",
      "Epoch 366/1000\n",
      "Training Loss: 267.3753, Training Accuracy: 0.1607\n",
      "Validation Loss: 241.9718, Validation Accuracy: 0.1691\n",
      "New best validation loss: 241.9718, saving model.\n",
      "Epoch 367/1000\n",
      "Training Loss: 268.2552, Training Accuracy: 0.1604\n",
      "Validation Loss: 241.9702, Validation Accuracy: 0.1697\n",
      "New best validation loss: 241.9702, saving model.\n",
      "Epoch 368/1000\n",
      "Training Loss: 268.1446, Training Accuracy: 0.1604\n",
      "Validation Loss: 241.9686, Validation Accuracy: 0.1701\n",
      "New best validation loss: 241.9686, saving model.\n",
      "Epoch 369/1000\n",
      "Training Loss: 268.2538, Training Accuracy: 0.1611\n",
      "Validation Loss: 241.9669, Validation Accuracy: 0.1706\n",
      "New best validation loss: 241.9669, saving model.\n",
      "Epoch 370/1000\n",
      "Training Loss: 266.6984, Training Accuracy: 0.1619\n",
      "Validation Loss: 241.9653, Validation Accuracy: 0.1711\n",
      "New best validation loss: 241.9653, saving model.\n",
      "Epoch 371/1000\n",
      "Training Loss: 268.0327, Training Accuracy: 0.1620\n",
      "Validation Loss: 241.9637, Validation Accuracy: 0.1716\n",
      "New best validation loss: 241.9637, saving model.\n",
      "Epoch 372/1000\n",
      "Training Loss: 266.7726, Training Accuracy: 0.1628\n",
      "Validation Loss: 241.9621, Validation Accuracy: 0.1721\n",
      "New best validation loss: 241.9621, saving model.\n",
      "Epoch 373/1000\n",
      "Training Loss: 269.0505, Training Accuracy: 0.1628\n",
      "Validation Loss: 241.9604, Validation Accuracy: 0.1726\n",
      "New best validation loss: 241.9604, saving model.\n",
      "Epoch 374/1000\n",
      "Training Loss: 267.4164, Training Accuracy: 0.1639\n",
      "Validation Loss: 241.9588, Validation Accuracy: 0.1730\n",
      "New best validation loss: 241.9588, saving model.\n",
      "Epoch 375/1000\n",
      "Training Loss: 266.7822, Training Accuracy: 0.1640\n",
      "Validation Loss: 241.9572, Validation Accuracy: 0.1734\n",
      "New best validation loss: 241.9572, saving model.\n",
      "Epoch 376/1000\n",
      "Training Loss: 266.9084, Training Accuracy: 0.1649\n",
      "Validation Loss: 241.9555, Validation Accuracy: 0.1739\n",
      "New best validation loss: 241.9555, saving model.\n",
      "Epoch 377/1000\n",
      "Training Loss: 267.2004, Training Accuracy: 0.1646\n",
      "Validation Loss: 241.9539, Validation Accuracy: 0.1744\n",
      "New best validation loss: 241.9539, saving model.\n",
      "Epoch 378/1000\n",
      "Training Loss: 268.4553, Training Accuracy: 0.1644\n",
      "Validation Loss: 241.9523, Validation Accuracy: 0.1749\n",
      "New best validation loss: 241.9523, saving model.\n",
      "Epoch 379/1000\n",
      "Training Loss: 268.4184, Training Accuracy: 0.1653\n",
      "Validation Loss: 241.9506, Validation Accuracy: 0.1754\n",
      "New best validation loss: 241.9506, saving model.\n",
      "Epoch 380/1000\n",
      "Training Loss: 268.2968, Training Accuracy: 0.1654\n",
      "Validation Loss: 241.9490, Validation Accuracy: 0.1758\n",
      "New best validation loss: 241.9490, saving model.\n",
      "Epoch 381/1000\n",
      "Training Loss: 269.5848, Training Accuracy: 0.1659\n",
      "Validation Loss: 241.9473, Validation Accuracy: 0.1762\n",
      "New best validation loss: 241.9473, saving model.\n",
      "Epoch 382/1000\n",
      "Training Loss: 267.4015, Training Accuracy: 0.1670\n",
      "Validation Loss: 241.9457, Validation Accuracy: 0.1767\n",
      "New best validation loss: 241.9457, saving model.\n",
      "Epoch 383/1000\n",
      "Training Loss: 268.3681, Training Accuracy: 0.1671\n",
      "Validation Loss: 241.9440, Validation Accuracy: 0.1771\n",
      "New best validation loss: 241.9440, saving model.\n",
      "Epoch 384/1000\n",
      "Training Loss: 267.5452, Training Accuracy: 0.1681\n",
      "Validation Loss: 241.9424, Validation Accuracy: 0.1775\n",
      "New best validation loss: 241.9424, saving model.\n",
      "Epoch 385/1000\n",
      "Training Loss: 268.0277, Training Accuracy: 0.1681\n",
      "Validation Loss: 241.9407, Validation Accuracy: 0.1780\n",
      "New best validation loss: 241.9407, saving model.\n",
      "Epoch 386/1000\n",
      "Training Loss: 269.1511, Training Accuracy: 0.1680\n",
      "Validation Loss: 241.9391, Validation Accuracy: 0.1785\n",
      "New best validation loss: 241.9391, saving model.\n",
      "Epoch 387/1000\n",
      "Training Loss: 266.8651, Training Accuracy: 0.1690\n",
      "Validation Loss: 241.9374, Validation Accuracy: 0.1789\n",
      "New best validation loss: 241.9374, saving model.\n",
      "Epoch 388/1000\n",
      "Training Loss: 267.4729, Training Accuracy: 0.1703\n",
      "Validation Loss: 241.9357, Validation Accuracy: 0.1794\n",
      "New best validation loss: 241.9357, saving model.\n",
      "Epoch 389/1000\n",
      "Training Loss: 266.3952, Training Accuracy: 0.1714\n",
      "Validation Loss: 241.9341, Validation Accuracy: 0.1798\n",
      "New best validation loss: 241.9341, saving model.\n",
      "Epoch 390/1000\n",
      "Training Loss: 266.4992, Training Accuracy: 0.1708\n",
      "Validation Loss: 241.9324, Validation Accuracy: 0.1802\n",
      "New best validation loss: 241.9324, saving model.\n",
      "Epoch 391/1000\n",
      "Training Loss: 266.5600, Training Accuracy: 0.1715\n",
      "Validation Loss: 241.9307, Validation Accuracy: 0.1806\n",
      "New best validation loss: 241.9307, saving model.\n",
      "Epoch 392/1000\n",
      "Training Loss: 268.4713, Training Accuracy: 0.1709\n",
      "Validation Loss: 241.9291, Validation Accuracy: 0.1810\n",
      "New best validation loss: 241.9291, saving model.\n",
      "Epoch 393/1000\n",
      "Training Loss: 268.4223, Training Accuracy: 0.1706\n",
      "Validation Loss: 241.9274, Validation Accuracy: 0.1816\n",
      "New best validation loss: 241.9274, saving model.\n",
      "Epoch 394/1000\n",
      "Training Loss: 267.4978, Training Accuracy: 0.1720\n",
      "Validation Loss: 241.9257, Validation Accuracy: 0.1819\n",
      "New best validation loss: 241.9257, saving model.\n",
      "Epoch 395/1000\n",
      "Training Loss: 267.5572, Training Accuracy: 0.1721\n",
      "Validation Loss: 241.9241, Validation Accuracy: 0.1823\n",
      "New best validation loss: 241.9241, saving model.\n",
      "Epoch 396/1000\n",
      "Training Loss: 267.0400, Training Accuracy: 0.1722\n",
      "Validation Loss: 241.9224, Validation Accuracy: 0.1828\n",
      "New best validation loss: 241.9224, saving model.\n",
      "Epoch 397/1000\n",
      "Training Loss: 266.6358, Training Accuracy: 0.1741\n",
      "Validation Loss: 241.9207, Validation Accuracy: 0.1833\n",
      "New best validation loss: 241.9207, saving model.\n",
      "Epoch 398/1000\n",
      "Training Loss: 269.1507, Training Accuracy: 0.1733\n",
      "Validation Loss: 241.9190, Validation Accuracy: 0.1838\n",
      "New best validation loss: 241.9190, saving model.\n",
      "Epoch 399/1000\n",
      "Training Loss: 267.7824, Training Accuracy: 0.1740\n",
      "Validation Loss: 241.9173, Validation Accuracy: 0.1842\n",
      "New best validation loss: 241.9173, saving model.\n",
      "Epoch 400/1000\n",
      "Training Loss: 267.4048, Training Accuracy: 0.1746\n",
      "Validation Loss: 241.9156, Validation Accuracy: 0.1846\n",
      "New best validation loss: 241.9156, saving model.\n",
      "Epoch 401/1000\n",
      "Training Loss: 267.1736, Training Accuracy: 0.1748\n",
      "Validation Loss: 241.9139, Validation Accuracy: 0.1851\n",
      "New best validation loss: 241.9139, saving model.\n",
      "Epoch 402/1000\n",
      "Training Loss: 266.3885, Training Accuracy: 0.1757\n",
      "Validation Loss: 241.9122, Validation Accuracy: 0.1855\n",
      "New best validation loss: 241.9122, saving model.\n",
      "Epoch 403/1000\n",
      "Training Loss: 267.3215, Training Accuracy: 0.1751\n",
      "Validation Loss: 241.9105, Validation Accuracy: 0.1859\n",
      "New best validation loss: 241.9105, saving model.\n",
      "Epoch 404/1000\n",
      "Training Loss: 269.9484, Training Accuracy: 0.1748\n",
      "Validation Loss: 241.9089, Validation Accuracy: 0.1864\n",
      "New best validation loss: 241.9089, saving model.\n",
      "Epoch 405/1000\n",
      "Training Loss: 268.2845, Training Accuracy: 0.1759\n",
      "Validation Loss: 241.9071, Validation Accuracy: 0.1868\n",
      "New best validation loss: 241.9071, saving model.\n",
      "Epoch 406/1000\n",
      "Training Loss: 268.3764, Training Accuracy: 0.1764\n",
      "Validation Loss: 241.9054, Validation Accuracy: 0.1872\n",
      "New best validation loss: 241.9054, saving model.\n",
      "Epoch 407/1000\n",
      "Training Loss: 269.4112, Training Accuracy: 0.1766\n",
      "Validation Loss: 241.9037, Validation Accuracy: 0.1876\n",
      "New best validation loss: 241.9037, saving model.\n",
      "Epoch 408/1000\n",
      "Training Loss: 270.1741, Training Accuracy: 0.1774\n",
      "Validation Loss: 241.9020, Validation Accuracy: 0.1880\n",
      "New best validation loss: 241.9020, saving model.\n",
      "Epoch 409/1000\n",
      "Training Loss: 266.8026, Training Accuracy: 0.1774\n",
      "Validation Loss: 241.9003, Validation Accuracy: 0.1884\n",
      "New best validation loss: 241.9003, saving model.\n",
      "Epoch 410/1000\n",
      "Training Loss: 270.1706, Training Accuracy: 0.1775\n",
      "Validation Loss: 241.8986, Validation Accuracy: 0.1888\n",
      "New best validation loss: 241.8986, saving model.\n",
      "Epoch 411/1000\n",
      "Training Loss: 268.5636, Training Accuracy: 0.1783\n",
      "Validation Loss: 241.8969, Validation Accuracy: 0.1891\n",
      "New best validation loss: 241.8969, saving model.\n",
      "Epoch 412/1000\n",
      "Training Loss: 267.8966, Training Accuracy: 0.1795\n",
      "Validation Loss: 241.8952, Validation Accuracy: 0.1895\n",
      "New best validation loss: 241.8952, saving model.\n",
      "Epoch 413/1000\n",
      "Training Loss: 268.0993, Training Accuracy: 0.1787\n",
      "Validation Loss: 241.8935, Validation Accuracy: 0.1899\n",
      "New best validation loss: 241.8935, saving model.\n",
      "Epoch 414/1000\n",
      "Training Loss: 267.3291, Training Accuracy: 0.1794\n",
      "Validation Loss: 241.8918, Validation Accuracy: 0.1901\n",
      "New best validation loss: 241.8918, saving model.\n",
      "Epoch 415/1000\n",
      "Training Loss: 267.6270, Training Accuracy: 0.1795\n",
      "Validation Loss: 241.8901, Validation Accuracy: 0.1905\n",
      "New best validation loss: 241.8901, saving model.\n",
      "Epoch 416/1000\n",
      "Training Loss: 268.5696, Training Accuracy: 0.1802\n",
      "Validation Loss: 241.8884, Validation Accuracy: 0.1909\n",
      "New best validation loss: 241.8884, saving model.\n",
      "Epoch 417/1000\n",
      "Training Loss: 267.4226, Training Accuracy: 0.1801\n",
      "Validation Loss: 241.8866, Validation Accuracy: 0.1913\n",
      "New best validation loss: 241.8866, saving model.\n",
      "Epoch 418/1000\n",
      "Training Loss: 266.9728, Training Accuracy: 0.1812\n",
      "Validation Loss: 241.8849, Validation Accuracy: 0.1917\n",
      "New best validation loss: 241.8849, saving model.\n",
      "Epoch 419/1000\n",
      "Training Loss: 268.0662, Training Accuracy: 0.1812\n",
      "Validation Loss: 241.8832, Validation Accuracy: 0.1921\n",
      "New best validation loss: 241.8832, saving model.\n",
      "Epoch 420/1000\n",
      "Training Loss: 266.9741, Training Accuracy: 0.1817\n",
      "Validation Loss: 241.8815, Validation Accuracy: 0.1925\n",
      "New best validation loss: 241.8815, saving model.\n",
      "Epoch 421/1000\n",
      "Training Loss: 266.9067, Training Accuracy: 0.1832\n",
      "Validation Loss: 241.8797, Validation Accuracy: 0.1928\n",
      "New best validation loss: 241.8797, saving model.\n",
      "Epoch 422/1000\n",
      "Training Loss: 267.6695, Training Accuracy: 0.1822\n",
      "Validation Loss: 241.8780, Validation Accuracy: 0.1931\n",
      "New best validation loss: 241.8780, saving model.\n",
      "Epoch 423/1000\n",
      "Training Loss: 266.7564, Training Accuracy: 0.1831\n",
      "Validation Loss: 241.8763, Validation Accuracy: 0.1935\n",
      "New best validation loss: 241.8763, saving model.\n",
      "Epoch 424/1000\n",
      "Training Loss: 267.3872, Training Accuracy: 0.1834\n",
      "Validation Loss: 241.8745, Validation Accuracy: 0.1938\n",
      "New best validation loss: 241.8745, saving model.\n",
      "Epoch 425/1000\n",
      "Training Loss: 266.4236, Training Accuracy: 0.1835\n",
      "Validation Loss: 241.8728, Validation Accuracy: 0.1942\n",
      "New best validation loss: 241.8728, saving model.\n",
      "Epoch 426/1000\n",
      "Training Loss: 267.8602, Training Accuracy: 0.1839\n",
      "Validation Loss: 241.8711, Validation Accuracy: 0.1945\n",
      "New best validation loss: 241.8711, saving model.\n",
      "Epoch 427/1000\n",
      "Training Loss: 267.0039, Training Accuracy: 0.1842\n",
      "Validation Loss: 241.8693, Validation Accuracy: 0.1949\n",
      "New best validation loss: 241.8693, saving model.\n",
      "Epoch 428/1000\n",
      "Training Loss: 268.7162, Training Accuracy: 0.1845\n",
      "Validation Loss: 241.8676, Validation Accuracy: 0.1952\n",
      "New best validation loss: 241.8676, saving model.\n",
      "Epoch 429/1000\n",
      "Training Loss: 269.1258, Training Accuracy: 0.1850\n",
      "Validation Loss: 241.8658, Validation Accuracy: 0.1956\n",
      "New best validation loss: 241.8658, saving model.\n",
      "Epoch 430/1000\n",
      "Training Loss: 266.6080, Training Accuracy: 0.1856\n",
      "Validation Loss: 241.8641, Validation Accuracy: 0.1960\n",
      "New best validation loss: 241.8641, saving model.\n",
      "Epoch 431/1000\n",
      "Training Loss: 267.4794, Training Accuracy: 0.1862\n",
      "Validation Loss: 241.8623, Validation Accuracy: 0.1963\n",
      "New best validation loss: 241.8623, saving model.\n",
      "Epoch 432/1000\n",
      "Training Loss: 267.3698, Training Accuracy: 0.1856\n",
      "Validation Loss: 241.8606, Validation Accuracy: 0.1967\n",
      "New best validation loss: 241.8606, saving model.\n",
      "Epoch 433/1000\n",
      "Training Loss: 266.7817, Training Accuracy: 0.1865\n",
      "Validation Loss: 241.8588, Validation Accuracy: 0.1969\n",
      "New best validation loss: 241.8588, saving model.\n",
      "Epoch 434/1000\n",
      "Training Loss: 268.9340, Training Accuracy: 0.1863\n",
      "Validation Loss: 241.8571, Validation Accuracy: 0.1973\n",
      "New best validation loss: 241.8571, saving model.\n",
      "Epoch 435/1000\n",
      "Training Loss: 267.1032, Training Accuracy: 0.1866\n",
      "Validation Loss: 241.8553, Validation Accuracy: 0.1976\n",
      "New best validation loss: 241.8553, saving model.\n",
      "Epoch 436/1000\n",
      "Training Loss: 267.6919, Training Accuracy: 0.1876\n",
      "Validation Loss: 241.8536, Validation Accuracy: 0.1980\n",
      "New best validation loss: 241.8536, saving model.\n",
      "Epoch 437/1000\n",
      "Training Loss: 267.5331, Training Accuracy: 0.1876\n",
      "Validation Loss: 241.8518, Validation Accuracy: 0.1983\n",
      "New best validation loss: 241.8518, saving model.\n",
      "Epoch 438/1000\n",
      "Training Loss: 268.9426, Training Accuracy: 0.1876\n",
      "Validation Loss: 241.8501, Validation Accuracy: 0.1986\n",
      "New best validation loss: 241.8501, saving model.\n",
      "Epoch 439/1000\n",
      "Training Loss: 267.2443, Training Accuracy: 0.1886\n",
      "Validation Loss: 241.8483, Validation Accuracy: 0.1989\n",
      "New best validation loss: 241.8483, saving model.\n",
      "Epoch 440/1000\n",
      "Training Loss: 267.9230, Training Accuracy: 0.1883\n",
      "Validation Loss: 241.8465, Validation Accuracy: 0.1992\n",
      "New best validation loss: 241.8465, saving model.\n",
      "Epoch 441/1000\n",
      "Training Loss: 268.8198, Training Accuracy: 0.1883\n",
      "Validation Loss: 241.8448, Validation Accuracy: 0.1995\n",
      "New best validation loss: 241.8448, saving model.\n",
      "Epoch 442/1000\n",
      "Training Loss: 266.7804, Training Accuracy: 0.1890\n",
      "Validation Loss: 241.8430, Validation Accuracy: 0.1998\n",
      "New best validation loss: 241.8430, saving model.\n",
      "Epoch 443/1000\n",
      "Training Loss: 266.9785, Training Accuracy: 0.1895\n",
      "Validation Loss: 241.8413, Validation Accuracy: 0.2001\n",
      "New best validation loss: 241.8413, saving model.\n",
      "Epoch 444/1000\n",
      "Training Loss: 267.8028, Training Accuracy: 0.1895\n",
      "Validation Loss: 241.8395, Validation Accuracy: 0.2004\n",
      "New best validation loss: 241.8395, saving model.\n",
      "Epoch 445/1000\n",
      "Training Loss: 266.2311, Training Accuracy: 0.1903\n",
      "Validation Loss: 241.8377, Validation Accuracy: 0.2006\n",
      "New best validation loss: 241.8377, saving model.\n",
      "Epoch 446/1000\n",
      "Training Loss: 266.4146, Training Accuracy: 0.1906\n",
      "Validation Loss: 241.8359, Validation Accuracy: 0.2010\n",
      "New best validation loss: 241.8359, saving model.\n",
      "Epoch 447/1000\n",
      "Training Loss: 266.5946, Training Accuracy: 0.1902\n",
      "Validation Loss: 241.8342, Validation Accuracy: 0.2012\n",
      "New best validation loss: 241.8342, saving model.\n",
      "Epoch 448/1000\n",
      "Training Loss: 267.7675, Training Accuracy: 0.1904\n",
      "Validation Loss: 241.8324, Validation Accuracy: 0.2015\n",
      "New best validation loss: 241.8324, saving model.\n",
      "Epoch 449/1000\n",
      "Training Loss: 267.1689, Training Accuracy: 0.1910\n",
      "Validation Loss: 241.8306, Validation Accuracy: 0.2018\n",
      "New best validation loss: 241.8306, saving model.\n",
      "Epoch 450/1000\n",
      "Training Loss: 268.5378, Training Accuracy: 0.1904\n",
      "Validation Loss: 241.8288, Validation Accuracy: 0.2021\n",
      "New best validation loss: 241.8288, saving model.\n",
      "Epoch 451/1000\n",
      "Training Loss: 266.9256, Training Accuracy: 0.1912\n",
      "Validation Loss: 241.8270, Validation Accuracy: 0.2025\n",
      "New best validation loss: 241.8270, saving model.\n",
      "Epoch 452/1000\n",
      "Training Loss: 266.3614, Training Accuracy: 0.1927\n",
      "Validation Loss: 241.8252, Validation Accuracy: 0.2027\n",
      "New best validation loss: 241.8252, saving model.\n",
      "Epoch 453/1000\n",
      "Training Loss: 270.3348, Training Accuracy: 0.1915\n",
      "Validation Loss: 241.8234, Validation Accuracy: 0.2030\n",
      "New best validation loss: 241.8234, saving model.\n",
      "Epoch 454/1000\n",
      "Training Loss: 266.3350, Training Accuracy: 0.1933\n",
      "Validation Loss: 241.8216, Validation Accuracy: 0.2033\n",
      "New best validation loss: 241.8216, saving model.\n",
      "Epoch 455/1000\n",
      "Training Loss: 269.1615, Training Accuracy: 0.1927\n",
      "Validation Loss: 241.8198, Validation Accuracy: 0.2037\n",
      "New best validation loss: 241.8198, saving model.\n",
      "Epoch 456/1000\n",
      "Training Loss: 266.5997, Training Accuracy: 0.1941\n",
      "Validation Loss: 241.8180, Validation Accuracy: 0.2039\n",
      "New best validation loss: 241.8180, saving model.\n",
      "Epoch 457/1000\n",
      "Training Loss: 267.0521, Training Accuracy: 0.1934\n",
      "Validation Loss: 241.8161, Validation Accuracy: 0.2044\n",
      "New best validation loss: 241.8161, saving model.\n",
      "Epoch 458/1000\n",
      "Training Loss: 267.1720, Training Accuracy: 0.1938\n",
      "Validation Loss: 241.8143, Validation Accuracy: 0.2047\n",
      "New best validation loss: 241.8143, saving model.\n",
      "Epoch 459/1000\n",
      "Training Loss: 267.7068, Training Accuracy: 0.1940\n",
      "Validation Loss: 241.8125, Validation Accuracy: 0.2051\n",
      "New best validation loss: 241.8125, saving model.\n",
      "Epoch 460/1000\n",
      "Training Loss: 267.4258, Training Accuracy: 0.1947\n",
      "Validation Loss: 241.8107, Validation Accuracy: 0.2054\n",
      "New best validation loss: 241.8107, saving model.\n",
      "Epoch 461/1000\n",
      "Training Loss: 267.9584, Training Accuracy: 0.1941\n",
      "Validation Loss: 241.8088, Validation Accuracy: 0.2058\n",
      "New best validation loss: 241.8088, saving model.\n",
      "Epoch 462/1000\n",
      "Training Loss: 269.3990, Training Accuracy: 0.1945\n",
      "Validation Loss: 241.8070, Validation Accuracy: 0.2061\n",
      "New best validation loss: 241.8070, saving model.\n",
      "Epoch 463/1000\n",
      "Training Loss: 268.0011, Training Accuracy: 0.1953\n",
      "Validation Loss: 241.8052, Validation Accuracy: 0.2065\n",
      "New best validation loss: 241.8052, saving model.\n",
      "Epoch 464/1000\n",
      "Training Loss: 266.5412, Training Accuracy: 0.1952\n",
      "Validation Loss: 241.8033, Validation Accuracy: 0.2067\n",
      "New best validation loss: 241.8033, saving model.\n",
      "Epoch 465/1000\n",
      "Training Loss: 266.5472, Training Accuracy: 0.1959\n",
      "Validation Loss: 241.8015, Validation Accuracy: 0.2071\n",
      "New best validation loss: 241.8015, saving model.\n",
      "Epoch 466/1000\n",
      "Training Loss: 268.4402, Training Accuracy: 0.1966\n",
      "Validation Loss: 241.7996, Validation Accuracy: 0.2074\n",
      "New best validation loss: 241.7996, saving model.\n",
      "Epoch 467/1000\n",
      "Training Loss: 267.6746, Training Accuracy: 0.1969\n",
      "Validation Loss: 241.7978, Validation Accuracy: 0.2077\n",
      "New best validation loss: 241.7978, saving model.\n",
      "Epoch 468/1000\n",
      "Training Loss: 266.7657, Training Accuracy: 0.1966\n",
      "Validation Loss: 241.7960, Validation Accuracy: 0.2080\n",
      "New best validation loss: 241.7960, saving model.\n",
      "Epoch 469/1000\n",
      "Training Loss: 268.3625, Training Accuracy: 0.1965\n",
      "Validation Loss: 241.7941, Validation Accuracy: 0.2083\n",
      "New best validation loss: 241.7941, saving model.\n",
      "Epoch 470/1000\n",
      "Training Loss: 268.4855, Training Accuracy: 0.1973\n",
      "Validation Loss: 241.7923, Validation Accuracy: 0.2085\n",
      "New best validation loss: 241.7923, saving model.\n",
      "Epoch 471/1000\n",
      "Training Loss: 268.3421, Training Accuracy: 0.1968\n",
      "Validation Loss: 241.7904, Validation Accuracy: 0.2088\n",
      "New best validation loss: 241.7904, saving model.\n",
      "Epoch 472/1000\n",
      "Training Loss: 267.4512, Training Accuracy: 0.1977\n",
      "Validation Loss: 241.7886, Validation Accuracy: 0.2090\n",
      "New best validation loss: 241.7886, saving model.\n",
      "Epoch 473/1000\n",
      "Training Loss: 266.4433, Training Accuracy: 0.1986\n",
      "Validation Loss: 241.7867, Validation Accuracy: 0.2092\n",
      "New best validation loss: 241.7867, saving model.\n",
      "Epoch 474/1000\n",
      "Training Loss: 267.3417, Training Accuracy: 0.1979\n",
      "Validation Loss: 241.7848, Validation Accuracy: 0.2095\n",
      "New best validation loss: 241.7848, saving model.\n",
      "Epoch 475/1000\n",
      "Training Loss: 269.7768, Training Accuracy: 0.1984\n",
      "Validation Loss: 241.7830, Validation Accuracy: 0.2098\n",
      "New best validation loss: 241.7830, saving model.\n",
      "Epoch 476/1000\n",
      "Training Loss: 266.9588, Training Accuracy: 0.1990\n",
      "Validation Loss: 241.7811, Validation Accuracy: 0.2101\n",
      "New best validation loss: 241.7811, saving model.\n",
      "Epoch 477/1000\n",
      "Training Loss: 269.8525, Training Accuracy: 0.1985\n",
      "Validation Loss: 241.7793, Validation Accuracy: 0.2103\n",
      "New best validation loss: 241.7793, saving model.\n",
      "Epoch 478/1000\n",
      "Training Loss: 266.4747, Training Accuracy: 0.1997\n",
      "Validation Loss: 241.7774, Validation Accuracy: 0.2106\n",
      "New best validation loss: 241.7774, saving model.\n",
      "Epoch 479/1000\n",
      "Training Loss: 268.7882, Training Accuracy: 0.1991\n",
      "Validation Loss: 241.7755, Validation Accuracy: 0.2108\n",
      "New best validation loss: 241.7755, saving model.\n",
      "Epoch 480/1000\n",
      "Training Loss: 267.9070, Training Accuracy: 0.1994\n",
      "Validation Loss: 241.7736, Validation Accuracy: 0.2110\n",
      "New best validation loss: 241.7736, saving model.\n",
      "Epoch 481/1000\n",
      "Training Loss: 266.6753, Training Accuracy: 0.2003\n",
      "Validation Loss: 241.7718, Validation Accuracy: 0.2113\n",
      "New best validation loss: 241.7718, saving model.\n",
      "Epoch 482/1000\n",
      "Training Loss: 266.5795, Training Accuracy: 0.2007\n",
      "Validation Loss: 241.7699, Validation Accuracy: 0.2115\n",
      "New best validation loss: 241.7699, saving model.\n",
      "Epoch 483/1000\n",
      "Training Loss: 266.4711, Training Accuracy: 0.2004\n",
      "Validation Loss: 241.7680, Validation Accuracy: 0.2118\n",
      "New best validation loss: 241.7680, saving model.\n",
      "Epoch 484/1000\n",
      "Training Loss: 266.8527, Training Accuracy: 0.2005\n",
      "Validation Loss: 241.7661, Validation Accuracy: 0.2120\n",
      "New best validation loss: 241.7661, saving model.\n",
      "Epoch 485/1000\n",
      "Training Loss: 267.8414, Training Accuracy: 0.2001\n",
      "Validation Loss: 241.7642, Validation Accuracy: 0.2123\n",
      "New best validation loss: 241.7642, saving model.\n",
      "Epoch 486/1000\n",
      "Training Loss: 267.6640, Training Accuracy: 0.2007\n",
      "Validation Loss: 241.7623, Validation Accuracy: 0.2125\n",
      "New best validation loss: 241.7623, saving model.\n",
      "Epoch 487/1000\n",
      "Training Loss: 266.7743, Training Accuracy: 0.2014\n",
      "Validation Loss: 241.7604, Validation Accuracy: 0.2128\n",
      "New best validation loss: 241.7604, saving model.\n",
      "Epoch 488/1000\n",
      "Training Loss: 266.4274, Training Accuracy: 0.2013\n",
      "Validation Loss: 241.7585, Validation Accuracy: 0.2129\n",
      "New best validation loss: 241.7585, saving model.\n",
      "Epoch 489/1000\n",
      "Training Loss: 266.7291, Training Accuracy: 0.2017\n",
      "Validation Loss: 241.7566, Validation Accuracy: 0.2132\n",
      "New best validation loss: 241.7566, saving model.\n",
      "Epoch 490/1000\n",
      "Training Loss: 267.3375, Training Accuracy: 0.2022\n",
      "Validation Loss: 241.7547, Validation Accuracy: 0.2134\n",
      "New best validation loss: 241.7547, saving model.\n",
      "Epoch 491/1000\n",
      "Training Loss: 266.9718, Training Accuracy: 0.2018\n",
      "Validation Loss: 241.7528, Validation Accuracy: 0.2136\n",
      "New best validation loss: 241.7528, saving model.\n",
      "Epoch 492/1000\n",
      "Training Loss: 267.5493, Training Accuracy: 0.2023\n",
      "Validation Loss: 241.7508, Validation Accuracy: 0.2138\n",
      "New best validation loss: 241.7508, saving model.\n",
      "Epoch 493/1000\n",
      "Training Loss: 267.2153, Training Accuracy: 0.2027\n",
      "Validation Loss: 241.7489, Validation Accuracy: 0.2140\n",
      "New best validation loss: 241.7489, saving model.\n",
      "Epoch 494/1000\n",
      "Training Loss: 267.7467, Training Accuracy: 0.2025\n",
      "Validation Loss: 241.7470, Validation Accuracy: 0.2143\n",
      "New best validation loss: 241.7470, saving model.\n",
      "Epoch 495/1000\n",
      "Training Loss: 267.5040, Training Accuracy: 0.2020\n",
      "Validation Loss: 241.7451, Validation Accuracy: 0.2145\n",
      "New best validation loss: 241.7451, saving model.\n",
      "Epoch 496/1000\n",
      "Training Loss: 266.3591, Training Accuracy: 0.2026\n",
      "Validation Loss: 241.7431, Validation Accuracy: 0.2148\n",
      "New best validation loss: 241.7431, saving model.\n",
      "Epoch 497/1000\n",
      "Training Loss: 268.3590, Training Accuracy: 0.2033\n",
      "Validation Loss: 241.7412, Validation Accuracy: 0.2149\n",
      "New best validation loss: 241.7412, saving model.\n",
      "Epoch 498/1000\n",
      "Training Loss: 267.5970, Training Accuracy: 0.2022\n",
      "Validation Loss: 241.7393, Validation Accuracy: 0.2151\n",
      "New best validation loss: 241.7393, saving model.\n",
      "Epoch 499/1000\n",
      "Training Loss: 266.6567, Training Accuracy: 0.2041\n",
      "Validation Loss: 241.7373, Validation Accuracy: 0.2153\n",
      "New best validation loss: 241.7373, saving model.\n",
      "Epoch 500/1000\n",
      "Training Loss: 266.7604, Training Accuracy: 0.2039\n",
      "Validation Loss: 241.7354, Validation Accuracy: 0.2156\n",
      "New best validation loss: 241.7354, saving model.\n",
      "Epoch 501/1000\n",
      "Training Loss: 266.4893, Training Accuracy: 0.2042\n",
      "Validation Loss: 241.7334, Validation Accuracy: 0.2158\n",
      "New best validation loss: 241.7334, saving model.\n",
      "Epoch 502/1000\n",
      "Training Loss: 267.2418, Training Accuracy: 0.2041\n",
      "Validation Loss: 241.7315, Validation Accuracy: 0.2160\n",
      "New best validation loss: 241.7315, saving model.\n",
      "Epoch 503/1000\n",
      "Training Loss: 269.2866, Training Accuracy: 0.2034\n",
      "Validation Loss: 241.7295, Validation Accuracy: 0.2162\n",
      "New best validation loss: 241.7295, saving model.\n",
      "Epoch 504/1000\n",
      "Training Loss: 267.1056, Training Accuracy: 0.2043\n",
      "Validation Loss: 241.7276, Validation Accuracy: 0.2165\n",
      "New best validation loss: 241.7276, saving model.\n",
      "Epoch 505/1000\n",
      "Training Loss: 266.5903, Training Accuracy: 0.2035\n",
      "Validation Loss: 241.7256, Validation Accuracy: 0.2167\n",
      "New best validation loss: 241.7256, saving model.\n",
      "Epoch 506/1000\n",
      "Training Loss: 270.0121, Training Accuracy: 0.2037\n",
      "Validation Loss: 241.7237, Validation Accuracy: 0.2169\n",
      "New best validation loss: 241.7237, saving model.\n",
      "Epoch 507/1000\n",
      "Training Loss: 267.5490, Training Accuracy: 0.2048\n",
      "Validation Loss: 241.7217, Validation Accuracy: 0.2171\n",
      "New best validation loss: 241.7217, saving model.\n",
      "Epoch 508/1000\n",
      "Training Loss: 266.4350, Training Accuracy: 0.2057\n",
      "Validation Loss: 241.7198, Validation Accuracy: 0.2173\n",
      "New best validation loss: 241.7198, saving model.\n",
      "Epoch 509/1000\n",
      "Training Loss: 267.6254, Training Accuracy: 0.2052\n",
      "Validation Loss: 241.7178, Validation Accuracy: 0.2176\n",
      "New best validation loss: 241.7178, saving model.\n",
      "Epoch 510/1000\n",
      "Training Loss: 266.1369, Training Accuracy: 0.2062\n",
      "Validation Loss: 241.7158, Validation Accuracy: 0.2177\n",
      "New best validation loss: 241.7158, saving model.\n",
      "Epoch 511/1000\n",
      "Training Loss: 267.7495, Training Accuracy: 0.2053\n",
      "Validation Loss: 241.7139, Validation Accuracy: 0.2179\n",
      "New best validation loss: 241.7139, saving model.\n",
      "Epoch 512/1000\n",
      "Training Loss: 266.5984, Training Accuracy: 0.2068\n",
      "Validation Loss: 241.7119, Validation Accuracy: 0.2181\n",
      "New best validation loss: 241.7119, saving model.\n",
      "Epoch 513/1000\n",
      "Training Loss: 267.7447, Training Accuracy: 0.2052\n",
      "Validation Loss: 241.7099, Validation Accuracy: 0.2183\n",
      "New best validation loss: 241.7099, saving model.\n",
      "Epoch 514/1000\n",
      "Training Loss: 266.1763, Training Accuracy: 0.2065\n",
      "Validation Loss: 241.7079, Validation Accuracy: 0.2185\n",
      "New best validation loss: 241.7079, saving model.\n",
      "Epoch 515/1000\n",
      "Training Loss: 267.9385, Training Accuracy: 0.2067\n",
      "Validation Loss: 241.7059, Validation Accuracy: 0.2187\n",
      "New best validation loss: 241.7059, saving model.\n",
      "Epoch 516/1000\n",
      "Training Loss: 267.8039, Training Accuracy: 0.2063\n",
      "Validation Loss: 241.7039, Validation Accuracy: 0.2189\n",
      "New best validation loss: 241.7039, saving model.\n",
      "Epoch 517/1000\n",
      "Training Loss: 268.4569, Training Accuracy: 0.2068\n",
      "Validation Loss: 241.7019, Validation Accuracy: 0.2191\n",
      "New best validation loss: 241.7019, saving model.\n",
      "Epoch 518/1000\n",
      "Training Loss: 268.5715, Training Accuracy: 0.2069\n",
      "Validation Loss: 241.6998, Validation Accuracy: 0.2193\n",
      "New best validation loss: 241.6998, saving model.\n",
      "Epoch 519/1000\n",
      "Training Loss: 266.5192, Training Accuracy: 0.2069\n",
      "Validation Loss: 241.6979, Validation Accuracy: 0.2195\n",
      "New best validation loss: 241.6979, saving model.\n",
      "Epoch 520/1000\n",
      "Training Loss: 266.3721, Training Accuracy: 0.2071\n",
      "Validation Loss: 241.6958, Validation Accuracy: 0.2197\n",
      "New best validation loss: 241.6958, saving model.\n",
      "Epoch 521/1000\n",
      "Training Loss: 267.4843, Training Accuracy: 0.2075\n",
      "Validation Loss: 241.6938, Validation Accuracy: 0.2199\n",
      "New best validation loss: 241.6938, saving model.\n",
      "Epoch 522/1000\n",
      "Training Loss: 267.6207, Training Accuracy: 0.2077\n",
      "Validation Loss: 241.6918, Validation Accuracy: 0.2201\n",
      "New best validation loss: 241.6918, saving model.\n",
      "Epoch 523/1000\n",
      "Training Loss: 268.9952, Training Accuracy: 0.2076\n",
      "Validation Loss: 241.6897, Validation Accuracy: 0.2203\n",
      "New best validation loss: 241.6897, saving model.\n",
      "Epoch 524/1000\n",
      "Training Loss: 267.3011, Training Accuracy: 0.2083\n",
      "Validation Loss: 241.6877, Validation Accuracy: 0.2205\n",
      "New best validation loss: 241.6877, saving model.\n",
      "Epoch 525/1000\n",
      "Training Loss: 267.0742, Training Accuracy: 0.2086\n",
      "Validation Loss: 241.6857, Validation Accuracy: 0.2207\n",
      "New best validation loss: 241.6857, saving model.\n",
      "Epoch 526/1000\n",
      "Training Loss: 268.3390, Training Accuracy: 0.2075\n",
      "Validation Loss: 241.6836, Validation Accuracy: 0.2209\n",
      "New best validation loss: 241.6836, saving model.\n",
      "Epoch 527/1000\n",
      "Training Loss: 268.0287, Training Accuracy: 0.2075\n",
      "Validation Loss: 241.6816, Validation Accuracy: 0.2210\n",
      "New best validation loss: 241.6816, saving model.\n",
      "Epoch 528/1000\n",
      "Training Loss: 267.0081, Training Accuracy: 0.2093\n",
      "Validation Loss: 241.6795, Validation Accuracy: 0.2212\n",
      "New best validation loss: 241.6795, saving model.\n",
      "Epoch 529/1000\n",
      "Training Loss: 266.8809, Training Accuracy: 0.2099\n",
      "Validation Loss: 241.6775, Validation Accuracy: 0.2214\n",
      "New best validation loss: 241.6775, saving model.\n",
      "Epoch 530/1000\n",
      "Training Loss: 267.0144, Training Accuracy: 0.2084\n",
      "Validation Loss: 241.6754, Validation Accuracy: 0.2216\n",
      "New best validation loss: 241.6754, saving model.\n",
      "Epoch 531/1000\n",
      "Training Loss: 266.9436, Training Accuracy: 0.2093\n",
      "Validation Loss: 241.6734, Validation Accuracy: 0.2219\n",
      "New best validation loss: 241.6734, saving model.\n",
      "Epoch 532/1000\n",
      "Training Loss: 266.9809, Training Accuracy: 0.2085\n",
      "Validation Loss: 241.6713, Validation Accuracy: 0.2221\n",
      "New best validation loss: 241.6713, saving model.\n",
      "Epoch 533/1000\n",
      "Training Loss: 266.7470, Training Accuracy: 0.2104\n",
      "Validation Loss: 241.6692, Validation Accuracy: 0.2223\n",
      "New best validation loss: 241.6692, saving model.\n",
      "Epoch 534/1000\n",
      "Training Loss: 266.3241, Training Accuracy: 0.2106\n",
      "Validation Loss: 241.6672, Validation Accuracy: 0.2224\n",
      "New best validation loss: 241.6672, saving model.\n",
      "Epoch 535/1000\n",
      "Training Loss: 267.8789, Training Accuracy: 0.2095\n",
      "Validation Loss: 241.6651, Validation Accuracy: 0.2227\n",
      "New best validation loss: 241.6651, saving model.\n",
      "Epoch 536/1000\n",
      "Training Loss: 267.1500, Training Accuracy: 0.2097\n",
      "Validation Loss: 241.6630, Validation Accuracy: 0.2229\n",
      "New best validation loss: 241.6630, saving model.\n",
      "Epoch 537/1000\n",
      "Training Loss: 267.2809, Training Accuracy: 0.2106\n",
      "Validation Loss: 241.6609, Validation Accuracy: 0.2231\n",
      "New best validation loss: 241.6609, saving model.\n",
      "Epoch 538/1000\n",
      "Training Loss: 266.8789, Training Accuracy: 0.2110\n",
      "Validation Loss: 241.6589, Validation Accuracy: 0.2233\n",
      "New best validation loss: 241.6589, saving model.\n",
      "Epoch 539/1000\n",
      "Training Loss: 266.9803, Training Accuracy: 0.2118\n",
      "Validation Loss: 241.6568, Validation Accuracy: 0.2235\n",
      "New best validation loss: 241.6568, saving model.\n",
      "Epoch 540/1000\n",
      "Training Loss: 267.2418, Training Accuracy: 0.2118\n",
      "Validation Loss: 241.6547, Validation Accuracy: 0.2237\n",
      "New best validation loss: 241.6547, saving model.\n",
      "Epoch 541/1000\n",
      "Training Loss: 266.4777, Training Accuracy: 0.2119\n",
      "Validation Loss: 241.6526, Validation Accuracy: 0.2239\n",
      "New best validation loss: 241.6526, saving model.\n",
      "Epoch 542/1000\n",
      "Training Loss: 266.5775, Training Accuracy: 0.2119\n",
      "Validation Loss: 241.6505, Validation Accuracy: 0.2242\n",
      "New best validation loss: 241.6505, saving model.\n",
      "Epoch 543/1000\n",
      "Training Loss: 266.9416, Training Accuracy: 0.2122\n",
      "Validation Loss: 241.6484, Validation Accuracy: 0.2244\n",
      "New best validation loss: 241.6484, saving model.\n",
      "Epoch 544/1000\n",
      "Training Loss: 267.5444, Training Accuracy: 0.2120\n",
      "Validation Loss: 241.6463, Validation Accuracy: 0.2247\n",
      "New best validation loss: 241.6463, saving model.\n",
      "Epoch 545/1000\n",
      "Training Loss: 267.6945, Training Accuracy: 0.2112\n",
      "Validation Loss: 241.6442, Validation Accuracy: 0.2249\n",
      "New best validation loss: 241.6442, saving model.\n",
      "Epoch 546/1000\n",
      "Training Loss: 268.0541, Training Accuracy: 0.2121\n",
      "Validation Loss: 241.6421, Validation Accuracy: 0.2251\n",
      "New best validation loss: 241.6421, saving model.\n",
      "Epoch 547/1000\n",
      "Training Loss: 266.6050, Training Accuracy: 0.2122\n",
      "Validation Loss: 241.6400, Validation Accuracy: 0.2254\n",
      "New best validation loss: 241.6400, saving model.\n",
      "Epoch 548/1000\n",
      "Training Loss: 270.4593, Training Accuracy: 0.2126\n",
      "Validation Loss: 241.6378, Validation Accuracy: 0.2256\n",
      "New best validation loss: 241.6378, saving model.\n",
      "Epoch 549/1000\n",
      "Training Loss: 267.7926, Training Accuracy: 0.2128\n",
      "Validation Loss: 241.6357, Validation Accuracy: 0.2258\n",
      "New best validation loss: 241.6357, saving model.\n",
      "Epoch 550/1000\n",
      "Training Loss: 266.8378, Training Accuracy: 0.2142\n",
      "Validation Loss: 241.6336, Validation Accuracy: 0.2260\n",
      "New best validation loss: 241.6336, saving model.\n",
      "Epoch 551/1000\n",
      "Training Loss: 267.6564, Training Accuracy: 0.2136\n",
      "Validation Loss: 241.6315, Validation Accuracy: 0.2262\n",
      "New best validation loss: 241.6315, saving model.\n",
      "Epoch 552/1000\n",
      "Training Loss: 266.7599, Training Accuracy: 0.2127\n",
      "Validation Loss: 241.6294, Validation Accuracy: 0.2265\n",
      "New best validation loss: 241.6294, saving model.\n",
      "Epoch 553/1000\n",
      "Training Loss: 267.2203, Training Accuracy: 0.2152\n",
      "Validation Loss: 241.6272, Validation Accuracy: 0.2267\n",
      "New best validation loss: 241.6272, saving model.\n",
      "Epoch 554/1000\n",
      "Training Loss: 267.3358, Training Accuracy: 0.2143\n",
      "Validation Loss: 241.6251, Validation Accuracy: 0.2269\n",
      "New best validation loss: 241.6251, saving model.\n",
      "Epoch 555/1000\n",
      "Training Loss: 268.5650, Training Accuracy: 0.2134\n",
      "Validation Loss: 241.6229, Validation Accuracy: 0.2272\n",
      "New best validation loss: 241.6229, saving model.\n",
      "Epoch 556/1000\n",
      "Training Loss: 267.1709, Training Accuracy: 0.2140\n",
      "Validation Loss: 241.6208, Validation Accuracy: 0.2274\n",
      "New best validation loss: 241.6208, saving model.\n",
      "Epoch 557/1000\n",
      "Training Loss: 266.4145, Training Accuracy: 0.2147\n",
      "Validation Loss: 241.6186, Validation Accuracy: 0.2276\n",
      "New best validation loss: 241.6186, saving model.\n",
      "Epoch 558/1000\n",
      "Training Loss: 267.8361, Training Accuracy: 0.2152\n",
      "Validation Loss: 241.6165, Validation Accuracy: 0.2278\n",
      "New best validation loss: 241.6165, saving model.\n",
      "Epoch 559/1000\n",
      "Training Loss: 267.8712, Training Accuracy: 0.2147\n",
      "Validation Loss: 241.6143, Validation Accuracy: 0.2280\n",
      "New best validation loss: 241.6143, saving model.\n",
      "Epoch 560/1000\n",
      "Training Loss: 266.5423, Training Accuracy: 0.2158\n",
      "Validation Loss: 241.6122, Validation Accuracy: 0.2283\n",
      "New best validation loss: 241.6122, saving model.\n",
      "Epoch 561/1000\n",
      "Training Loss: 266.4824, Training Accuracy: 0.2163\n",
      "Validation Loss: 241.6100, Validation Accuracy: 0.2284\n",
      "New best validation loss: 241.6100, saving model.\n",
      "Epoch 562/1000\n",
      "Training Loss: 267.7842, Training Accuracy: 0.2157\n",
      "Validation Loss: 241.6078, Validation Accuracy: 0.2287\n",
      "New best validation loss: 241.6078, saving model.\n",
      "Epoch 563/1000\n",
      "Training Loss: 268.6155, Training Accuracy: 0.2155\n",
      "Validation Loss: 241.6056, Validation Accuracy: 0.2290\n",
      "New best validation loss: 241.6056, saving model.\n",
      "Epoch 564/1000\n",
      "Training Loss: 266.8095, Training Accuracy: 0.2159\n",
      "Validation Loss: 241.6035, Validation Accuracy: 0.2292\n",
      "New best validation loss: 241.6035, saving model.\n",
      "Epoch 565/1000\n",
      "Training Loss: 267.8638, Training Accuracy: 0.2164\n",
      "Validation Loss: 241.6013, Validation Accuracy: 0.2294\n",
      "New best validation loss: 241.6013, saving model.\n",
      "Epoch 566/1000\n",
      "Training Loss: 266.5890, Training Accuracy: 0.2172\n",
      "Validation Loss: 241.5991, Validation Accuracy: 0.2296\n",
      "New best validation loss: 241.5991, saving model.\n",
      "Epoch 567/1000\n",
      "Training Loss: 267.1933, Training Accuracy: 0.2161\n",
      "Validation Loss: 241.5969, Validation Accuracy: 0.2299\n",
      "New best validation loss: 241.5969, saving model.\n",
      "Epoch 568/1000\n",
      "Training Loss: 266.0445, Training Accuracy: 0.2169\n",
      "Validation Loss: 241.5947, Validation Accuracy: 0.2302\n",
      "New best validation loss: 241.5947, saving model.\n",
      "Epoch 569/1000\n",
      "Training Loss: 266.7148, Training Accuracy: 0.2172\n",
      "Validation Loss: 241.5925, Validation Accuracy: 0.2305\n",
      "New best validation loss: 241.5925, saving model.\n",
      "Epoch 570/1000\n",
      "Training Loss: 267.5152, Training Accuracy: 0.2171\n",
      "Validation Loss: 241.5903, Validation Accuracy: 0.2307\n",
      "New best validation loss: 241.5903, saving model.\n",
      "Epoch 571/1000\n",
      "Training Loss: 267.3439, Training Accuracy: 0.2175\n",
      "Validation Loss: 241.5880, Validation Accuracy: 0.2310\n",
      "New best validation loss: 241.5880, saving model.\n",
      "Epoch 572/1000\n",
      "Training Loss: 267.1475, Training Accuracy: 0.2179\n",
      "Validation Loss: 241.5858, Validation Accuracy: 0.2313\n",
      "New best validation loss: 241.5858, saving model.\n",
      "Epoch 573/1000\n",
      "Training Loss: 267.3924, Training Accuracy: 0.2172\n",
      "Validation Loss: 241.5836, Validation Accuracy: 0.2316\n",
      "New best validation loss: 241.5836, saving model.\n",
      "Epoch 574/1000\n",
      "Training Loss: 266.9985, Training Accuracy: 0.2187\n",
      "Validation Loss: 241.5814, Validation Accuracy: 0.2318\n",
      "New best validation loss: 241.5814, saving model.\n",
      "Epoch 575/1000\n",
      "Training Loss: 266.9078, Training Accuracy: 0.2184\n",
      "Validation Loss: 241.5791, Validation Accuracy: 0.2320\n",
      "New best validation loss: 241.5791, saving model.\n",
      "Epoch 576/1000\n",
      "Training Loss: 266.9222, Training Accuracy: 0.2195\n",
      "Validation Loss: 241.5769, Validation Accuracy: 0.2323\n",
      "New best validation loss: 241.5769, saving model.\n",
      "Epoch 577/1000\n",
      "Training Loss: 267.1116, Training Accuracy: 0.2188\n",
      "Validation Loss: 241.5746, Validation Accuracy: 0.2325\n",
      "New best validation loss: 241.5746, saving model.\n",
      "Epoch 578/1000\n",
      "Training Loss: 266.7338, Training Accuracy: 0.2186\n",
      "Validation Loss: 241.5724, Validation Accuracy: 0.2327\n",
      "New best validation loss: 241.5724, saving model.\n",
      "Epoch 579/1000\n",
      "Training Loss: 267.8935, Training Accuracy: 0.2205\n",
      "Validation Loss: 241.5701, Validation Accuracy: 0.2329\n",
      "New best validation loss: 241.5701, saving model.\n",
      "Epoch 580/1000\n",
      "Training Loss: 266.3415, Training Accuracy: 0.2187\n",
      "Validation Loss: 241.5679, Validation Accuracy: 0.2332\n",
      "New best validation loss: 241.5679, saving model.\n",
      "Epoch 581/1000\n",
      "Training Loss: 267.5495, Training Accuracy: 0.2203\n",
      "Validation Loss: 241.5656, Validation Accuracy: 0.2335\n",
      "New best validation loss: 241.5656, saving model.\n",
      "Epoch 582/1000\n",
      "Training Loss: 267.2582, Training Accuracy: 0.2194\n",
      "Validation Loss: 241.5633, Validation Accuracy: 0.2337\n",
      "New best validation loss: 241.5633, saving model.\n",
      "Epoch 583/1000\n",
      "Training Loss: 266.7941, Training Accuracy: 0.2199\n",
      "Validation Loss: 241.5611, Validation Accuracy: 0.2340\n",
      "New best validation loss: 241.5611, saving model.\n",
      "Epoch 584/1000\n",
      "Training Loss: 268.3220, Training Accuracy: 0.2196\n",
      "Validation Loss: 241.5588, Validation Accuracy: 0.2343\n",
      "New best validation loss: 241.5588, saving model.\n",
      "Epoch 585/1000\n",
      "Training Loss: 267.1355, Training Accuracy: 0.2202\n",
      "Validation Loss: 241.5565, Validation Accuracy: 0.2345\n",
      "New best validation loss: 241.5565, saving model.\n",
      "Epoch 586/1000\n",
      "Training Loss: 268.9089, Training Accuracy: 0.2207\n",
      "Validation Loss: 241.5542, Validation Accuracy: 0.2347\n",
      "New best validation loss: 241.5542, saving model.\n",
      "Epoch 587/1000\n",
      "Training Loss: 267.8221, Training Accuracy: 0.2216\n",
      "Validation Loss: 241.5519, Validation Accuracy: 0.2350\n",
      "New best validation loss: 241.5519, saving model.\n",
      "Epoch 588/1000\n",
      "Training Loss: 267.9375, Training Accuracy: 0.2219\n",
      "Validation Loss: 241.5496, Validation Accuracy: 0.2352\n",
      "New best validation loss: 241.5496, saving model.\n",
      "Epoch 589/1000\n",
      "Training Loss: 266.0610, Training Accuracy: 0.2229\n",
      "Validation Loss: 241.5473, Validation Accuracy: 0.2355\n",
      "New best validation loss: 241.5473, saving model.\n",
      "Epoch 590/1000\n",
      "Training Loss: 267.0076, Training Accuracy: 0.2215\n",
      "Validation Loss: 241.5450, Validation Accuracy: 0.2358\n",
      "New best validation loss: 241.5450, saving model.\n",
      "Epoch 591/1000\n",
      "Training Loss: 267.2544, Training Accuracy: 0.2231\n",
      "Validation Loss: 241.5427, Validation Accuracy: 0.2360\n",
      "New best validation loss: 241.5427, saving model.\n",
      "Epoch 592/1000\n",
      "Training Loss: 267.9500, Training Accuracy: 0.2227\n",
      "Validation Loss: 241.5404, Validation Accuracy: 0.2363\n",
      "New best validation loss: 241.5404, saving model.\n",
      "Epoch 593/1000\n",
      "Training Loss: 267.9473, Training Accuracy: 0.2224\n",
      "Validation Loss: 241.5381, Validation Accuracy: 0.2366\n",
      "New best validation loss: 241.5381, saving model.\n",
      "Epoch 594/1000\n",
      "Training Loss: 269.6773, Training Accuracy: 0.2232\n",
      "Validation Loss: 241.5358, Validation Accuracy: 0.2368\n",
      "New best validation loss: 241.5358, saving model.\n",
      "Epoch 595/1000\n",
      "Training Loss: 266.4740, Training Accuracy: 0.2246\n",
      "Validation Loss: 241.5335, Validation Accuracy: 0.2371\n",
      "New best validation loss: 241.5335, saving model.\n",
      "Epoch 596/1000\n",
      "Training Loss: 266.3738, Training Accuracy: 0.2239\n",
      "Validation Loss: 241.5312, Validation Accuracy: 0.2374\n",
      "New best validation loss: 241.5312, saving model.\n",
      "Epoch 597/1000\n",
      "Training Loss: 267.3250, Training Accuracy: 0.2244\n",
      "Validation Loss: 241.5289, Validation Accuracy: 0.2376\n",
      "New best validation loss: 241.5289, saving model.\n",
      "Epoch 598/1000\n",
      "Training Loss: 266.9261, Training Accuracy: 0.2251\n",
      "Validation Loss: 241.5265, Validation Accuracy: 0.2379\n",
      "New best validation loss: 241.5265, saving model.\n",
      "Epoch 599/1000\n",
      "Training Loss: 266.7240, Training Accuracy: 0.2254\n",
      "Validation Loss: 241.5242, Validation Accuracy: 0.2382\n",
      "New best validation loss: 241.5242, saving model.\n",
      "Epoch 600/1000\n",
      "Training Loss: 268.1849, Training Accuracy: 0.2254\n",
      "Validation Loss: 241.5218, Validation Accuracy: 0.2385\n",
      "New best validation loss: 241.5218, saving model.\n",
      "Epoch 601/1000\n",
      "Training Loss: 267.4071, Training Accuracy: 0.2249\n",
      "Validation Loss: 241.5195, Validation Accuracy: 0.2389\n",
      "New best validation loss: 241.5195, saving model.\n",
      "Epoch 602/1000\n",
      "Training Loss: 266.8149, Training Accuracy: 0.2255\n",
      "Validation Loss: 241.5171, Validation Accuracy: 0.2392\n",
      "New best validation loss: 241.5171, saving model.\n",
      "Epoch 603/1000\n",
      "Training Loss: 266.0454, Training Accuracy: 0.2265\n",
      "Validation Loss: 241.5148, Validation Accuracy: 0.2395\n",
      "New best validation loss: 241.5148, saving model.\n",
      "Epoch 604/1000\n",
      "Training Loss: 268.3653, Training Accuracy: 0.2264\n",
      "Validation Loss: 241.5124, Validation Accuracy: 0.2398\n",
      "New best validation loss: 241.5124, saving model.\n",
      "Epoch 605/1000\n",
      "Training Loss: 267.5271, Training Accuracy: 0.2263\n",
      "Validation Loss: 241.5100, Validation Accuracy: 0.2401\n",
      "New best validation loss: 241.5100, saving model.\n",
      "Epoch 606/1000\n",
      "Training Loss: 267.9941, Training Accuracy: 0.2267\n",
      "Validation Loss: 241.5076, Validation Accuracy: 0.2405\n",
      "New best validation loss: 241.5076, saving model.\n",
      "Epoch 607/1000\n",
      "Training Loss: 266.8166, Training Accuracy: 0.2264\n",
      "Validation Loss: 241.5052, Validation Accuracy: 0.2408\n",
      "New best validation loss: 241.5052, saving model.\n",
      "Epoch 608/1000\n",
      "Training Loss: 266.6839, Training Accuracy: 0.2279\n",
      "Validation Loss: 241.5028, Validation Accuracy: 0.2411\n",
      "New best validation loss: 241.5028, saving model.\n",
      "Epoch 609/1000\n",
      "Training Loss: 267.7798, Training Accuracy: 0.2274\n",
      "Validation Loss: 241.5004, Validation Accuracy: 0.2415\n",
      "New best validation loss: 241.5004, saving model.\n",
      "Epoch 610/1000\n",
      "Training Loss: 267.3390, Training Accuracy: 0.2279\n",
      "Validation Loss: 241.4980, Validation Accuracy: 0.2418\n",
      "New best validation loss: 241.4980, saving model.\n",
      "Epoch 611/1000\n",
      "Training Loss: 266.4306, Training Accuracy: 0.2281\n",
      "Validation Loss: 241.4957, Validation Accuracy: 0.2422\n",
      "New best validation loss: 241.4957, saving model.\n",
      "Epoch 612/1000\n",
      "Training Loss: 267.7478, Training Accuracy: 0.2285\n",
      "Validation Loss: 241.4933, Validation Accuracy: 0.2425\n",
      "New best validation loss: 241.4933, saving model.\n",
      "Epoch 613/1000\n",
      "Training Loss: 268.0976, Training Accuracy: 0.2286\n",
      "Validation Loss: 241.4909, Validation Accuracy: 0.2428\n",
      "New best validation loss: 241.4909, saving model.\n",
      "Epoch 614/1000\n",
      "Training Loss: 269.3975, Training Accuracy: 0.2285\n",
      "Validation Loss: 241.4885, Validation Accuracy: 0.2431\n",
      "New best validation loss: 241.4885, saving model.\n",
      "Epoch 615/1000\n",
      "Training Loss: 266.5043, Training Accuracy: 0.2298\n",
      "Validation Loss: 241.4861, Validation Accuracy: 0.2435\n",
      "New best validation loss: 241.4861, saving model.\n",
      "Epoch 616/1000\n",
      "Training Loss: 266.5317, Training Accuracy: 0.2293\n",
      "Validation Loss: 241.4836, Validation Accuracy: 0.2439\n",
      "New best validation loss: 241.4836, saving model.\n",
      "Epoch 617/1000\n",
      "Training Loss: 266.9500, Training Accuracy: 0.2311\n",
      "Validation Loss: 241.4812, Validation Accuracy: 0.2442\n",
      "New best validation loss: 241.4812, saving model.\n",
      "Epoch 618/1000\n",
      "Training Loss: 266.5481, Training Accuracy: 0.2316\n",
      "Validation Loss: 241.4788, Validation Accuracy: 0.2446\n",
      "New best validation loss: 241.4788, saving model.\n",
      "Epoch 619/1000\n",
      "Training Loss: 266.1995, Training Accuracy: 0.2317\n",
      "Validation Loss: 241.4763, Validation Accuracy: 0.2448\n",
      "New best validation loss: 241.4763, saving model.\n",
      "Epoch 620/1000\n",
      "Training Loss: 267.9192, Training Accuracy: 0.2311\n",
      "Validation Loss: 241.4739, Validation Accuracy: 0.2452\n",
      "New best validation loss: 241.4739, saving model.\n",
      "Epoch 621/1000\n",
      "Training Loss: 267.4248, Training Accuracy: 0.2315\n",
      "Validation Loss: 241.4715, Validation Accuracy: 0.2456\n",
      "New best validation loss: 241.4715, saving model.\n",
      "Epoch 622/1000\n",
      "Training Loss: 269.4988, Training Accuracy: 0.2313\n",
      "Validation Loss: 241.4690, Validation Accuracy: 0.2460\n",
      "New best validation loss: 241.4690, saving model.\n",
      "Epoch 623/1000\n",
      "Training Loss: 268.1650, Training Accuracy: 0.2315\n",
      "Validation Loss: 241.4666, Validation Accuracy: 0.2464\n",
      "New best validation loss: 241.4666, saving model.\n",
      "Epoch 624/1000\n",
      "Training Loss: 266.7113, Training Accuracy: 0.2323\n",
      "Validation Loss: 241.4641, Validation Accuracy: 0.2468\n",
      "New best validation loss: 241.4641, saving model.\n",
      "Epoch 625/1000\n",
      "Training Loss: 269.2848, Training Accuracy: 0.2317\n",
      "Validation Loss: 241.4617, Validation Accuracy: 0.2472\n",
      "New best validation loss: 241.4617, saving model.\n",
      "Epoch 626/1000\n",
      "Training Loss: 267.5091, Training Accuracy: 0.2323\n",
      "Validation Loss: 241.4593, Validation Accuracy: 0.2475\n",
      "New best validation loss: 241.4593, saving model.\n",
      "Epoch 627/1000\n",
      "Training Loss: 266.8036, Training Accuracy: 0.2337\n",
      "Validation Loss: 241.4568, Validation Accuracy: 0.2479\n",
      "New best validation loss: 241.4568, saving model.\n",
      "Epoch 628/1000\n",
      "Training Loss: 266.3903, Training Accuracy: 0.2333\n",
      "Validation Loss: 241.4543, Validation Accuracy: 0.2483\n",
      "New best validation loss: 241.4543, saving model.\n",
      "Epoch 629/1000\n",
      "Training Loss: 266.5719, Training Accuracy: 0.2337\n",
      "Validation Loss: 241.4519, Validation Accuracy: 0.2487\n",
      "New best validation loss: 241.4519, saving model.\n",
      "Epoch 630/1000\n",
      "Training Loss: 267.5304, Training Accuracy: 0.2346\n",
      "Validation Loss: 241.4494, Validation Accuracy: 0.2491\n",
      "New best validation loss: 241.4494, saving model.\n",
      "Epoch 631/1000\n",
      "Training Loss: 267.8638, Training Accuracy: 0.2342\n",
      "Validation Loss: 241.4469, Validation Accuracy: 0.2495\n",
      "New best validation loss: 241.4469, saving model.\n",
      "Epoch 632/1000\n",
      "Training Loss: 266.6507, Training Accuracy: 0.2358\n",
      "Validation Loss: 241.4444, Validation Accuracy: 0.2499\n",
      "New best validation loss: 241.4444, saving model.\n",
      "Epoch 633/1000\n",
      "Training Loss: 266.3793, Training Accuracy: 0.2354\n",
      "Validation Loss: 241.4420, Validation Accuracy: 0.2503\n",
      "New best validation loss: 241.4420, saving model.\n",
      "Epoch 634/1000\n",
      "Training Loss: 267.5898, Training Accuracy: 0.2361\n",
      "Validation Loss: 241.4395, Validation Accuracy: 0.2506\n",
      "New best validation loss: 241.4395, saving model.\n",
      "Epoch 635/1000\n",
      "Training Loss: 268.2816, Training Accuracy: 0.2363\n",
      "Validation Loss: 241.4370, Validation Accuracy: 0.2510\n",
      "New best validation loss: 241.4370, saving model.\n",
      "Epoch 636/1000\n",
      "Training Loss: 266.4445, Training Accuracy: 0.2363\n",
      "Validation Loss: 241.4346, Validation Accuracy: 0.2513\n",
      "New best validation loss: 241.4346, saving model.\n",
      "Epoch 637/1000\n",
      "Training Loss: 268.4783, Training Accuracy: 0.2371\n",
      "Validation Loss: 241.4321, Validation Accuracy: 0.2516\n",
      "New best validation loss: 241.4321, saving model.\n",
      "Epoch 638/1000\n",
      "Training Loss: 268.0608, Training Accuracy: 0.2363\n",
      "Validation Loss: 241.4295, Validation Accuracy: 0.2521\n",
      "New best validation loss: 241.4295, saving model.\n",
      "Epoch 639/1000\n",
      "Training Loss: 266.7539, Training Accuracy: 0.2365\n",
      "Validation Loss: 241.4271, Validation Accuracy: 0.2524\n",
      "New best validation loss: 241.4271, saving model.\n",
      "Epoch 640/1000\n",
      "Training Loss: 266.1274, Training Accuracy: 0.2382\n",
      "Validation Loss: 241.4246, Validation Accuracy: 0.2528\n",
      "New best validation loss: 241.4246, saving model.\n",
      "Epoch 641/1000\n",
      "Training Loss: 268.1887, Training Accuracy: 0.2374\n",
      "Validation Loss: 241.4221, Validation Accuracy: 0.2531\n",
      "New best validation loss: 241.4221, saving model.\n",
      "Epoch 642/1000\n",
      "Training Loss: 267.1113, Training Accuracy: 0.2384\n",
      "Validation Loss: 241.4195, Validation Accuracy: 0.2535\n",
      "New best validation loss: 241.4195, saving model.\n",
      "Epoch 643/1000\n",
      "Training Loss: 267.6975, Training Accuracy: 0.2381\n",
      "Validation Loss: 241.4170, Validation Accuracy: 0.2539\n",
      "New best validation loss: 241.4170, saving model.\n",
      "Epoch 644/1000\n",
      "Training Loss: 266.0530, Training Accuracy: 0.2404\n",
      "Validation Loss: 241.4145, Validation Accuracy: 0.2542\n",
      "New best validation loss: 241.4145, saving model.\n",
      "Epoch 645/1000\n",
      "Training Loss: 266.0109, Training Accuracy: 0.2405\n",
      "Validation Loss: 241.4120, Validation Accuracy: 0.2546\n",
      "New best validation loss: 241.4120, saving model.\n",
      "Epoch 646/1000\n",
      "Training Loss: 266.8793, Training Accuracy: 0.2394\n",
      "Validation Loss: 241.4094, Validation Accuracy: 0.2549\n",
      "New best validation loss: 241.4094, saving model.\n",
      "Epoch 647/1000\n",
      "Training Loss: 268.3276, Training Accuracy: 0.2390\n",
      "Validation Loss: 241.4069, Validation Accuracy: 0.2552\n",
      "New best validation loss: 241.4069, saving model.\n",
      "Epoch 648/1000\n",
      "Training Loss: 269.8945, Training Accuracy: 0.2391\n",
      "Validation Loss: 241.4043, Validation Accuracy: 0.2556\n",
      "New best validation loss: 241.4043, saving model.\n",
      "Epoch 649/1000\n",
      "Training Loss: 266.2706, Training Accuracy: 0.2406\n",
      "Validation Loss: 241.4018, Validation Accuracy: 0.2560\n",
      "New best validation loss: 241.4018, saving model.\n",
      "Epoch 650/1000\n",
      "Training Loss: 267.1766, Training Accuracy: 0.2403\n",
      "Validation Loss: 241.3992, Validation Accuracy: 0.2563\n",
      "New best validation loss: 241.3992, saving model.\n",
      "Epoch 651/1000\n",
      "Training Loss: 267.2239, Training Accuracy: 0.2409\n",
      "Validation Loss: 241.3967, Validation Accuracy: 0.2567\n",
      "New best validation loss: 241.3967, saving model.\n",
      "Epoch 652/1000\n",
      "Training Loss: 267.2301, Training Accuracy: 0.2415\n",
      "Validation Loss: 241.3942, Validation Accuracy: 0.2571\n",
      "New best validation loss: 241.3942, saving model.\n",
      "Epoch 653/1000\n",
      "Training Loss: 266.6684, Training Accuracy: 0.2423\n",
      "Validation Loss: 241.3916, Validation Accuracy: 0.2574\n",
      "New best validation loss: 241.3916, saving model.\n",
      "Epoch 654/1000\n",
      "Training Loss: 266.9834, Training Accuracy: 0.2422\n",
      "Validation Loss: 241.3890, Validation Accuracy: 0.2578\n",
      "New best validation loss: 241.3890, saving model.\n",
      "Epoch 655/1000\n",
      "Training Loss: 268.3145, Training Accuracy: 0.2412\n",
      "Validation Loss: 241.3865, Validation Accuracy: 0.2582\n",
      "New best validation loss: 241.3865, saving model.\n",
      "Epoch 656/1000\n",
      "Training Loss: 267.4422, Training Accuracy: 0.2434\n",
      "Validation Loss: 241.3839, Validation Accuracy: 0.2585\n",
      "New best validation loss: 241.3839, saving model.\n",
      "Epoch 657/1000\n",
      "Training Loss: 268.7314, Training Accuracy: 0.2439\n",
      "Validation Loss: 241.3813, Validation Accuracy: 0.2588\n",
      "New best validation loss: 241.3813, saving model.\n",
      "Epoch 658/1000\n",
      "Training Loss: 265.8340, Training Accuracy: 0.2441\n",
      "Validation Loss: 241.3787, Validation Accuracy: 0.2593\n",
      "New best validation loss: 241.3787, saving model.\n",
      "Epoch 659/1000\n",
      "Training Loss: 266.7510, Training Accuracy: 0.2433\n",
      "Validation Loss: 241.3761, Validation Accuracy: 0.2596\n",
      "New best validation loss: 241.3761, saving model.\n",
      "Epoch 660/1000\n",
      "Training Loss: 266.8494, Training Accuracy: 0.2440\n",
      "Validation Loss: 241.3735, Validation Accuracy: 0.2600\n",
      "New best validation loss: 241.3735, saving model.\n",
      "Epoch 661/1000\n",
      "Training Loss: 267.2611, Training Accuracy: 0.2445\n",
      "Validation Loss: 241.3709, Validation Accuracy: 0.2603\n",
      "New best validation loss: 241.3709, saving model.\n",
      "Epoch 662/1000\n",
      "Training Loss: 266.3897, Training Accuracy: 0.2453\n",
      "Validation Loss: 241.3683, Validation Accuracy: 0.2607\n",
      "New best validation loss: 241.3683, saving model.\n",
      "Epoch 663/1000\n",
      "Training Loss: 267.2691, Training Accuracy: 0.2445\n",
      "Validation Loss: 241.3657, Validation Accuracy: 0.2611\n",
      "New best validation loss: 241.3657, saving model.\n",
      "Epoch 664/1000\n",
      "Training Loss: 267.2071, Training Accuracy: 0.2453\n",
      "Validation Loss: 241.3631, Validation Accuracy: 0.2615\n",
      "New best validation loss: 241.3631, saving model.\n",
      "Epoch 665/1000\n",
      "Training Loss: 267.3333, Training Accuracy: 0.2436\n",
      "Validation Loss: 241.3605, Validation Accuracy: 0.2618\n",
      "New best validation loss: 241.3605, saving model.\n",
      "Epoch 666/1000\n",
      "Training Loss: 269.7515, Training Accuracy: 0.2463\n",
      "Validation Loss: 241.3579, Validation Accuracy: 0.2621\n",
      "New best validation loss: 241.3579, saving model.\n",
      "Epoch 667/1000\n",
      "Training Loss: 266.5201, Training Accuracy: 0.2466\n",
      "Validation Loss: 241.3552, Validation Accuracy: 0.2625\n",
      "New best validation loss: 241.3552, saving model.\n",
      "Epoch 668/1000\n",
      "Training Loss: 266.7670, Training Accuracy: 0.2476\n",
      "Validation Loss: 241.3526, Validation Accuracy: 0.2629\n",
      "New best validation loss: 241.3526, saving model.\n",
      "Epoch 669/1000\n",
      "Training Loss: 268.8523, Training Accuracy: 0.2477\n",
      "Validation Loss: 241.3499, Validation Accuracy: 0.2632\n",
      "New best validation loss: 241.3499, saving model.\n",
      "Epoch 670/1000\n",
      "Training Loss: 267.0247, Training Accuracy: 0.2467\n",
      "Validation Loss: 241.3473, Validation Accuracy: 0.2635\n",
      "New best validation loss: 241.3473, saving model.\n",
      "Epoch 671/1000\n",
      "Training Loss: 266.4084, Training Accuracy: 0.2478\n",
      "Validation Loss: 241.3446, Validation Accuracy: 0.2639\n",
      "New best validation loss: 241.3446, saving model.\n",
      "Epoch 672/1000\n",
      "Training Loss: 267.4029, Training Accuracy: 0.2481\n",
      "Validation Loss: 241.3420, Validation Accuracy: 0.2643\n",
      "New best validation loss: 241.3420, saving model.\n",
      "Epoch 673/1000\n",
      "Training Loss: 267.5735, Training Accuracy: 0.2468\n",
      "Validation Loss: 241.3393, Validation Accuracy: 0.2647\n",
      "New best validation loss: 241.3393, saving model.\n",
      "Epoch 674/1000\n",
      "Training Loss: 268.4496, Training Accuracy: 0.2486\n",
      "Validation Loss: 241.3366, Validation Accuracy: 0.2651\n",
      "New best validation loss: 241.3366, saving model.\n",
      "Epoch 675/1000\n",
      "Training Loss: 267.4922, Training Accuracy: 0.2496\n",
      "Validation Loss: 241.3340, Validation Accuracy: 0.2654\n",
      "New best validation loss: 241.3340, saving model.\n",
      "Epoch 676/1000\n",
      "Training Loss: 268.4642, Training Accuracy: 0.2487\n",
      "Validation Loss: 241.3313, Validation Accuracy: 0.2658\n",
      "New best validation loss: 241.3313, saving model.\n",
      "Epoch 677/1000\n",
      "Training Loss: 265.9041, Training Accuracy: 0.2505\n",
      "Validation Loss: 241.3286, Validation Accuracy: 0.2662\n",
      "New best validation loss: 241.3286, saving model.\n",
      "Epoch 678/1000\n",
      "Training Loss: 266.6415, Training Accuracy: 0.2509\n",
      "Validation Loss: 241.3259, Validation Accuracy: 0.2667\n",
      "New best validation loss: 241.3259, saving model.\n",
      "Epoch 679/1000\n",
      "Training Loss: 267.5900, Training Accuracy: 0.2510\n",
      "Validation Loss: 241.3232, Validation Accuracy: 0.2671\n",
      "New best validation loss: 241.3232, saving model.\n",
      "Epoch 680/1000\n",
      "Training Loss: 268.1296, Training Accuracy: 0.2511\n",
      "Validation Loss: 241.3206, Validation Accuracy: 0.2675\n",
      "New best validation loss: 241.3206, saving model.\n",
      "Epoch 681/1000\n",
      "Training Loss: 266.0772, Training Accuracy: 0.2512\n",
      "Validation Loss: 241.3179, Validation Accuracy: 0.2679\n",
      "New best validation loss: 241.3179, saving model.\n",
      "Epoch 682/1000\n",
      "Training Loss: 265.7824, Training Accuracy: 0.2530\n",
      "Validation Loss: 241.3152, Validation Accuracy: 0.2684\n",
      "New best validation loss: 241.3152, saving model.\n",
      "Epoch 683/1000\n",
      "Training Loss: 268.0517, Training Accuracy: 0.2519\n",
      "Validation Loss: 241.3125, Validation Accuracy: 0.2688\n",
      "New best validation loss: 241.3125, saving model.\n",
      "Epoch 684/1000\n",
      "Training Loss: 267.5404, Training Accuracy: 0.2517\n",
      "Validation Loss: 241.3098, Validation Accuracy: 0.2692\n",
      "New best validation loss: 241.3098, saving model.\n",
      "Epoch 685/1000\n",
      "Training Loss: 267.4292, Training Accuracy: 0.2521\n",
      "Validation Loss: 241.3070, Validation Accuracy: 0.2696\n",
      "New best validation loss: 241.3070, saving model.\n",
      "Epoch 686/1000\n",
      "Training Loss: 266.7476, Training Accuracy: 0.2545\n",
      "Validation Loss: 241.3043, Validation Accuracy: 0.2699\n",
      "New best validation loss: 241.3043, saving model.\n",
      "Epoch 687/1000\n",
      "Training Loss: 267.1852, Training Accuracy: 0.2533\n",
      "Validation Loss: 241.3015, Validation Accuracy: 0.2704\n",
      "New best validation loss: 241.3015, saving model.\n",
      "Epoch 688/1000\n",
      "Training Loss: 267.5739, Training Accuracy: 0.2544\n",
      "Validation Loss: 241.2988, Validation Accuracy: 0.2708\n",
      "New best validation loss: 241.2988, saving model.\n",
      "Epoch 689/1000\n",
      "Training Loss: 267.3366, Training Accuracy: 0.2540\n",
      "Validation Loss: 241.2960, Validation Accuracy: 0.2712\n",
      "New best validation loss: 241.2960, saving model.\n",
      "Epoch 690/1000\n",
      "Training Loss: 267.5916, Training Accuracy: 0.2553\n",
      "Validation Loss: 241.2933, Validation Accuracy: 0.2715\n",
      "New best validation loss: 241.2933, saving model.\n",
      "Epoch 691/1000\n",
      "Training Loss: 266.1656, Training Accuracy: 0.2549\n",
      "Validation Loss: 241.2905, Validation Accuracy: 0.2719\n",
      "New best validation loss: 241.2905, saving model.\n",
      "Epoch 692/1000\n",
      "Training Loss: 267.6011, Training Accuracy: 0.2558\n",
      "Validation Loss: 241.2877, Validation Accuracy: 0.2723\n",
      "New best validation loss: 241.2877, saving model.\n",
      "Epoch 693/1000\n",
      "Training Loss: 265.8954, Training Accuracy: 0.2564\n",
      "Validation Loss: 241.2850, Validation Accuracy: 0.2727\n",
      "New best validation loss: 241.2850, saving model.\n",
      "Epoch 694/1000\n",
      "Training Loss: 266.4157, Training Accuracy: 0.2550\n",
      "Validation Loss: 241.2822, Validation Accuracy: 0.2731\n",
      "New best validation loss: 241.2822, saving model.\n",
      "Epoch 695/1000\n",
      "Training Loss: 266.8142, Training Accuracy: 0.2565\n",
      "Validation Loss: 241.2793, Validation Accuracy: 0.2734\n",
      "New best validation loss: 241.2793, saving model.\n",
      "Epoch 696/1000\n",
      "Training Loss: 267.0956, Training Accuracy: 0.2573\n",
      "Validation Loss: 241.2765, Validation Accuracy: 0.2738\n",
      "New best validation loss: 241.2765, saving model.\n",
      "Epoch 697/1000\n",
      "Training Loss: 266.8151, Training Accuracy: 0.2581\n",
      "Validation Loss: 241.2737, Validation Accuracy: 0.2741\n",
      "New best validation loss: 241.2737, saving model.\n",
      "Epoch 698/1000\n",
      "Training Loss: 266.0127, Training Accuracy: 0.2583\n",
      "Validation Loss: 241.2709, Validation Accuracy: 0.2745\n",
      "New best validation loss: 241.2709, saving model.\n",
      "Epoch 699/1000\n",
      "Training Loss: 267.0121, Training Accuracy: 0.2585\n",
      "Validation Loss: 241.2681, Validation Accuracy: 0.2749\n",
      "New best validation loss: 241.2681, saving model.\n",
      "Epoch 700/1000\n",
      "Training Loss: 268.0834, Training Accuracy: 0.2582\n",
      "Validation Loss: 241.2653, Validation Accuracy: 0.2752\n",
      "New best validation loss: 241.2653, saving model.\n",
      "Epoch 701/1000\n",
      "Training Loss: 265.9810, Training Accuracy: 0.2586\n",
      "Validation Loss: 241.2625, Validation Accuracy: 0.2756\n",
      "New best validation loss: 241.2625, saving model.\n",
      "Epoch 702/1000\n",
      "Training Loss: 268.5486, Training Accuracy: 0.2579\n",
      "Validation Loss: 241.2596, Validation Accuracy: 0.2760\n",
      "New best validation loss: 241.2596, saving model.\n",
      "Epoch 703/1000\n",
      "Training Loss: 266.8222, Training Accuracy: 0.2587\n",
      "Validation Loss: 241.2568, Validation Accuracy: 0.2763\n",
      "New best validation loss: 241.2568, saving model.\n",
      "Epoch 704/1000\n",
      "Training Loss: 267.2728, Training Accuracy: 0.2592\n",
      "Validation Loss: 241.2540, Validation Accuracy: 0.2767\n",
      "New best validation loss: 241.2540, saving model.\n",
      "Epoch 705/1000\n",
      "Training Loss: 266.9837, Training Accuracy: 0.2599\n",
      "Validation Loss: 241.2511, Validation Accuracy: 0.2770\n",
      "New best validation loss: 241.2511, saving model.\n",
      "Epoch 706/1000\n",
      "Training Loss: 266.8516, Training Accuracy: 0.2594\n",
      "Validation Loss: 241.2482, Validation Accuracy: 0.2775\n",
      "New best validation loss: 241.2482, saving model.\n",
      "Epoch 707/1000\n",
      "Training Loss: 267.1346, Training Accuracy: 0.2593\n",
      "Validation Loss: 241.2453, Validation Accuracy: 0.2779\n",
      "New best validation loss: 241.2453, saving model.\n",
      "Epoch 708/1000\n",
      "Training Loss: 266.9441, Training Accuracy: 0.2597\n",
      "Validation Loss: 241.2425, Validation Accuracy: 0.2783\n",
      "New best validation loss: 241.2425, saving model.\n",
      "Epoch 709/1000\n",
      "Training Loss: 268.2714, Training Accuracy: 0.2617\n",
      "Validation Loss: 241.2395, Validation Accuracy: 0.2787\n",
      "New best validation loss: 241.2395, saving model.\n",
      "Epoch 710/1000\n",
      "Training Loss: 266.1783, Training Accuracy: 0.2610\n",
      "Validation Loss: 241.2366, Validation Accuracy: 0.2791\n",
      "New best validation loss: 241.2366, saving model.\n",
      "Epoch 711/1000\n",
      "Training Loss: 266.2608, Training Accuracy: 0.2623\n",
      "Validation Loss: 241.2337, Validation Accuracy: 0.2795\n",
      "New best validation loss: 241.2337, saving model.\n",
      "Epoch 712/1000\n",
      "Training Loss: 267.2933, Training Accuracy: 0.2620\n",
      "Validation Loss: 241.2308, Validation Accuracy: 0.2798\n",
      "New best validation loss: 241.2308, saving model.\n",
      "Epoch 713/1000\n",
      "Training Loss: 266.4362, Training Accuracy: 0.2623\n",
      "Validation Loss: 241.2279, Validation Accuracy: 0.2802\n",
      "New best validation loss: 241.2279, saving model.\n",
      "Epoch 714/1000\n",
      "Training Loss: 268.6267, Training Accuracy: 0.2612\n",
      "Validation Loss: 241.2249, Validation Accuracy: 0.2805\n",
      "New best validation loss: 241.2249, saving model.\n",
      "Epoch 715/1000\n",
      "Training Loss: 266.2256, Training Accuracy: 0.2631\n",
      "Validation Loss: 241.2219, Validation Accuracy: 0.2810\n",
      "New best validation loss: 241.2219, saving model.\n",
      "Epoch 716/1000\n",
      "Training Loss: 266.3215, Training Accuracy: 0.2641\n",
      "Validation Loss: 241.2190, Validation Accuracy: 0.2814\n",
      "New best validation loss: 241.2190, saving model.\n",
      "Epoch 717/1000\n",
      "Training Loss: 265.6204, Training Accuracy: 0.2642\n",
      "Validation Loss: 241.2160, Validation Accuracy: 0.2817\n",
      "New best validation loss: 241.2160, saving model.\n",
      "Epoch 718/1000\n",
      "Training Loss: 265.7428, Training Accuracy: 0.2646\n",
      "Validation Loss: 241.2131, Validation Accuracy: 0.2822\n",
      "New best validation loss: 241.2131, saving model.\n",
      "Epoch 719/1000\n",
      "Training Loss: 266.7678, Training Accuracy: 0.2638\n",
      "Validation Loss: 241.2101, Validation Accuracy: 0.2825\n",
      "New best validation loss: 241.2101, saving model.\n",
      "Epoch 720/1000\n",
      "Training Loss: 265.9845, Training Accuracy: 0.2660\n",
      "Validation Loss: 241.2071, Validation Accuracy: 0.2829\n",
      "New best validation loss: 241.2071, saving model.\n",
      "Epoch 721/1000\n",
      "Training Loss: 266.5494, Training Accuracy: 0.2650\n",
      "Validation Loss: 241.2041, Validation Accuracy: 0.2833\n",
      "New best validation loss: 241.2041, saving model.\n",
      "Epoch 722/1000\n",
      "Training Loss: 266.2039, Training Accuracy: 0.2656\n",
      "Validation Loss: 241.2011, Validation Accuracy: 0.2837\n",
      "New best validation loss: 241.2011, saving model.\n",
      "Epoch 723/1000\n",
      "Training Loss: 265.8151, Training Accuracy: 0.2662\n",
      "Validation Loss: 241.1980, Validation Accuracy: 0.2841\n",
      "New best validation loss: 241.1980, saving model.\n",
      "Epoch 724/1000\n",
      "Training Loss: 266.1859, Training Accuracy: 0.2665\n",
      "Validation Loss: 241.1950, Validation Accuracy: 0.2844\n",
      "New best validation loss: 241.1950, saving model.\n",
      "Epoch 725/1000\n",
      "Training Loss: 266.2112, Training Accuracy: 0.2666\n",
      "Validation Loss: 241.1920, Validation Accuracy: 0.2847\n",
      "New best validation loss: 241.1920, saving model.\n",
      "Epoch 726/1000\n",
      "Training Loss: 266.2068, Training Accuracy: 0.2670\n",
      "Validation Loss: 241.1890, Validation Accuracy: 0.2851\n",
      "New best validation loss: 241.1890, saving model.\n",
      "Epoch 727/1000\n",
      "Training Loss: 267.6603, Training Accuracy: 0.2671\n",
      "Validation Loss: 241.1859, Validation Accuracy: 0.2855\n",
      "New best validation loss: 241.1859, saving model.\n",
      "Epoch 728/1000\n",
      "Training Loss: 267.4229, Training Accuracy: 0.2667\n",
      "Validation Loss: 241.1829, Validation Accuracy: 0.2858\n",
      "New best validation loss: 241.1829, saving model.\n",
      "Epoch 729/1000\n",
      "Training Loss: 266.1866, Training Accuracy: 0.2678\n",
      "Validation Loss: 241.1798, Validation Accuracy: 0.2861\n",
      "New best validation loss: 241.1798, saving model.\n",
      "Epoch 730/1000\n",
      "Training Loss: 266.4584, Training Accuracy: 0.2674\n",
      "Validation Loss: 241.1767, Validation Accuracy: 0.2865\n",
      "New best validation loss: 241.1767, saving model.\n",
      "Epoch 731/1000\n",
      "Training Loss: 267.7368, Training Accuracy: 0.2685\n",
      "Validation Loss: 241.1737, Validation Accuracy: 0.2869\n",
      "New best validation loss: 241.1737, saving model.\n",
      "Epoch 732/1000\n",
      "Training Loss: 266.8630, Training Accuracy: 0.2674\n",
      "Validation Loss: 241.1706, Validation Accuracy: 0.2872\n",
      "New best validation loss: 241.1706, saving model.\n",
      "Epoch 733/1000\n",
      "Training Loss: 266.7138, Training Accuracy: 0.2698\n",
      "Validation Loss: 241.1675, Validation Accuracy: 0.2874\n",
      "New best validation loss: 241.1675, saving model.\n",
      "Epoch 734/1000\n",
      "Training Loss: 267.1280, Training Accuracy: 0.2695\n",
      "Validation Loss: 241.1644, Validation Accuracy: 0.2879\n",
      "New best validation loss: 241.1644, saving model.\n",
      "Epoch 735/1000\n",
      "Training Loss: 266.6822, Training Accuracy: 0.2701\n",
      "Validation Loss: 241.1613, Validation Accuracy: 0.2881\n",
      "New best validation loss: 241.1613, saving model.\n",
      "Epoch 736/1000\n",
      "Training Loss: 267.7095, Training Accuracy: 0.2679\n",
      "Validation Loss: 241.1582, Validation Accuracy: 0.2885\n",
      "New best validation loss: 241.1582, saving model.\n",
      "Epoch 737/1000\n",
      "Training Loss: 266.6748, Training Accuracy: 0.2700\n",
      "Validation Loss: 241.1551, Validation Accuracy: 0.2888\n",
      "New best validation loss: 241.1551, saving model.\n",
      "Epoch 738/1000\n",
      "Training Loss: 266.2613, Training Accuracy: 0.2687\n",
      "Validation Loss: 241.1521, Validation Accuracy: 0.2891\n",
      "New best validation loss: 241.1521, saving model.\n",
      "Epoch 739/1000\n",
      "Training Loss: 266.7061, Training Accuracy: 0.2711\n",
      "Validation Loss: 241.1489, Validation Accuracy: 0.2894\n",
      "New best validation loss: 241.1489, saving model.\n",
      "Epoch 740/1000\n",
      "Training Loss: 267.2833, Training Accuracy: 0.2696\n",
      "Validation Loss: 241.1458, Validation Accuracy: 0.2898\n",
      "New best validation loss: 241.1458, saving model.\n",
      "Epoch 741/1000\n",
      "Training Loss: 266.0781, Training Accuracy: 0.2718\n",
      "Validation Loss: 241.1426, Validation Accuracy: 0.2900\n",
      "New best validation loss: 241.1426, saving model.\n",
      "Epoch 742/1000\n",
      "Training Loss: 267.6969, Training Accuracy: 0.2730\n",
      "Validation Loss: 241.1395, Validation Accuracy: 0.2903\n",
      "New best validation loss: 241.1395, saving model.\n",
      "Epoch 743/1000\n",
      "Training Loss: 267.8997, Training Accuracy: 0.2736\n",
      "Validation Loss: 241.1363, Validation Accuracy: 0.2906\n",
      "New best validation loss: 241.1363, saving model.\n",
      "Epoch 744/1000\n",
      "Training Loss: 269.0987, Training Accuracy: 0.2714\n",
      "Validation Loss: 241.1331, Validation Accuracy: 0.2909\n",
      "New best validation loss: 241.1331, saving model.\n",
      "Epoch 745/1000\n",
      "Training Loss: 267.0661, Training Accuracy: 0.2731\n",
      "Validation Loss: 241.1300, Validation Accuracy: 0.2911\n",
      "New best validation loss: 241.1300, saving model.\n",
      "Epoch 746/1000\n",
      "Training Loss: 268.8250, Training Accuracy: 0.2728\n",
      "Validation Loss: 241.1267, Validation Accuracy: 0.2914\n",
      "New best validation loss: 241.1267, saving model.\n",
      "Epoch 747/1000\n",
      "Training Loss: 267.3652, Training Accuracy: 0.2741\n",
      "Validation Loss: 241.1235, Validation Accuracy: 0.2916\n",
      "New best validation loss: 241.1235, saving model.\n",
      "Epoch 748/1000\n",
      "Training Loss: 266.9025, Training Accuracy: 0.2732\n",
      "Validation Loss: 241.1203, Validation Accuracy: 0.2919\n",
      "New best validation loss: 241.1203, saving model.\n",
      "Epoch 749/1000\n",
      "Training Loss: 266.1520, Training Accuracy: 0.2741\n",
      "Validation Loss: 241.1171, Validation Accuracy: 0.2921\n",
      "New best validation loss: 241.1171, saving model.\n",
      "Epoch 750/1000\n",
      "Training Loss: 267.2014, Training Accuracy: 0.2744\n",
      "Validation Loss: 241.1138, Validation Accuracy: 0.2924\n",
      "New best validation loss: 241.1138, saving model.\n",
      "Epoch 751/1000\n",
      "Training Loss: 270.0431, Training Accuracy: 0.2733\n",
      "Validation Loss: 241.1105, Validation Accuracy: 0.2927\n",
      "New best validation loss: 241.1105, saving model.\n",
      "Epoch 752/1000\n",
      "Training Loss: 266.4191, Training Accuracy: 0.2742\n",
      "Validation Loss: 241.1073, Validation Accuracy: 0.2930\n",
      "New best validation loss: 241.1073, saving model.\n",
      "Epoch 753/1000\n",
      "Training Loss: 266.2066, Training Accuracy: 0.2752\n",
      "Validation Loss: 241.1040, Validation Accuracy: 0.2933\n",
      "New best validation loss: 241.1040, saving model.\n",
      "Epoch 754/1000\n",
      "Training Loss: 266.4242, Training Accuracy: 0.2757\n",
      "Validation Loss: 241.1008, Validation Accuracy: 0.2936\n",
      "New best validation loss: 241.1008, saving model.\n",
      "Epoch 755/1000\n",
      "Training Loss: 265.6979, Training Accuracy: 0.2751\n",
      "Validation Loss: 241.0975, Validation Accuracy: 0.2940\n",
      "New best validation loss: 241.0975, saving model.\n",
      "Epoch 756/1000\n",
      "Training Loss: 265.5316, Training Accuracy: 0.2768\n",
      "Validation Loss: 241.0942, Validation Accuracy: 0.2943\n",
      "New best validation loss: 241.0942, saving model.\n",
      "Epoch 757/1000\n",
      "Training Loss: 265.9144, Training Accuracy: 0.2775\n",
      "Validation Loss: 241.0909, Validation Accuracy: 0.2945\n",
      "New best validation loss: 241.0909, saving model.\n",
      "Epoch 758/1000\n",
      "Training Loss: 267.6926, Training Accuracy: 0.2772\n",
      "Validation Loss: 241.0876, Validation Accuracy: 0.2949\n",
      "New best validation loss: 241.0876, saving model.\n",
      "Epoch 759/1000\n",
      "Training Loss: 267.1482, Training Accuracy: 0.2763\n",
      "Validation Loss: 241.0842, Validation Accuracy: 0.2952\n",
      "New best validation loss: 241.0842, saving model.\n",
      "Epoch 760/1000\n",
      "Training Loss: 266.9195, Training Accuracy: 0.2782\n",
      "Validation Loss: 241.0809, Validation Accuracy: 0.2956\n",
      "New best validation loss: 241.0809, saving model.\n",
      "Epoch 761/1000\n",
      "Training Loss: 267.4175, Training Accuracy: 0.2757\n",
      "Validation Loss: 241.0776, Validation Accuracy: 0.2959\n",
      "New best validation loss: 241.0776, saving model.\n",
      "Epoch 762/1000\n",
      "Training Loss: 266.2792, Training Accuracy: 0.2762\n",
      "Validation Loss: 241.0743, Validation Accuracy: 0.2962\n",
      "New best validation loss: 241.0743, saving model.\n",
      "Epoch 763/1000\n",
      "Training Loss: 266.4499, Training Accuracy: 0.2763\n",
      "Validation Loss: 241.0709, Validation Accuracy: 0.2966\n",
      "New best validation loss: 241.0709, saving model.\n",
      "Epoch 764/1000\n",
      "Training Loss: 267.8466, Training Accuracy: 0.2776\n",
      "Validation Loss: 241.0675, Validation Accuracy: 0.2968\n",
      "New best validation loss: 241.0675, saving model.\n",
      "Epoch 765/1000\n",
      "Training Loss: 266.6269, Training Accuracy: 0.2776\n",
      "Validation Loss: 241.0642, Validation Accuracy: 0.2971\n",
      "New best validation loss: 241.0642, saving model.\n",
      "Epoch 766/1000\n",
      "Training Loss: 266.4845, Training Accuracy: 0.2785\n",
      "Validation Loss: 241.0608, Validation Accuracy: 0.2975\n",
      "New best validation loss: 241.0608, saving model.\n",
      "Epoch 767/1000\n",
      "Training Loss: 266.7924, Training Accuracy: 0.2773\n",
      "Validation Loss: 241.0574, Validation Accuracy: 0.2978\n",
      "New best validation loss: 241.0574, saving model.\n",
      "Epoch 768/1000\n",
      "Training Loss: 265.6742, Training Accuracy: 0.2809\n",
      "Validation Loss: 241.0539, Validation Accuracy: 0.2981\n",
      "New best validation loss: 241.0539, saving model.\n",
      "Epoch 769/1000\n",
      "Training Loss: 265.9810, Training Accuracy: 0.2774\n",
      "Validation Loss: 241.0505, Validation Accuracy: 0.2985\n",
      "New best validation loss: 241.0505, saving model.\n",
      "Epoch 770/1000\n",
      "Training Loss: 266.4967, Training Accuracy: 0.2798\n",
      "Validation Loss: 241.0471, Validation Accuracy: 0.2987\n",
      "New best validation loss: 241.0471, saving model.\n",
      "Epoch 771/1000\n",
      "Training Loss: 266.8514, Training Accuracy: 0.2770\n",
      "Validation Loss: 241.0436, Validation Accuracy: 0.2991\n",
      "New best validation loss: 241.0436, saving model.\n",
      "Epoch 772/1000\n",
      "Training Loss: 267.8365, Training Accuracy: 0.2777\n",
      "Validation Loss: 241.0401, Validation Accuracy: 0.2994\n",
      "New best validation loss: 241.0401, saving model.\n",
      "Epoch 773/1000\n",
      "Training Loss: 266.8668, Training Accuracy: 0.2817\n",
      "Validation Loss: 241.0367, Validation Accuracy: 0.2997\n",
      "New best validation loss: 241.0367, saving model.\n",
      "Epoch 774/1000\n",
      "Training Loss: 266.8345, Training Accuracy: 0.2797\n",
      "Validation Loss: 241.0332, Validation Accuracy: 0.3000\n",
      "New best validation loss: 241.0332, saving model.\n",
      "Epoch 775/1000\n",
      "Training Loss: 265.8149, Training Accuracy: 0.2797\n",
      "Validation Loss: 241.0298, Validation Accuracy: 0.3003\n",
      "New best validation loss: 241.0298, saving model.\n",
      "Epoch 776/1000\n",
      "Training Loss: 266.1188, Training Accuracy: 0.2795\n",
      "Validation Loss: 241.0263, Validation Accuracy: 0.3006\n",
      "New best validation loss: 241.0263, saving model.\n",
      "Epoch 777/1000\n",
      "Training Loss: 265.4890, Training Accuracy: 0.2815\n",
      "Validation Loss: 241.0228, Validation Accuracy: 0.3009\n",
      "New best validation loss: 241.0228, saving model.\n",
      "Epoch 778/1000\n",
      "Training Loss: 267.0195, Training Accuracy: 0.2818\n",
      "Validation Loss: 241.0193, Validation Accuracy: 0.3012\n",
      "New best validation loss: 241.0193, saving model.\n",
      "Epoch 779/1000\n",
      "Training Loss: 266.5735, Training Accuracy: 0.2829\n",
      "Validation Loss: 241.0157, Validation Accuracy: 0.3015\n",
      "New best validation loss: 241.0157, saving model.\n",
      "Epoch 780/1000\n",
      "Training Loss: 268.5545, Training Accuracy: 0.2797\n",
      "Validation Loss: 241.0122, Validation Accuracy: 0.3019\n",
      "New best validation loss: 241.0122, saving model.\n",
      "Epoch 781/1000\n",
      "Training Loss: 266.4906, Training Accuracy: 0.2799\n",
      "Validation Loss: 241.0086, Validation Accuracy: 0.3022\n",
      "New best validation loss: 241.0086, saving model.\n",
      "Epoch 782/1000\n",
      "Training Loss: 267.3850, Training Accuracy: 0.2810\n",
      "Validation Loss: 241.0050, Validation Accuracy: 0.3025\n",
      "New best validation loss: 241.0050, saving model.\n",
      "Epoch 783/1000\n",
      "Training Loss: 268.4123, Training Accuracy: 0.2825\n",
      "Validation Loss: 241.0014, Validation Accuracy: 0.3029\n",
      "New best validation loss: 241.0014, saving model.\n",
      "Epoch 784/1000\n",
      "Training Loss: 267.1638, Training Accuracy: 0.2828\n",
      "Validation Loss: 240.9979, Validation Accuracy: 0.3032\n",
      "New best validation loss: 240.9979, saving model.\n",
      "Epoch 785/1000\n",
      "Training Loss: 268.2876, Training Accuracy: 0.2803\n",
      "Validation Loss: 240.9943, Validation Accuracy: 0.3035\n",
      "New best validation loss: 240.9943, saving model.\n",
      "Epoch 786/1000\n",
      "Training Loss: 266.4626, Training Accuracy: 0.2833\n",
      "Validation Loss: 240.9907, Validation Accuracy: 0.3039\n",
      "New best validation loss: 240.9907, saving model.\n",
      "Epoch 787/1000\n",
      "Training Loss: 266.9723, Training Accuracy: 0.2825\n",
      "Validation Loss: 240.9871, Validation Accuracy: 0.3042\n",
      "New best validation loss: 240.9871, saving model.\n",
      "Epoch 788/1000\n",
      "Training Loss: 266.1898, Training Accuracy: 0.2821\n",
      "Validation Loss: 240.9835, Validation Accuracy: 0.3044\n",
      "New best validation loss: 240.9835, saving model.\n",
      "Epoch 789/1000\n",
      "Training Loss: 266.7297, Training Accuracy: 0.2856\n",
      "Validation Loss: 240.9798, Validation Accuracy: 0.3049\n",
      "New best validation loss: 240.9798, saving model.\n",
      "Epoch 790/1000\n",
      "Training Loss: 266.0549, Training Accuracy: 0.2839\n",
      "Validation Loss: 240.9762, Validation Accuracy: 0.3051\n",
      "New best validation loss: 240.9762, saving model.\n",
      "Epoch 791/1000\n",
      "Training Loss: 266.5624, Training Accuracy: 0.2844\n",
      "Validation Loss: 240.9726, Validation Accuracy: 0.3054\n",
      "New best validation loss: 240.9726, saving model.\n",
      "Epoch 792/1000\n",
      "Training Loss: 266.2853, Training Accuracy: 0.2846\n",
      "Validation Loss: 240.9689, Validation Accuracy: 0.3056\n",
      "New best validation loss: 240.9689, saving model.\n",
      "Epoch 793/1000\n",
      "Training Loss: 266.6289, Training Accuracy: 0.2849\n",
      "Validation Loss: 240.9653, Validation Accuracy: 0.3059\n",
      "New best validation loss: 240.9653, saving model.\n",
      "Epoch 794/1000\n",
      "Training Loss: 266.3197, Training Accuracy: 0.2866\n",
      "Validation Loss: 240.9616, Validation Accuracy: 0.3062\n",
      "New best validation loss: 240.9616, saving model.\n",
      "Epoch 795/1000\n",
      "Training Loss: 265.8547, Training Accuracy: 0.2853\n",
      "Validation Loss: 240.9579, Validation Accuracy: 0.3065\n",
      "New best validation loss: 240.9579, saving model.\n",
      "Epoch 796/1000\n",
      "Training Loss: 265.9268, Training Accuracy: 0.2870\n",
      "Validation Loss: 240.9542, Validation Accuracy: 0.3068\n",
      "New best validation loss: 240.9542, saving model.\n",
      "Epoch 797/1000\n",
      "Training Loss: 266.6348, Training Accuracy: 0.2858\n",
      "Validation Loss: 240.9505, Validation Accuracy: 0.3070\n",
      "New best validation loss: 240.9505, saving model.\n",
      "Epoch 798/1000\n",
      "Training Loss: 266.0331, Training Accuracy: 0.2854\n",
      "Validation Loss: 240.9468, Validation Accuracy: 0.3074\n",
      "New best validation loss: 240.9468, saving model.\n",
      "Epoch 799/1000\n",
      "Training Loss: 266.0936, Training Accuracy: 0.2850\n",
      "Validation Loss: 240.9431, Validation Accuracy: 0.3077\n",
      "New best validation loss: 240.9431, saving model.\n",
      "Epoch 800/1000\n",
      "Training Loss: 267.3768, Training Accuracy: 0.2868\n",
      "Validation Loss: 240.9393, Validation Accuracy: 0.3081\n",
      "New best validation loss: 240.9393, saving model.\n",
      "Epoch 801/1000\n",
      "Training Loss: 266.4239, Training Accuracy: 0.2875\n",
      "Validation Loss: 240.9357, Validation Accuracy: 0.3084\n",
      "New best validation loss: 240.9357, saving model.\n",
      "Epoch 802/1000\n",
      "Training Loss: 268.1467, Training Accuracy: 0.2883\n",
      "Validation Loss: 240.9319, Validation Accuracy: 0.3086\n",
      "New best validation loss: 240.9319, saving model.\n",
      "Epoch 803/1000\n",
      "Training Loss: 266.7345, Training Accuracy: 0.2868\n",
      "Validation Loss: 240.9282, Validation Accuracy: 0.3089\n",
      "New best validation loss: 240.9282, saving model.\n",
      "Epoch 804/1000\n",
      "Training Loss: 266.1807, Training Accuracy: 0.2890\n",
      "Validation Loss: 240.9244, Validation Accuracy: 0.3091\n",
      "New best validation loss: 240.9244, saving model.\n",
      "Epoch 805/1000\n",
      "Training Loss: 267.1225, Training Accuracy: 0.2912\n",
      "Validation Loss: 240.9206, Validation Accuracy: 0.3093\n",
      "New best validation loss: 240.9206, saving model.\n",
      "Epoch 806/1000\n",
      "Training Loss: 268.4183, Training Accuracy: 0.2877\n",
      "Validation Loss: 240.9169, Validation Accuracy: 0.3096\n",
      "New best validation loss: 240.9169, saving model.\n",
      "Epoch 807/1000\n",
      "Training Loss: 266.7300, Training Accuracy: 0.2914\n",
      "Validation Loss: 240.9131, Validation Accuracy: 0.3098\n",
      "New best validation loss: 240.9131, saving model.\n",
      "Epoch 808/1000\n",
      "Training Loss: 265.8904, Training Accuracy: 0.2895\n",
      "Validation Loss: 240.9094, Validation Accuracy: 0.3100\n",
      "New best validation loss: 240.9094, saving model.\n",
      "Epoch 809/1000\n",
      "Training Loss: 266.2478, Training Accuracy: 0.2901\n",
      "Validation Loss: 240.9056, Validation Accuracy: 0.3103\n",
      "New best validation loss: 240.9056, saving model.\n",
      "Epoch 810/1000\n",
      "Training Loss: 266.0492, Training Accuracy: 0.2898\n",
      "Validation Loss: 240.9018, Validation Accuracy: 0.3105\n",
      "New best validation loss: 240.9018, saving model.\n",
      "Epoch 811/1000\n",
      "Training Loss: 267.3673, Training Accuracy: 0.2896\n",
      "Validation Loss: 240.8980, Validation Accuracy: 0.3108\n",
      "New best validation loss: 240.8980, saving model.\n",
      "Epoch 812/1000\n",
      "Training Loss: 267.8001, Training Accuracy: 0.2890\n",
      "Validation Loss: 240.8942, Validation Accuracy: 0.3111\n",
      "New best validation loss: 240.8942, saving model.\n",
      "Epoch 813/1000\n",
      "Training Loss: 266.6350, Training Accuracy: 0.2902\n",
      "Validation Loss: 240.8904, Validation Accuracy: 0.3113\n",
      "New best validation loss: 240.8904, saving model.\n",
      "Epoch 814/1000\n",
      "Training Loss: 267.0415, Training Accuracy: 0.2893\n",
      "Validation Loss: 240.8866, Validation Accuracy: 0.3115\n",
      "New best validation loss: 240.8866, saving model.\n",
      "Epoch 815/1000\n",
      "Training Loss: 266.8103, Training Accuracy: 0.2911\n",
      "Validation Loss: 240.8827, Validation Accuracy: 0.3118\n",
      "New best validation loss: 240.8827, saving model.\n",
      "Epoch 816/1000\n",
      "Training Loss: 267.6923, Training Accuracy: 0.2920\n",
      "Validation Loss: 240.8789, Validation Accuracy: 0.3121\n",
      "New best validation loss: 240.8789, saving model.\n",
      "Epoch 817/1000\n",
      "Training Loss: 267.9115, Training Accuracy: 0.2893\n",
      "Validation Loss: 240.8751, Validation Accuracy: 0.3123\n",
      "New best validation loss: 240.8751, saving model.\n",
      "Epoch 818/1000\n",
      "Training Loss: 265.9683, Training Accuracy: 0.2917\n",
      "Validation Loss: 240.8712, Validation Accuracy: 0.3125\n",
      "New best validation loss: 240.8712, saving model.\n",
      "Epoch 819/1000\n",
      "Training Loss: 266.1217, Training Accuracy: 0.2916\n",
      "Validation Loss: 240.8674, Validation Accuracy: 0.3127\n",
      "New best validation loss: 240.8674, saving model.\n",
      "Epoch 820/1000\n",
      "Training Loss: 266.6184, Training Accuracy: 0.2903\n",
      "Validation Loss: 240.8635, Validation Accuracy: 0.3129\n",
      "New best validation loss: 240.8635, saving model.\n",
      "Epoch 821/1000\n",
      "Training Loss: 268.3976, Training Accuracy: 0.2923\n",
      "Validation Loss: 240.8595, Validation Accuracy: 0.3130\n",
      "New best validation loss: 240.8595, saving model.\n",
      "Epoch 822/1000\n",
      "Training Loss: 267.4914, Training Accuracy: 0.2897\n",
      "Validation Loss: 240.8556, Validation Accuracy: 0.3132\n",
      "New best validation loss: 240.8556, saving model.\n",
      "Epoch 823/1000\n",
      "Training Loss: 267.8338, Training Accuracy: 0.2890\n",
      "Validation Loss: 240.8517, Validation Accuracy: 0.3134\n",
      "New best validation loss: 240.8517, saving model.\n",
      "Epoch 824/1000\n",
      "Training Loss: 265.9278, Training Accuracy: 0.2934\n",
      "Validation Loss: 240.8478, Validation Accuracy: 0.3136\n",
      "New best validation loss: 240.8478, saving model.\n",
      "Epoch 825/1000\n",
      "Training Loss: 266.9524, Training Accuracy: 0.2908\n",
      "Validation Loss: 240.8438, Validation Accuracy: 0.3138\n",
      "New best validation loss: 240.8438, saving model.\n",
      "Epoch 826/1000\n",
      "Training Loss: 267.3285, Training Accuracy: 0.2912\n",
      "Validation Loss: 240.8399, Validation Accuracy: 0.3139\n",
      "New best validation loss: 240.8399, saving model.\n",
      "Epoch 827/1000\n",
      "Training Loss: 265.5732, Training Accuracy: 0.2940\n",
      "Validation Loss: 240.8358, Validation Accuracy: 0.3141\n",
      "New best validation loss: 240.8358, saving model.\n",
      "Epoch 828/1000\n",
      "Training Loss: 266.2391, Training Accuracy: 0.2947\n",
      "Validation Loss: 240.8318, Validation Accuracy: 0.3143\n",
      "New best validation loss: 240.8318, saving model.\n",
      "Epoch 829/1000\n",
      "Training Loss: 266.0616, Training Accuracy: 0.2923\n",
      "Validation Loss: 240.8279, Validation Accuracy: 0.3144\n",
      "New best validation loss: 240.8279, saving model.\n",
      "Epoch 830/1000\n",
      "Training Loss: 266.7655, Training Accuracy: 0.2902\n",
      "Validation Loss: 240.8239, Validation Accuracy: 0.3147\n",
      "New best validation loss: 240.8239, saving model.\n",
      "Epoch 831/1000\n",
      "Training Loss: 265.5980, Training Accuracy: 0.2915\n",
      "Validation Loss: 240.8199, Validation Accuracy: 0.3148\n",
      "New best validation loss: 240.8199, saving model.\n",
      "Epoch 832/1000\n",
      "Training Loss: 266.1590, Training Accuracy: 0.2916\n",
      "Validation Loss: 240.8159, Validation Accuracy: 0.3150\n",
      "New best validation loss: 240.8159, saving model.\n",
      "Epoch 833/1000\n",
      "Training Loss: 266.3691, Training Accuracy: 0.2927\n",
      "Validation Loss: 240.8119, Validation Accuracy: 0.3152\n",
      "New best validation loss: 240.8119, saving model.\n",
      "Epoch 834/1000\n",
      "Training Loss: 267.6868, Training Accuracy: 0.2916\n",
      "Validation Loss: 240.8078, Validation Accuracy: 0.3153\n",
      "New best validation loss: 240.8078, saving model.\n",
      "Epoch 835/1000\n",
      "Training Loss: 266.1730, Training Accuracy: 0.2929\n",
      "Validation Loss: 240.8038, Validation Accuracy: 0.3154\n",
      "New best validation loss: 240.8038, saving model.\n",
      "Epoch 836/1000\n",
      "Training Loss: 266.6919, Training Accuracy: 0.2929\n",
      "Validation Loss: 240.7997, Validation Accuracy: 0.3156\n",
      "New best validation loss: 240.7997, saving model.\n",
      "Epoch 837/1000\n",
      "Training Loss: 268.0073, Training Accuracy: 0.2956\n",
      "Validation Loss: 240.7955, Validation Accuracy: 0.3157\n",
      "New best validation loss: 240.7955, saving model.\n",
      "Epoch 838/1000\n",
      "Training Loss: 266.1091, Training Accuracy: 0.2941\n",
      "Validation Loss: 240.7915, Validation Accuracy: 0.3158\n",
      "New best validation loss: 240.7915, saving model.\n",
      "Epoch 839/1000\n",
      "Training Loss: 267.0005, Training Accuracy: 0.2930\n",
      "Validation Loss: 240.7874, Validation Accuracy: 0.3160\n",
      "New best validation loss: 240.7874, saving model.\n",
      "Epoch 840/1000\n",
      "Training Loss: 265.6415, Training Accuracy: 0.2946\n",
      "Validation Loss: 240.7834, Validation Accuracy: 0.3160\n",
      "New best validation loss: 240.7834, saving model.\n",
      "Epoch 841/1000\n",
      "Training Loss: 265.7617, Training Accuracy: 0.2932\n",
      "Validation Loss: 240.7792, Validation Accuracy: 0.3162\n",
      "New best validation loss: 240.7792, saving model.\n",
      "Epoch 842/1000\n",
      "Training Loss: 265.6836, Training Accuracy: 0.2946\n",
      "Validation Loss: 240.7751, Validation Accuracy: 0.3164\n",
      "New best validation loss: 240.7751, saving model.\n",
      "Epoch 843/1000\n",
      "Training Loss: 266.7026, Training Accuracy: 0.2951\n",
      "Validation Loss: 240.7710, Validation Accuracy: 0.3166\n",
      "New best validation loss: 240.7710, saving model.\n",
      "Epoch 844/1000\n",
      "Training Loss: 269.0594, Training Accuracy: 0.2935\n",
      "Validation Loss: 240.7668, Validation Accuracy: 0.3167\n",
      "New best validation loss: 240.7668, saving model.\n",
      "Epoch 845/1000\n",
      "Training Loss: 265.2451, Training Accuracy: 0.2957\n",
      "Validation Loss: 240.7626, Validation Accuracy: 0.3169\n",
      "New best validation loss: 240.7626, saving model.\n",
      "Epoch 846/1000\n",
      "Training Loss: 266.4333, Training Accuracy: 0.2931\n",
      "Validation Loss: 240.7584, Validation Accuracy: 0.3170\n",
      "New best validation loss: 240.7584, saving model.\n",
      "Epoch 847/1000\n",
      "Training Loss: 265.4348, Training Accuracy: 0.2955\n",
      "Validation Loss: 240.7542, Validation Accuracy: 0.3172\n",
      "New best validation loss: 240.7542, saving model.\n",
      "Epoch 848/1000\n",
      "Training Loss: 265.5834, Training Accuracy: 0.2957\n",
      "Validation Loss: 240.7500, Validation Accuracy: 0.3174\n",
      "New best validation loss: 240.7500, saving model.\n",
      "Epoch 849/1000\n",
      "Training Loss: 266.6480, Training Accuracy: 0.2973\n",
      "Validation Loss: 240.7457, Validation Accuracy: 0.3175\n",
      "New best validation loss: 240.7457, saving model.\n",
      "Epoch 850/1000\n",
      "Training Loss: 265.9386, Training Accuracy: 0.2968\n",
      "Validation Loss: 240.7415, Validation Accuracy: 0.3176\n",
      "New best validation loss: 240.7415, saving model.\n",
      "Epoch 851/1000\n",
      "Training Loss: 265.1382, Training Accuracy: 0.2963\n",
      "Validation Loss: 240.7372, Validation Accuracy: 0.3176\n",
      "New best validation loss: 240.7372, saving model.\n",
      "Epoch 852/1000\n",
      "Training Loss: 265.5987, Training Accuracy: 0.2960\n",
      "Validation Loss: 240.7329, Validation Accuracy: 0.3179\n",
      "New best validation loss: 240.7329, saving model.\n",
      "Epoch 853/1000\n",
      "Training Loss: 265.2821, Training Accuracy: 0.2973\n",
      "Validation Loss: 240.7286, Validation Accuracy: 0.3181\n",
      "New best validation loss: 240.7286, saving model.\n",
      "Epoch 854/1000\n",
      "Training Loss: 266.3299, Training Accuracy: 0.2966\n",
      "Validation Loss: 240.7244, Validation Accuracy: 0.3183\n",
      "New best validation loss: 240.7244, saving model.\n",
      "Epoch 855/1000\n",
      "Training Loss: 265.5368, Training Accuracy: 0.2971\n",
      "Validation Loss: 240.7201, Validation Accuracy: 0.3184\n",
      "New best validation loss: 240.7201, saving model.\n",
      "Epoch 856/1000\n",
      "Training Loss: 266.7307, Training Accuracy: 0.2944\n",
      "Validation Loss: 240.7157, Validation Accuracy: 0.3185\n",
      "New best validation loss: 240.7157, saving model.\n",
      "Epoch 857/1000\n",
      "Training Loss: 266.1466, Training Accuracy: 0.2981\n",
      "Validation Loss: 240.7114, Validation Accuracy: 0.3186\n",
      "New best validation loss: 240.7114, saving model.\n",
      "Epoch 858/1000\n",
      "Training Loss: 265.7196, Training Accuracy: 0.2963\n",
      "Validation Loss: 240.7071, Validation Accuracy: 0.3187\n",
      "New best validation loss: 240.7071, saving model.\n",
      "Epoch 859/1000\n",
      "Training Loss: 266.9302, Training Accuracy: 0.2953\n",
      "Validation Loss: 240.7027, Validation Accuracy: 0.3189\n",
      "New best validation loss: 240.7027, saving model.\n",
      "Epoch 860/1000\n",
      "Training Loss: 266.0520, Training Accuracy: 0.2965\n",
      "Validation Loss: 240.6984, Validation Accuracy: 0.3189\n",
      "New best validation loss: 240.6984, saving model.\n",
      "Epoch 861/1000\n",
      "Training Loss: 265.7553, Training Accuracy: 0.2982\n",
      "Validation Loss: 240.6940, Validation Accuracy: 0.3191\n",
      "New best validation loss: 240.6940, saving model.\n",
      "Epoch 862/1000\n",
      "Training Loss: 265.5255, Training Accuracy: 0.2985\n",
      "Validation Loss: 240.6896, Validation Accuracy: 0.3191\n",
      "New best validation loss: 240.6896, saving model.\n",
      "Epoch 863/1000\n",
      "Training Loss: 265.7359, Training Accuracy: 0.2982\n",
      "Validation Loss: 240.6852, Validation Accuracy: 0.3192\n",
      "New best validation loss: 240.6852, saving model.\n",
      "Epoch 864/1000\n",
      "Training Loss: 266.7460, Training Accuracy: 0.2960\n",
      "Validation Loss: 240.6810, Validation Accuracy: 0.3193\n",
      "New best validation loss: 240.6810, saving model.\n",
      "Epoch 865/1000\n",
      "Training Loss: 265.7651, Training Accuracy: 0.2956\n",
      "Validation Loss: 240.6765, Validation Accuracy: 0.3194\n",
      "New best validation loss: 240.6765, saving model.\n",
      "Epoch 866/1000\n",
      "Training Loss: 267.9893, Training Accuracy: 0.2962\n",
      "Validation Loss: 240.6721, Validation Accuracy: 0.3196\n",
      "New best validation loss: 240.6721, saving model.\n",
      "Epoch 867/1000\n",
      "Training Loss: 265.8152, Training Accuracy: 0.2970\n",
      "Validation Loss: 240.6677, Validation Accuracy: 0.3196\n",
      "New best validation loss: 240.6677, saving model.\n",
      "Epoch 868/1000\n",
      "Training Loss: 268.6241, Training Accuracy: 0.2967\n",
      "Validation Loss: 240.6632, Validation Accuracy: 0.3197\n",
      "New best validation loss: 240.6632, saving model.\n",
      "Epoch 869/1000\n",
      "Training Loss: 265.1863, Training Accuracy: 0.3002\n",
      "Validation Loss: 240.6587, Validation Accuracy: 0.3199\n",
      "New best validation loss: 240.6587, saving model.\n",
      "Epoch 870/1000\n",
      "Training Loss: 266.3467, Training Accuracy: 0.2973\n",
      "Validation Loss: 240.6543, Validation Accuracy: 0.3200\n",
      "New best validation loss: 240.6543, saving model.\n",
      "Epoch 871/1000\n",
      "Training Loss: 266.4177, Training Accuracy: 0.2981\n",
      "Validation Loss: 240.6498, Validation Accuracy: 0.3202\n",
      "New best validation loss: 240.6498, saving model.\n",
      "Epoch 872/1000\n",
      "Training Loss: 268.2718, Training Accuracy: 0.2964\n",
      "Validation Loss: 240.6454, Validation Accuracy: 0.3203\n",
      "New best validation loss: 240.6454, saving model.\n",
      "Epoch 873/1000\n",
      "Training Loss: 265.4779, Training Accuracy: 0.2985\n",
      "Validation Loss: 240.6409, Validation Accuracy: 0.3204\n",
      "New best validation loss: 240.6409, saving model.\n",
      "Epoch 874/1000\n",
      "Training Loss: 265.2002, Training Accuracy: 0.2978\n",
      "Validation Loss: 240.6364, Validation Accuracy: 0.3206\n",
      "New best validation loss: 240.6364, saving model.\n",
      "Epoch 875/1000\n",
      "Training Loss: 266.4076, Training Accuracy: 0.2993\n",
      "Validation Loss: 240.6319, Validation Accuracy: 0.3206\n",
      "New best validation loss: 240.6319, saving model.\n",
      "Epoch 876/1000\n",
      "Training Loss: 267.1046, Training Accuracy: 0.2973\n",
      "Validation Loss: 240.6273, Validation Accuracy: 0.3206\n",
      "New best validation loss: 240.6273, saving model.\n",
      "Epoch 877/1000\n",
      "Training Loss: 267.8776, Training Accuracy: 0.2982\n",
      "Validation Loss: 240.6227, Validation Accuracy: 0.3208\n",
      "New best validation loss: 240.6227, saving model.\n",
      "Epoch 878/1000\n",
      "Training Loss: 266.4471, Training Accuracy: 0.2978\n",
      "Validation Loss: 240.6182, Validation Accuracy: 0.3209\n",
      "New best validation loss: 240.6182, saving model.\n",
      "Epoch 879/1000\n",
      "Training Loss: 267.1403, Training Accuracy: 0.2972\n",
      "Validation Loss: 240.6136, Validation Accuracy: 0.3210\n",
      "New best validation loss: 240.6136, saving model.\n",
      "Epoch 880/1000\n",
      "Training Loss: 265.9236, Training Accuracy: 0.2987\n",
      "Validation Loss: 240.6090, Validation Accuracy: 0.3211\n",
      "New best validation loss: 240.6090, saving model.\n",
      "Epoch 881/1000\n",
      "Training Loss: 265.6952, Training Accuracy: 0.2989\n",
      "Validation Loss: 240.6044, Validation Accuracy: 0.3212\n",
      "New best validation loss: 240.6044, saving model.\n",
      "Epoch 882/1000\n",
      "Training Loss: 266.9089, Training Accuracy: 0.2974\n",
      "Validation Loss: 240.5999, Validation Accuracy: 0.3213\n",
      "New best validation loss: 240.5999, saving model.\n",
      "Epoch 883/1000\n",
      "Training Loss: 266.1840, Training Accuracy: 0.2976\n",
      "Validation Loss: 240.5952, Validation Accuracy: 0.3214\n",
      "New best validation loss: 240.5952, saving model.\n",
      "Epoch 884/1000\n",
      "Training Loss: 265.4448, Training Accuracy: 0.2995\n",
      "Validation Loss: 240.5905, Validation Accuracy: 0.3214\n",
      "New best validation loss: 240.5905, saving model.\n",
      "Epoch 885/1000\n",
      "Training Loss: 266.4885, Training Accuracy: 0.2983\n",
      "Validation Loss: 240.5858, Validation Accuracy: 0.3217\n",
      "New best validation loss: 240.5858, saving model.\n",
      "Epoch 886/1000\n",
      "Training Loss: 265.1533, Training Accuracy: 0.3010\n",
      "Validation Loss: 240.5811, Validation Accuracy: 0.3218\n",
      "New best validation loss: 240.5811, saving model.\n",
      "Epoch 887/1000\n",
      "Training Loss: 266.7445, Training Accuracy: 0.2980\n",
      "Validation Loss: 240.5764, Validation Accuracy: 0.3219\n",
      "New best validation loss: 240.5764, saving model.\n",
      "Epoch 888/1000\n",
      "Training Loss: 266.0584, Training Accuracy: 0.2998\n",
      "Validation Loss: 240.5718, Validation Accuracy: 0.3219\n",
      "New best validation loss: 240.5718, saving model.\n",
      "Epoch 889/1000\n",
      "Training Loss: 265.7890, Training Accuracy: 0.2989\n",
      "Validation Loss: 240.5670, Validation Accuracy: 0.3220\n",
      "New best validation loss: 240.5670, saving model.\n",
      "Epoch 890/1000\n",
      "Training Loss: 266.7498, Training Accuracy: 0.3016\n",
      "Validation Loss: 240.5623, Validation Accuracy: 0.3221\n",
      "New best validation loss: 240.5623, saving model.\n",
      "Epoch 891/1000\n",
      "Training Loss: 265.7520, Training Accuracy: 0.3001\n",
      "Validation Loss: 240.5576, Validation Accuracy: 0.3222\n",
      "New best validation loss: 240.5576, saving model.\n",
      "Epoch 892/1000\n",
      "Training Loss: 265.5703, Training Accuracy: 0.2994\n",
      "Validation Loss: 240.5528, Validation Accuracy: 0.3222\n",
      "New best validation loss: 240.5528, saving model.\n",
      "Epoch 893/1000\n",
      "Training Loss: 266.3561, Training Accuracy: 0.2979\n",
      "Validation Loss: 240.5482, Validation Accuracy: 0.3223\n",
      "New best validation loss: 240.5482, saving model.\n",
      "Epoch 894/1000\n",
      "Training Loss: 266.1783, Training Accuracy: 0.2979\n",
      "Validation Loss: 240.5434, Validation Accuracy: 0.3223\n",
      "New best validation loss: 240.5434, saving model.\n",
      "Epoch 895/1000\n",
      "Training Loss: 265.7305, Training Accuracy: 0.2991\n",
      "Validation Loss: 240.5386, Validation Accuracy: 0.3224\n",
      "New best validation loss: 240.5386, saving model.\n",
      "Epoch 896/1000\n",
      "Training Loss: 265.6095, Training Accuracy: 0.2999\n",
      "Validation Loss: 240.5338, Validation Accuracy: 0.3226\n",
      "New best validation loss: 240.5338, saving model.\n",
      "Epoch 897/1000\n",
      "Training Loss: 265.1467, Training Accuracy: 0.3017\n",
      "Validation Loss: 240.5289, Validation Accuracy: 0.3227\n",
      "New best validation loss: 240.5289, saving model.\n",
      "Epoch 898/1000\n",
      "Training Loss: 266.5993, Training Accuracy: 0.3008\n",
      "Validation Loss: 240.5242, Validation Accuracy: 0.3227\n",
      "New best validation loss: 240.5242, saving model.\n",
      "Epoch 899/1000\n",
      "Training Loss: 267.0688, Training Accuracy: 0.2991\n",
      "Validation Loss: 240.5194, Validation Accuracy: 0.3227\n",
      "New best validation loss: 240.5194, saving model.\n",
      "Epoch 900/1000\n",
      "Training Loss: 266.8119, Training Accuracy: 0.2996\n",
      "Validation Loss: 240.5146, Validation Accuracy: 0.3228\n",
      "New best validation loss: 240.5146, saving model.\n",
      "Epoch 901/1000\n",
      "Training Loss: 265.7227, Training Accuracy: 0.3008\n",
      "Validation Loss: 240.5097, Validation Accuracy: 0.3229\n",
      "New best validation loss: 240.5097, saving model.\n",
      "Epoch 902/1000\n",
      "Training Loss: 267.7452, Training Accuracy: 0.2988\n",
      "Validation Loss: 240.5049, Validation Accuracy: 0.3229\n",
      "New best validation loss: 240.5049, saving model.\n",
      "Epoch 903/1000\n",
      "Training Loss: 265.9472, Training Accuracy: 0.3005\n",
      "Validation Loss: 240.5001, Validation Accuracy: 0.3230\n",
      "New best validation loss: 240.5001, saving model.\n",
      "Epoch 904/1000\n",
      "Training Loss: 266.5951, Training Accuracy: 0.2982\n",
      "Validation Loss: 240.4952, Validation Accuracy: 0.3230\n",
      "New best validation loss: 240.4952, saving model.\n",
      "Epoch 905/1000\n",
      "Training Loss: 265.3446, Training Accuracy: 0.3012\n",
      "Validation Loss: 240.4903, Validation Accuracy: 0.3231\n",
      "New best validation loss: 240.4903, saving model.\n",
      "Epoch 906/1000\n",
      "Training Loss: 265.1208, Training Accuracy: 0.3006\n",
      "Validation Loss: 240.4854, Validation Accuracy: 0.3232\n",
      "New best validation loss: 240.4854, saving model.\n",
      "Epoch 907/1000\n",
      "Training Loss: 265.7491, Training Accuracy: 0.2987\n",
      "Validation Loss: 240.4805, Validation Accuracy: 0.3233\n",
      "New best validation loss: 240.4805, saving model.\n",
      "Epoch 908/1000\n",
      "Training Loss: 266.1260, Training Accuracy: 0.3010\n",
      "Validation Loss: 240.4755, Validation Accuracy: 0.3233\n",
      "New best validation loss: 240.4755, saving model.\n",
      "Epoch 909/1000\n",
      "Training Loss: 265.3607, Training Accuracy: 0.3015\n",
      "Validation Loss: 240.4706, Validation Accuracy: 0.3234\n",
      "New best validation loss: 240.4706, saving model.\n",
      "Epoch 910/1000\n",
      "Training Loss: 265.7898, Training Accuracy: 0.2998\n",
      "Validation Loss: 240.4655, Validation Accuracy: 0.3235\n",
      "New best validation loss: 240.4655, saving model.\n",
      "Epoch 911/1000\n",
      "Training Loss: 266.2471, Training Accuracy: 0.2999\n",
      "Validation Loss: 240.4606, Validation Accuracy: 0.3235\n",
      "New best validation loss: 240.4606, saving model.\n",
      "Epoch 912/1000\n",
      "Training Loss: 266.3560, Training Accuracy: 0.3011\n",
      "Validation Loss: 240.4556, Validation Accuracy: 0.3235\n",
      "New best validation loss: 240.4556, saving model.\n",
      "Epoch 913/1000\n",
      "Training Loss: 266.1958, Training Accuracy: 0.2984\n",
      "Validation Loss: 240.4506, Validation Accuracy: 0.3236\n",
      "New best validation loss: 240.4506, saving model.\n",
      "Epoch 914/1000\n",
      "Training Loss: 266.5713, Training Accuracy: 0.3006\n",
      "Validation Loss: 240.4455, Validation Accuracy: 0.3237\n",
      "New best validation loss: 240.4455, saving model.\n",
      "Epoch 915/1000\n",
      "Training Loss: 265.4263, Training Accuracy: 0.3013\n",
      "Validation Loss: 240.4404, Validation Accuracy: 0.3237\n",
      "New best validation loss: 240.4404, saving model.\n",
      "Epoch 916/1000\n",
      "Training Loss: 264.8491, Training Accuracy: 0.3037\n",
      "Validation Loss: 240.4354, Validation Accuracy: 0.3237\n",
      "New best validation loss: 240.4354, saving model.\n",
      "Epoch 917/1000\n",
      "Training Loss: 265.5793, Training Accuracy: 0.3002\n",
      "Validation Loss: 240.4303, Validation Accuracy: 0.3238\n",
      "New best validation loss: 240.4303, saving model.\n",
      "Epoch 918/1000\n",
      "Training Loss: 266.2799, Training Accuracy: 0.3016\n",
      "Validation Loss: 240.4253, Validation Accuracy: 0.3237\n",
      "New best validation loss: 240.4253, saving model.\n",
      "Epoch 919/1000\n",
      "Training Loss: 268.4908, Training Accuracy: 0.2982\n",
      "Validation Loss: 240.4202, Validation Accuracy: 0.3238\n",
      "New best validation loss: 240.4202, saving model.\n",
      "Epoch 920/1000\n",
      "Training Loss: 265.8143, Training Accuracy: 0.3006\n",
      "Validation Loss: 240.4151, Validation Accuracy: 0.3238\n",
      "New best validation loss: 240.4151, saving model.\n",
      "Epoch 921/1000\n",
      "Training Loss: 266.1852, Training Accuracy: 0.3019\n",
      "Validation Loss: 240.4099, Validation Accuracy: 0.3238\n",
      "New best validation loss: 240.4099, saving model.\n",
      "Epoch 922/1000\n",
      "Training Loss: 268.0976, Training Accuracy: 0.3006\n",
      "Validation Loss: 240.4047, Validation Accuracy: 0.3240\n",
      "New best validation loss: 240.4047, saving model.\n",
      "Epoch 923/1000\n",
      "Training Loss: 265.1899, Training Accuracy: 0.3025\n",
      "Validation Loss: 240.3996, Validation Accuracy: 0.3239\n",
      "New best validation loss: 240.3996, saving model.\n",
      "Epoch 924/1000\n",
      "Training Loss: 265.5793, Training Accuracy: 0.3009\n",
      "Validation Loss: 240.3945, Validation Accuracy: 0.3239\n",
      "New best validation loss: 240.3945, saving model.\n",
      "Epoch 925/1000\n",
      "Training Loss: 265.8983, Training Accuracy: 0.2993\n",
      "Validation Loss: 240.3893, Validation Accuracy: 0.3240\n",
      "New best validation loss: 240.3893, saving model.\n",
      "Epoch 926/1000\n",
      "Training Loss: 266.1910, Training Accuracy: 0.3017\n",
      "Validation Loss: 240.3841, Validation Accuracy: 0.3241\n",
      "New best validation loss: 240.3841, saving model.\n",
      "Epoch 927/1000\n",
      "Training Loss: 267.7104, Training Accuracy: 0.3010\n",
      "Validation Loss: 240.3788, Validation Accuracy: 0.3240\n",
      "New best validation loss: 240.3788, saving model.\n",
      "Epoch 928/1000\n",
      "Training Loss: 265.3602, Training Accuracy: 0.3022\n",
      "Validation Loss: 240.3737, Validation Accuracy: 0.3241\n",
      "New best validation loss: 240.3737, saving model.\n",
      "Epoch 929/1000\n",
      "Training Loss: 265.7051, Training Accuracy: 0.3021\n",
      "Validation Loss: 240.3685, Validation Accuracy: 0.3240\n",
      "New best validation loss: 240.3685, saving model.\n",
      "Epoch 930/1000\n",
      "Training Loss: 267.9592, Training Accuracy: 0.3002\n",
      "Validation Loss: 240.3631, Validation Accuracy: 0.3241\n",
      "New best validation loss: 240.3631, saving model.\n",
      "Epoch 931/1000\n",
      "Training Loss: 266.0629, Training Accuracy: 0.3010\n",
      "Validation Loss: 240.3579, Validation Accuracy: 0.3242\n",
      "New best validation loss: 240.3579, saving model.\n",
      "Epoch 932/1000\n",
      "Training Loss: 265.5235, Training Accuracy: 0.3019\n",
      "Validation Loss: 240.3526, Validation Accuracy: 0.3242\n",
      "New best validation loss: 240.3526, saving model.\n",
      "Epoch 933/1000\n",
      "Training Loss: 266.6689, Training Accuracy: 0.3012\n",
      "Validation Loss: 240.3473, Validation Accuracy: 0.3241\n",
      "New best validation loss: 240.3473, saving model.\n",
      "Epoch 934/1000\n",
      "Training Loss: 264.9661, Training Accuracy: 0.3028\n",
      "Validation Loss: 240.3420, Validation Accuracy: 0.3242\n",
      "New best validation loss: 240.3420, saving model.\n",
      "Epoch 935/1000\n",
      "Training Loss: 266.8754, Training Accuracy: 0.3004\n",
      "Validation Loss: 240.3368, Validation Accuracy: 0.3242\n",
      "New best validation loss: 240.3368, saving model.\n",
      "Epoch 936/1000\n",
      "Training Loss: 265.9684, Training Accuracy: 0.3005\n",
      "Validation Loss: 240.3315, Validation Accuracy: 0.3242\n",
      "New best validation loss: 240.3315, saving model.\n",
      "Epoch 937/1000\n",
      "Training Loss: 264.9562, Training Accuracy: 0.3012\n",
      "Validation Loss: 240.3260, Validation Accuracy: 0.3242\n",
      "New best validation loss: 240.3260, saving model.\n",
      "Epoch 938/1000\n",
      "Training Loss: 266.8211, Training Accuracy: 0.3006\n",
      "Validation Loss: 240.3207, Validation Accuracy: 0.3244\n",
      "New best validation loss: 240.3207, saving model.\n",
      "Epoch 939/1000\n",
      "Training Loss: 265.8391, Training Accuracy: 0.3017\n",
      "Validation Loss: 240.3153, Validation Accuracy: 0.3244\n",
      "New best validation loss: 240.3153, saving model.\n",
      "Epoch 940/1000\n",
      "Training Loss: 265.9829, Training Accuracy: 0.3009\n",
      "Validation Loss: 240.3099, Validation Accuracy: 0.3244\n",
      "New best validation loss: 240.3099, saving model.\n",
      "Epoch 941/1000\n",
      "Training Loss: 266.4497, Training Accuracy: 0.3003\n",
      "Validation Loss: 240.3045, Validation Accuracy: 0.3245\n",
      "New best validation loss: 240.3045, saving model.\n",
      "Epoch 942/1000\n",
      "Training Loss: 266.4948, Training Accuracy: 0.3018\n",
      "Validation Loss: 240.2992, Validation Accuracy: 0.3244\n",
      "New best validation loss: 240.2992, saving model.\n",
      "Epoch 943/1000\n",
      "Training Loss: 265.4489, Training Accuracy: 0.3021\n",
      "Validation Loss: 240.2938, Validation Accuracy: 0.3245\n",
      "New best validation loss: 240.2938, saving model.\n",
      "Epoch 944/1000\n",
      "Training Loss: 266.0206, Training Accuracy: 0.3029\n",
      "Validation Loss: 240.2882, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.2882, saving model.\n",
      "Epoch 945/1000\n",
      "Training Loss: 265.2376, Training Accuracy: 0.3018\n",
      "Validation Loss: 240.2829, Validation Accuracy: 0.3245\n",
      "New best validation loss: 240.2829, saving model.\n",
      "Epoch 946/1000\n",
      "Training Loss: 266.9508, Training Accuracy: 0.2999\n",
      "Validation Loss: 240.2774, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.2774, saving model.\n",
      "Epoch 947/1000\n",
      "Training Loss: 266.6123, Training Accuracy: 0.3009\n",
      "Validation Loss: 240.2720, Validation Accuracy: 0.3245\n",
      "New best validation loss: 240.2720, saving model.\n",
      "Epoch 948/1000\n",
      "Training Loss: 266.2384, Training Accuracy: 0.3003\n",
      "Validation Loss: 240.2665, Validation Accuracy: 0.3245\n",
      "New best validation loss: 240.2665, saving model.\n",
      "Epoch 949/1000\n",
      "Training Loss: 265.1757, Training Accuracy: 0.3016\n",
      "Validation Loss: 240.2611, Validation Accuracy: 0.3245\n",
      "New best validation loss: 240.2611, saving model.\n",
      "Epoch 950/1000\n",
      "Training Loss: 266.6999, Training Accuracy: 0.2998\n",
      "Validation Loss: 240.2556, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.2556, saving model.\n",
      "Epoch 951/1000\n",
      "Training Loss: 266.5707, Training Accuracy: 0.3011\n",
      "Validation Loss: 240.2499, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.2499, saving model.\n",
      "Epoch 952/1000\n",
      "Training Loss: 264.9292, Training Accuracy: 0.3019\n",
      "Validation Loss: 240.2443, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.2443, saving model.\n",
      "Epoch 953/1000\n",
      "Training Loss: 266.4098, Training Accuracy: 0.3004\n",
      "Validation Loss: 240.2389, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.2389, saving model.\n",
      "Epoch 954/1000\n",
      "Training Loss: 265.9045, Training Accuracy: 0.3003\n",
      "Validation Loss: 240.2333, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.2333, saving model.\n",
      "Epoch 955/1000\n",
      "Training Loss: 265.3464, Training Accuracy: 0.3010\n",
      "Validation Loss: 240.2278, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.2278, saving model.\n",
      "Epoch 956/1000\n",
      "Training Loss: 266.0587, Training Accuracy: 0.3013\n",
      "Validation Loss: 240.2221, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.2221, saving model.\n",
      "Epoch 957/1000\n",
      "Training Loss: 265.2242, Training Accuracy: 0.3018\n",
      "Validation Loss: 240.2166, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.2166, saving model.\n",
      "Epoch 958/1000\n",
      "Training Loss: 265.7143, Training Accuracy: 0.3018\n",
      "Validation Loss: 240.2109, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.2109, saving model.\n",
      "Epoch 959/1000\n",
      "Training Loss: 265.1327, Training Accuracy: 0.3019\n",
      "Validation Loss: 240.2052, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.2052, saving model.\n",
      "Epoch 960/1000\n",
      "Training Loss: 265.4200, Training Accuracy: 0.3017\n",
      "Validation Loss: 240.1996, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1996, saving model.\n",
      "Epoch 961/1000\n",
      "Training Loss: 264.8451, Training Accuracy: 0.3005\n",
      "Validation Loss: 240.1939, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1939, saving model.\n",
      "Epoch 962/1000\n",
      "Training Loss: 265.1942, Training Accuracy: 0.3016\n",
      "Validation Loss: 240.1883, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1883, saving model.\n",
      "Epoch 963/1000\n",
      "Training Loss: 265.7966, Training Accuracy: 0.3032\n",
      "Validation Loss: 240.1825, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1825, saving model.\n",
      "Epoch 964/1000\n",
      "Training Loss: 265.3026, Training Accuracy: 0.3022\n",
      "Validation Loss: 240.1769, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.1769, saving model.\n",
      "Epoch 965/1000\n",
      "Training Loss: 266.1363, Training Accuracy: 0.3001\n",
      "Validation Loss: 240.1712, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.1712, saving model.\n",
      "Epoch 966/1000\n",
      "Training Loss: 266.8142, Training Accuracy: 0.3022\n",
      "Validation Loss: 240.1653, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1653, saving model.\n",
      "Epoch 967/1000\n",
      "Training Loss: 265.7762, Training Accuracy: 0.3027\n",
      "Validation Loss: 240.1596, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1596, saving model.\n",
      "Epoch 968/1000\n",
      "Training Loss: 266.5043, Training Accuracy: 0.3027\n",
      "Validation Loss: 240.1538, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1538, saving model.\n",
      "Epoch 969/1000\n",
      "Training Loss: 265.5461, Training Accuracy: 0.3014\n",
      "Validation Loss: 240.1480, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1480, saving model.\n",
      "Epoch 970/1000\n",
      "Training Loss: 265.0974, Training Accuracy: 0.3017\n",
      "Validation Loss: 240.1422, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.1422, saving model.\n",
      "Epoch 971/1000\n",
      "Training Loss: 267.9189, Training Accuracy: 0.3007\n",
      "Validation Loss: 240.1363, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.1363, saving model.\n",
      "Epoch 972/1000\n",
      "Training Loss: 268.4507, Training Accuracy: 0.2994\n",
      "Validation Loss: 240.1306, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1306, saving model.\n",
      "Epoch 973/1000\n",
      "Training Loss: 266.7563, Training Accuracy: 0.2996\n",
      "Validation Loss: 240.1248, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.1248, saving model.\n",
      "Epoch 974/1000\n",
      "Training Loss: 267.5048, Training Accuracy: 0.3018\n",
      "Validation Loss: 240.1189, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1189, saving model.\n",
      "Epoch 975/1000\n",
      "Training Loss: 265.2903, Training Accuracy: 0.3014\n",
      "Validation Loss: 240.1130, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.1130, saving model.\n",
      "Epoch 976/1000\n",
      "Training Loss: 266.6271, Training Accuracy: 0.3011\n",
      "Validation Loss: 240.1070, Validation Accuracy: 0.3250\n",
      "New best validation loss: 240.1070, saving model.\n",
      "Epoch 977/1000\n",
      "Training Loss: 265.2179, Training Accuracy: 0.3033\n",
      "Validation Loss: 240.1013, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.1013, saving model.\n",
      "Epoch 978/1000\n",
      "Training Loss: 266.0282, Training Accuracy: 0.3034\n",
      "Validation Loss: 240.0953, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.0953, saving model.\n",
      "Epoch 979/1000\n",
      "Training Loss: 266.5010, Training Accuracy: 0.3019\n",
      "Validation Loss: 240.0894, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.0894, saving model.\n",
      "Epoch 980/1000\n",
      "Training Loss: 265.4035, Training Accuracy: 0.3017\n",
      "Validation Loss: 240.0835, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.0835, saving model.\n",
      "Epoch 981/1000\n",
      "Training Loss: 264.9049, Training Accuracy: 0.3044\n",
      "Validation Loss: 240.0775, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.0775, saving model.\n",
      "Epoch 982/1000\n",
      "Training Loss: 265.8273, Training Accuracy: 0.2993\n",
      "Validation Loss: 240.0716, Validation Accuracy: 0.3250\n",
      "New best validation loss: 240.0716, saving model.\n",
      "Epoch 983/1000\n",
      "Training Loss: 264.9522, Training Accuracy: 0.3012\n",
      "Validation Loss: 240.0656, Validation Accuracy: 0.3250\n",
      "New best validation loss: 240.0656, saving model.\n",
      "Epoch 984/1000\n",
      "Training Loss: 266.2433, Training Accuracy: 0.3022\n",
      "Validation Loss: 240.0597, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.0597, saving model.\n",
      "Epoch 985/1000\n",
      "Training Loss: 265.1950, Training Accuracy: 0.3029\n",
      "Validation Loss: 240.0537, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.0537, saving model.\n",
      "Epoch 986/1000\n",
      "Training Loss: 264.4342, Training Accuracy: 0.3055\n",
      "Validation Loss: 240.0476, Validation Accuracy: 0.3250\n",
      "New best validation loss: 240.0476, saving model.\n",
      "Epoch 987/1000\n",
      "Training Loss: 264.7096, Training Accuracy: 0.3018\n",
      "Validation Loss: 240.0416, Validation Accuracy: 0.3249\n",
      "New best validation loss: 240.0416, saving model.\n",
      "Epoch 988/1000\n",
      "Training Loss: 265.4246, Training Accuracy: 0.3035\n",
      "Validation Loss: 240.0356, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.0356, saving model.\n",
      "Epoch 989/1000\n",
      "Training Loss: 266.2289, Training Accuracy: 0.3011\n",
      "Validation Loss: 240.0296, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.0296, saving model.\n",
      "Epoch 990/1000\n",
      "Training Loss: 265.3951, Training Accuracy: 0.3041\n",
      "Validation Loss: 240.0234, Validation Accuracy: 0.3248\n",
      "New best validation loss: 240.0234, saving model.\n",
      "Epoch 991/1000\n",
      "Training Loss: 266.5749, Training Accuracy: 0.3015\n",
      "Validation Loss: 240.0174, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.0174, saving model.\n",
      "Epoch 992/1000\n",
      "Training Loss: 266.3493, Training Accuracy: 0.3015\n",
      "Validation Loss: 240.0111, Validation Accuracy: 0.3247\n",
      "New best validation loss: 240.0111, saving model.\n",
      "Epoch 993/1000\n",
      "Training Loss: 264.9829, Training Accuracy: 0.3019\n",
      "Validation Loss: 240.0050, Validation Accuracy: 0.3246\n",
      "New best validation loss: 240.0050, saving model.\n",
      "Epoch 994/1000\n",
      "Training Loss: 268.1963, Training Accuracy: 0.3021\n",
      "Validation Loss: 239.9988, Validation Accuracy: 0.3247\n",
      "New best validation loss: 239.9988, saving model.\n",
      "Epoch 995/1000\n",
      "Training Loss: 265.2407, Training Accuracy: 0.3023\n",
      "Validation Loss: 239.9926, Validation Accuracy: 0.3247\n",
      "New best validation loss: 239.9926, saving model.\n",
      "Epoch 996/1000\n",
      "Training Loss: 268.6538, Training Accuracy: 0.3015\n",
      "Validation Loss: 239.9864, Validation Accuracy: 0.3247\n",
      "New best validation loss: 239.9864, saving model.\n",
      "Epoch 997/1000\n",
      "Training Loss: 265.7221, Training Accuracy: 0.3027\n",
      "Validation Loss: 239.9802, Validation Accuracy: 0.3247\n",
      "New best validation loss: 239.9802, saving model.\n",
      "Epoch 998/1000\n",
      "Training Loss: 264.9218, Training Accuracy: 0.3030\n",
      "Validation Loss: 239.9740, Validation Accuracy: 0.3247\n",
      "New best validation loss: 239.9740, saving model.\n",
      "Epoch 999/1000\n",
      "Training Loss: 264.9402, Training Accuracy: 0.3017\n",
      "Validation Loss: 239.9677, Validation Accuracy: 0.3247\n",
      "New best validation loss: 239.9677, saving model.\n",
      "Epoch 1000/1000\n",
      "Training Loss: 266.4190, Training Accuracy: 0.3034\n",
      "Validation Loss: 239.9613, Validation Accuracy: 0.3247\n",
      "New best validation loss: 239.9613, saving model.\n"
     ]
    }
   ],
   "source": [
    "# Define patience for early stopping and the learning rate scheduler\n",
    "patience = 3  # Number of epochs to wait before stopping if no improvement\n",
    "best_val_loss = np.inf  # Track the best validation loss\n",
    "early_stop_counter = 0  # Counter for early stopping\n",
    "# Define the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "\n",
    "    for i, (images, masks) in enumerate(train_loader):\n",
    "        images = images.type(torch.float32).to(device)  # Ensure float32\n",
    "        masks = masks.to(device)\n",
    "        images = (images - images.min()) / (images.max() - images.min())\n",
    "\n",
    "        if torch.isnan(images).any():\n",
    "            print(\"NaN detected in input images.\")\n",
    "        if torch.isnan(masks).any():\n",
    "            print(\"NaN detected in input masks.\")\n",
    "\n",
    "        # Forward pass\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            outputs = outputs[:, 0, :, :, :]\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += calculate_accuracy(outputs, masks).item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_acc = train_accuracy / len(train_loader)\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}, Training Accuracy: {avg_train_acc:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(val_loader):\n",
    "            images = images.type(torch.float32).to(device)  # Ensure float32\n",
    "            masks = masks.to(device)\n",
    "            images = (images - images.min()) / (images.max() - images.min())\n",
    "\n",
    "            if torch.isnan(images).any():\n",
    "                print(\"NaN detected in input images.\")\n",
    "            if torch.isnan(masks).any():\n",
    "                print(\"NaN detected in input masks.\")\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            outputs = outputs[:, 0, :, :, :]\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += calculate_accuracy(outputs, masks).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_acc = val_accuracy / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_acc:.4f}\")\n",
    "\n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0  # Reset counter if validation loss improves\n",
    "        # Optionally save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"New best validation loss: {best_val_loss:.4f}, saving model.\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"No improvement in validation loss. Early stop counter: {early_stop_counter}/{patience}\")\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28220.487585,
   "end_time": "2024-10-21T14:06:38.692226",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-21T06:16:18.204641",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
